{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import numpy as np\n",
    "from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
    "from imblearn.under_sampling import NearMiss, RandomUnderSampler\n",
    "from imblearn.combine import SMOTEENN,SMOTETomek\n",
    "from imblearn.ensemble import BalanceCascade\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from mlxtend.plotting import plot_decision_regions\n",
    "import h5py\n",
    "import keras\n",
    "from sklearn.utils import class_weight\n",
    "from keras.utils import to_categorical\n",
    "from keras.optimizers import *\n",
    "from keras.regularizers import *\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, f1_score, precision_recall_fscore_support\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "KFOLD_SEED = 42\n",
    "\n",
    "def shuffle(features, labels):\n",
    "    p = np.random.permutation(len(features))\n",
    "    return features[p], labels[p]\n",
    "\n",
    "def rtb_confusion_matrix(test_labels, y_preds):\n",
    "    m = confusion_matrix(test_labels[:,1], y_preds.argmax(axis=-1))\n",
    "    \n",
    "    print(\"================================\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(\"True Negative = %d\" % m[0][0])\n",
    "    print(\"False Negative = %d\" % m[1][0])\n",
    "    print(\"True Positive = %d\" % m[1][1])\n",
    "    print(\"False Positive = %d\" % m[0][1])\n",
    "\n",
    "\n",
    "def rtb_f1_score(test_labels, y_preds):\n",
    "    f = f1_score(test_labels[:,1], y_preds.argmax(axis=-1))\n",
    "    print(\"================================\")\n",
    "    print(\"f1 score = %0.3f\" % f)\n",
    "\n",
    "\n",
    "def rtb_precision_recall(test_labels, y_preds):\n",
    "    precision, recall, fbeta_score, support = precision_recall_fscore_support(\n",
    "        test_labels[:,1], y_preds.argmax(axis=-1))\n",
    "    print(\"================================\")\n",
    "    print(\"Precision = %0.3f, Recall = %0.3f\" % (np.mean(precision), np.mean(recall)))\n",
    "    return precision, recall\n",
    "\n",
    "\n",
    "def print_metrics(true_labels, y_preds, is_train=True):\n",
    "    if is_train:\n",
    "        print(\"--------train---------\")\n",
    "    else:\n",
    "        print(\"--------test---------\")\n",
    "    \n",
    "    rtb_confusion_matrix(true_labels, y_preds)\n",
    "    rtb_f1_score(true_labels, y_preds)\n",
    "    rtb_precision_recall(true_labels, y_preds)\n",
    "    print(\"================================\")\n",
    "    print(\"ROC AUC Score = %0.3f\" % roc_auc_score(true_labels, y_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000000, 89)\n"
     ]
    }
   ],
   "source": [
    "input_path = '~/data/biddings.csv'\n",
    "data = pd.read_csv(input_path)\n",
    "print(data.shape)\n",
    "\n",
    "train = data[:800000]\n",
    "test = data[800000:]\n",
    "\n",
    "sample = train.sample(frac=1)\n",
    "features = sample.drop('convert', axis=1).values\n",
    "labels = to_categorical(sample.convert.ravel(), 2)\n",
    "\n",
    "test_features = test.drop('convert', axis=1).values\n",
    "test_labels = to_categorical(test.convert.ravel(), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0.50095871 261.26714566]\n"
     ]
    }
   ],
   "source": [
    "# Data prep\n",
    "'''\n",
    "when sample weights is balanced, model predicts everything as positive. This is too strong\n",
    "'''\n",
    "sample_weights = class_weight.compute_sample_weight(\n",
    "    class_weight={0:1, 1:100},\n",
    "    y=labels[:,1])\n",
    "class_weights = class_weight.compute_class_weight('balanced', np.unique(labels[:,1]), labels[:,1])\n",
    "\n",
    "print(class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "epochs = 5\n",
    "\n",
    "# Build model\n",
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, input_shape=(88,),\n",
    "                    activation='relu',\n",
    "                    kernel_regularizer=l2(0.01),\n",
    "                    kernel_initializer='glorot_uniform'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(32,\n",
    "                    activation='relu',\n",
    "                    kernel_regularizer=l2(0.01),\n",
    "                    kernel_initializer='glorot_uniform'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "    #               loss_weights=class_weights,\n",
    "                  optimizer=SGD(lr=0.1, decay=0.02),\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1531\n",
      "(16841, 88) (16841, 2)\n",
      "(16841, 88) (16841, 2)\n",
      "(16841, 88) (16841, 2)\n",
      "(16841, 88) (16841, 2)\n",
      "(16841, 88) (16841, 2)\n",
      "(16841, 88) (16841, 2)\n",
      "(16841, 88) (16841, 2)\n",
      "(16841, 88) (16841, 2)\n",
      "(16841, 88) (16841, 2)\n",
      "(16841, 88) (16841, 2)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_208 (Dense)            (None, 64)                5696      \n",
      "_________________________________________________________________\n",
      "dropout_139 (Dropout)        (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_209 (Dense)            (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dropout_140 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_210 (Dense)            (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 7,842\n",
      "Trainable params: 7,842\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "(16841, 88)\n",
      "(16841, 88) (16841, 2)\n",
      "Train on 13472 samples, validate on 3369 samples\n",
      "Epoch 1/5\n",
      "13472/13472 [==============================] - 5s 342us/step - loss: 1.5499 - acc: 0.0102 - val_loss: 1.4273 - val_acc: 0.0000e+00\n",
      "Epoch 2/5\n",
      "13472/13472 [==============================] - 1s 95us/step - loss: 1.3778 - acc: 0.0102 - val_loss: 1.3392 - val_acc: 0.0000e+00\n",
      "Epoch 3/5\n",
      "13472/13472 [==============================] - 1s 99us/step - loss: 1.3134 - acc: 0.0102 - val_loss: 1.2911 - val_acc: 0.0000e+00\n",
      "Epoch 4/5\n",
      "13472/13472 [==============================] - 1s 96us/step - loss: 1.2741 - acc: 0.0102 - val_loss: 1.2588 - val_acc: 0.0000e+00\n",
      "Epoch 5/5\n",
      "13472/13472 [==============================] - 1s 98us/step - loss: 1.2462 - acc: 0.0102 - val_loss: 1.2347 - val_acc: 0.0000e+00\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_211 (Dense)            (None, 64)                5696      \n",
      "_________________________________________________________________\n",
      "dropout_141 (Dropout)        (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_212 (Dense)            (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dropout_142 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_213 (Dense)            (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 7,842\n",
      "Trainable params: 7,842\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "(16841, 88)\n",
      "(16841, 88) (16841, 2)\n",
      "Train on 13472 samples, validate on 3369 samples\n",
      "Epoch 1/5\n",
      "13472/13472 [==============================] - 5s 373us/step - loss: 1.5689 - acc: 0.0000e+00 - val_loss: 1.4436 - val_acc: 0.0000e+00\n",
      "Epoch 2/5\n",
      "13472/13472 [==============================] - 2s 120us/step - loss: 1.3930 - acc: 0.0000e+00 - val_loss: 1.3535 - val_acc: 0.0000e+00\n",
      "Epoch 3/5\n",
      "13472/13472 [==============================] - 1s 103us/step - loss: 1.3271 - acc: 0.0000e+00 - val_loss: 1.3044 - val_acc: 0.0000e+00\n",
      "Epoch 4/5\n",
      "13472/13472 [==============================] - 1s 97us/step - loss: 1.2870 - acc: 0.0000e+00 - val_loss: 1.2713 - val_acc: 0.0000e+00\n",
      "Epoch 5/5\n",
      "13472/13472 [==============================] - 1s 100us/step - loss: 1.2585 - acc: 0.0000e+00 - val_loss: 1.2467 - val_acc: 0.0000e+00\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_214 (Dense)            (None, 64)                5696      \n",
      "_________________________________________________________________\n",
      "dropout_143 (Dropout)        (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_215 (Dense)            (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dropout_144 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_216 (Dense)            (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 7,842\n",
      "Trainable params: 7,842\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "(16841, 88)\n",
      "(16841, 88) (16841, 2)\n",
      "Train on 13472 samples, validate on 3369 samples\n",
      "Epoch 1/5\n",
      "13472/13472 [==============================] - 5s 340us/step - loss: 1.5710 - acc: 0.0000e+00 - val_loss: 1.4453 - val_acc: 0.0000e+00\n",
      "Epoch 2/5\n",
      "13472/13472 [==============================] - 1s 97us/step - loss: 1.3946 - acc: 0.0000e+00 - val_loss: 1.3551 - val_acc: 0.0000e+00\n",
      "Epoch 3/5\n",
      "13472/13472 [==============================] - 1s 98us/step - loss: 1.3286 - acc: 0.0000e+00 - val_loss: 1.3058 - val_acc: 0.0000e+00\n",
      "Epoch 4/5\n",
      "13472/13472 [==============================] - 1s 101us/step - loss: 1.2883 - acc: 0.0000e+00 - val_loss: 1.2726 - val_acc: 0.0000e+00\n",
      "Epoch 5/5\n",
      "13472/13472 [==============================] - 1s 108us/step - loss: 1.2598 - acc: 0.0000e+00 - val_loss: 1.2480 - val_acc: 0.0000e+00\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_217 (Dense)            (None, 64)                5696      \n",
      "_________________________________________________________________\n",
      "dropout_145 (Dropout)        (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_218 (Dense)            (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dropout_146 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_219 (Dense)            (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 7,842\n",
      "Trainable params: 7,842\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "(16841, 88)\n",
      "(16841, 88) (16841, 2)\n",
      "Train on 13472 samples, validate on 3369 samples\n",
      "Epoch 1/5\n",
      "13472/13472 [==============================] - 5s 351us/step - loss: 1.5497 - acc: 0.0000e+00 - val_loss: 1.4271 - val_acc: 0.0000e+00\n",
      "Epoch 2/5\n",
      "13472/13472 [==============================] - 1s 98us/step - loss: 1.3776 - acc: 0.0000e+00 - val_loss: 1.3390 - val_acc: 0.0000e+00\n",
      "Epoch 3/5\n",
      "13472/13472 [==============================] - 1s 100us/step - loss: 1.3132 - acc: 0.0000e+00 - val_loss: 1.2910 - val_acc: 0.0000e+00\n",
      "Epoch 4/5\n",
      "13472/13472 [==============================] - 1s 106us/step - loss: 1.2739 - acc: 0.0000e+00 - val_loss: 1.2586 - val_acc: 0.0000e+00\n",
      "Epoch 5/5\n",
      "13472/13472 [==============================] - 1s 99us/step - loss: 1.2461 - acc: 0.0000e+00 - val_loss: 1.2345 - val_acc: 0.0000e+00\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_220 (Dense)            (None, 64)                5696      \n",
      "_________________________________________________________________\n",
      "dropout_147 (Dropout)        (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_221 (Dense)            (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dropout_148 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_222 (Dense)            (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 7,842\n",
      "Trainable params: 7,842\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "(16841, 88)\n",
      "(16841, 88) (16841, 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 13472 samples, validate on 3369 samples\n",
      "Epoch 1/5\n",
      "13472/13472 [==============================] - 5s 374us/step - loss: 1.5636 - acc: 0.1658 - val_loss: 1.4396 - val_acc: 0.5003\n",
      "Epoch 2/5\n",
      "13472/13472 [==============================] - 1s 101us/step - loss: 1.3886 - acc: 0.1598 - val_loss: 1.3497 - val_acc: 0.5003\n",
      "Epoch 3/5\n",
      "13472/13472 [==============================] - 1s 103us/step - loss: 1.3230 - acc: 0.1598 - val_loss: 1.3008 - val_acc: 0.5003\n",
      "Epoch 4/5\n",
      "13472/13472 [==============================] - 1s 101us/step - loss: 1.2830 - acc: 0.1598 - val_loss: 1.2679 - val_acc: 0.5003\n",
      "Epoch 5/5\n",
      "13472/13472 [==============================] - 1s 98us/step - loss: 1.2546 - acc: 0.1598 - val_loss: 1.2435 - val_acc: 0.5003\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_223 (Dense)            (None, 64)                5696      \n",
      "_________________________________________________________________\n",
      "dropout_149 (Dropout)        (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_224 (Dense)            (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dropout_150 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_225 (Dense)            (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 7,842\n",
      "Trainable params: 7,842\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "(16841, 88)\n",
      "(16841, 88) (16841, 2)\n",
      "Train on 13472 samples, validate on 3369 samples\n",
      "Epoch 1/5\n",
      "13472/13472 [==============================] - 5s 382us/step - loss: 1.5716 - acc: 0.5045 - val_loss: 1.4458 - val_acc: 0.4994\n",
      "Epoch 2/5\n",
      "13472/13472 [==============================] - 1s 111us/step - loss: 1.3951 - acc: 0.5000 - val_loss: 1.3555 - val_acc: 0.4994\n",
      "Epoch 3/5\n",
      "13472/13472 [==============================] - 1s 106us/step - loss: 1.3290 - acc: 0.5003 - val_loss: 1.3062 - val_acc: 0.4994\n",
      "Epoch 4/5\n",
      "13472/13472 [==============================] - 1s 101us/step - loss: 1.2888 - acc: 0.5003 - val_loss: 1.2730 - val_acc: 0.4994\n",
      "Epoch 5/5\n",
      "13472/13472 [==============================] - 1s 95us/step - loss: 1.2602 - acc: 0.5003 - val_loss: 1.2484 - val_acc: 0.4994\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_226 (Dense)            (None, 64)                5696      \n",
      "_________________________________________________________________\n",
      "dropout_151 (Dropout)        (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_227 (Dense)            (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dropout_152 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_228 (Dense)            (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 7,842\n",
      "Trainable params: 7,842\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "(16841, 88)\n",
      "(16841, 88) (16841, 2)\n",
      "Train on 13472 samples, validate on 3369 samples\n",
      "Epoch 1/5\n",
      "13472/13472 [==============================] - 5s 392us/step - loss: 1.5576 - acc: 0.5016 - val_loss: 1.4339 - val_acc: 0.4996\n",
      "Epoch 2/5\n",
      "13472/13472 [==============================] - 1s 109us/step - loss: 1.3839 - acc: 0.5006 - val_loss: 1.3450 - val_acc: 0.4996\n",
      "Epoch 3/5\n",
      "13472/13472 [==============================] - 2s 113us/step - loss: 1.3189 - acc: 0.5006 - val_loss: 1.2965 - val_acc: 0.4996\n",
      "Epoch 4/5\n",
      "13472/13472 [==============================] - 1s 97us/step - loss: 1.2793 - acc: 0.5006 - val_loss: 1.2638 - val_acc: 0.4996\n",
      "Epoch 5/5\n",
      "13472/13472 [==============================] - 2s 116us/step - loss: 1.2512 - acc: 0.5006 - val_loss: 1.2395 - val_acc: 0.4996\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_229 (Dense)            (None, 64)                5696      \n",
      "_________________________________________________________________\n",
      "dropout_153 (Dropout)        (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_230 (Dense)            (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dropout_154 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_231 (Dense)            (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 7,842\n",
      "Trainable params: 7,842\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "(16841, 88)\n",
      "(16841, 88) (16841, 2)\n",
      "Train on 13472 samples, validate on 3369 samples\n",
      "Epoch 1/5\n",
      "13472/13472 [==============================] - 5s 360us/step - loss: 1.5604 - acc: 0.5117 - val_loss: 1.4363 - val_acc: 0.5006\n",
      "Epoch 2/5\n",
      "13472/13472 [==============================] - 1s 100us/step - loss: 1.3861 - acc: 0.4996 - val_loss: 1.3471 - val_acc: 0.5006\n",
      "Epoch 3/5\n",
      "13472/13472 [==============================] - 1s 107us/step - loss: 1.3209 - acc: 0.4992 - val_loss: 1.2984 - val_acc: 0.5006\n",
      "Epoch 4/5\n",
      "13472/13472 [==============================] - 2s 118us/step - loss: 1.2812 - acc: 0.4998 - val_loss: 1.2657 - val_acc: 0.5006\n",
      "Epoch 5/5\n",
      "13472/13472 [==============================] - 1s 103us/step - loss: 1.2530 - acc: 0.4996 - val_loss: 1.2413 - val_acc: 0.5006\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_232 (Dense)            (None, 64)                5696      \n",
      "_________________________________________________________________\n",
      "dropout_155 (Dropout)        (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_233 (Dense)            (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dropout_156 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_234 (Dense)            (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 7,842\n",
      "Trainable params: 7,842\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "(16841, 88)\n",
      "(16841, 88) (16841, 2)\n",
      "Train on 13472 samples, validate on 3369 samples\n",
      "Epoch 1/5\n",
      "13472/13472 [==============================] - 6s 417us/step - loss: 1.5645 - acc: 0.5009 - val_loss: 1.4398 - val_acc: 0.5001\n",
      "Epoch 2/5\n",
      "13472/13472 [==============================] - 1s 95us/step - loss: 1.3894 - acc: 0.4999 - val_loss: 1.3502 - val_acc: 0.4999\n",
      "Epoch 3/5\n",
      "13472/13472 [==============================] - 1s 111us/step - loss: 1.3239 - acc: 0.4993 - val_loss: 1.3013 - val_acc: 0.4999\n",
      "Epoch 4/5\n",
      "13472/13472 [==============================] - 1s 105us/step - loss: 1.2839 - acc: 0.4996 - val_loss: 1.2684 - val_acc: 0.4999\n",
      "Epoch 5/5\n",
      "13472/13472 [==============================] - 2s 111us/step - loss: 1.2556 - acc: 0.5000 - val_loss: 1.2439 - val_acc: 0.4999\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_235 (Dense)            (None, 64)                5696      \n",
      "_________________________________________________________________\n",
      "dropout_157 (Dropout)        (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_236 (Dense)            (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dropout_158 (Dropout)        (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_237 (Dense)            (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 7,842\n",
      "Trainable params: 7,842\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "(16841, 88)\n",
      "(16841, 88) (16841, 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 13472 samples, validate on 3369 samples\n",
      "Epoch 1/5\n",
      "13472/13472 [==============================] - 5s 383us/step - loss: 0.2785 - acc: 0.0554 - val_loss: -0.7008 - val_acc: 0.0000e+00\n",
      "Epoch 2/5\n",
      "13472/13472 [==============================] - 2s 119us/step - loss: -0.2243 - acc: 0.0552 - val_loss: -1.8113 - val_acc: 0.0000e+00\n",
      "Epoch 3/5\n",
      "13472/13472 [==============================] - 1s 102us/step - loss: -0.4045 - acc: 0.0552 - val_loss: -2.2294 - val_acc: 0.0000e+00\n",
      "Epoch 4/5\n",
      "13472/13472 [==============================] - 1s 102us/step - loss: -0.4369 - acc: 0.0552 - val_loss: -1.5716 - val_acc: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "n_batches = 10\n",
    "\n",
    "def gen_batches(features, labels, n_batches=10, ratio=10):\n",
    "    positive_samples = sample[sample.convert == 1]\n",
    "    negative_samples = sample[sample.convert == 0]\n",
    "    \n",
    "    positive_size = positive_samples.shape[0]\n",
    "    \n",
    "    print(positive_size)\n",
    "    \n",
    "#     batches = np.empty(shape=(n_batches, positive_size * 2, 89))\n",
    "    feature_batches = np.empty(shape=(n_batches, positive_size*(ratio+1), 88))\n",
    "    label_batches = np.empty(shape=(n_batches, positive_size*(ratio+1), 2))\n",
    "\n",
    "    for i in range(n_batches):\n",
    "        b = negative_samples[i*n_batches : (positive_size*ratio + i*n_batches)]\n",
    "        shuffled = pd.concat([b, positive_samples]).sample(frac=1)\n",
    "        shuffled_features = shuffled.drop('convert', axis = 1).values\n",
    "        shuffled_labels = to_categorical(shuffled.convert.ravel(), 2)\n",
    "        \n",
    "        print(shuffled_features.shape, shuffled_labels.shape)\n",
    "        np.append(feature_batches, shuffled_features)\n",
    "        np.append(label_batches, shuffled_labels)\n",
    "    \n",
    "    return feature_batches, label_batches\n",
    "\n",
    "\n",
    "def train_batched_models(feature_batches, label_batches):\n",
    "    models = []\n",
    "    for i, fb in enumerate(feature_batches):\n",
    "        model = create_model()\n",
    "        print(fb.shape)\n",
    "\n",
    "        lb = label_batches[i]\n",
    "        \n",
    "        print(fb.shape, lb.shape)\n",
    "    \n",
    "        model.fit(fb, lb,\n",
    "            batch_size=batch_size,\n",
    "#             class_weight={0:1, 1:5},\n",
    "    #       sample_weight=sample_weights,\n",
    "            epochs=epochs,\n",
    "            callbacks=[keras.callbacks.EarlyStopping()],\n",
    "            validation_split=0.2,\n",
    "            verbose=1)\n",
    "        models.append(model)\n",
    "    return models\n",
    "\n",
    "\n",
    "def predict_batched_models(models, test_features, test_labels, n_batches=10):\n",
    "    cum_preds = None\n",
    "    for model in models:\n",
    "        test_preds = model.predict(test_features, verbose=1)\n",
    "        print(test_preds.shape)\n",
    "        print(test_preds[0:10])\n",
    "        print_metrics(test_labels, test_preds, is_train=False)\n",
    "        \n",
    "        if cum_preds is None:\n",
    "            cum_preds = test_preds\n",
    "            print(cum_preds.shape)\n",
    "        else:\n",
    "            cum_preds += test_preds\n",
    "    \n",
    "    return cum_preds/n_batches\n",
    "\n",
    "\n",
    "feature_batches, label_batches = gen_batches(features, labels, n_batches=n_batches)\n",
    "models = train_batched_models(feature_batches, label_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200000/200000 [==============================] - 10s 51us/step\n",
      "(200000, 2)\n",
      "[[0.6916608  0.30833918]\n",
      " [0.44448575 0.5555142 ]\n",
      " [0.52824044 0.47175953]\n",
      " [0.48681757 0.51318246]\n",
      " [0.44983444 0.5501656 ]\n",
      " [0.55644184 0.44355822]\n",
      " [0.5795436  0.4204565 ]\n",
      " [0.4676635  0.53233653]\n",
      " [0.544575   0.45542502]\n",
      " [0.5532304  0.44676957]]\n",
      "--------test---------\n",
      "================================\n",
      "Confusion Matrix:\n",
      "True Negative = 148904\n",
      "False Negative = 263\n",
      "True Positive = 114\n",
      "False Positive = 50719\n",
      "================================\n",
      "f1 score = 0.004\n",
      "================================\n",
      "Precision = 0.500, Recall = 0.524\n",
      "================================\n",
      "ROC AUC Score = 0.528\n",
      "(200000, 2)\n",
      "200000/200000 [==============================] - 10s 50us/step\n",
      "(200000, 2)\n",
      "[[0.28798667 0.71201336]\n",
      " [0.332157   0.66784304]\n",
      " [0.43195635 0.56804365]\n",
      " [0.39905155 0.60094845]\n",
      " [0.46526214 0.5347378 ]\n",
      " [0.3623842  0.63761574]\n",
      " [0.52184844 0.47815156]\n",
      " [0.4619948  0.5380052 ]\n",
      " [0.51808023 0.48191977]\n",
      " [0.4178925  0.5821075 ]]\n",
      "--------test---------\n",
      "================================\n",
      "Confusion Matrix:\n",
      "True Negative = 16877\n",
      "False Negative = 28\n",
      "True Positive = 349\n",
      "False Positive = 182746\n",
      "================================\n",
      "f1 score = 0.004\n",
      "================================\n",
      "Precision = 0.500, Recall = 0.505\n",
      "================================\n",
      "ROC AUC Score = 0.517\n",
      "200000/200000 [==============================] - 10s 50us/step\n",
      "(200000, 2)\n",
      "[[0.756174   0.24382599]\n",
      " [0.37576675 0.62423325]\n",
      " [0.47349966 0.52650034]\n",
      " [0.40694568 0.59305435]\n",
      " [0.48796543 0.51203465]\n",
      " [0.4553109  0.54468906]\n",
      " [0.52230364 0.4776964 ]\n",
      " [0.43279865 0.5672014 ]\n",
      " [0.44847065 0.55152935]\n",
      " [0.49242836 0.50757164]]\n",
      "--------test---------\n",
      "================================\n",
      "Confusion Matrix:\n",
      "True Negative = 102061\n",
      "False Negative = 208\n",
      "True Positive = 169\n",
      "False Positive = 97562\n",
      "================================\n",
      "f1 score = 0.003\n",
      "================================\n",
      "Precision = 0.500, Recall = 0.480\n",
      "================================\n",
      "ROC AUC Score = 0.471\n",
      "200000/200000 [==============================] - 10s 48us/step\n",
      "(200000, 2)\n",
      "[[0.8539042  0.14609575]\n",
      " [0.5898548  0.41014516]\n",
      " [0.6034417  0.39655828]\n",
      " [0.6206059  0.37939408]\n",
      " [0.881857   0.11814307]\n",
      " [0.6211061  0.37889385]\n",
      " [0.7322518  0.26774815]\n",
      " [0.731549   0.26845106]\n",
      " [0.6466307  0.3533693 ]\n",
      " [0.6504957  0.34950432]]\n",
      "--------test---------\n",
      "================================\n",
      "Confusion Matrix:\n",
      "True Negative = 188040\n",
      "False Negative = 353\n",
      "True Positive = 24\n",
      "False Positive = 11583\n",
      "================================\n",
      "f1 score = 0.004\n",
      "================================\n",
      "Precision = 0.500, Recall = 0.503\n",
      "================================\n",
      "ROC AUC Score = 0.479\n",
      "200000/200000 [==============================] - 10s 50us/step\n",
      "(200000, 2)\n",
      "[[0.7499481  0.25005192]\n",
      " [0.4337072  0.5662928 ]\n",
      " [0.47029686 0.5297031 ]\n",
      " [0.46472204 0.53527796]\n",
      " [0.4344311  0.5655689 ]\n",
      " [0.50660974 0.49339032]\n",
      " [0.45194143 0.5480586 ]\n",
      " [0.532462   0.46753803]\n",
      " [0.41845775 0.58154225]\n",
      " [0.34407544 0.6559246 ]]\n",
      "--------test---------\n",
      "================================\n",
      "Confusion Matrix:\n",
      "True Negative = 67317\n",
      "False Negative = 163\n",
      "True Positive = 214\n",
      "False Positive = 132306\n",
      "================================\n",
      "f1 score = 0.003\n",
      "================================\n",
      "Precision = 0.500, Recall = 0.452\n",
      "================================\n",
      "ROC AUC Score = 0.446\n",
      "200000/200000 [==============================] - 10s 51us/step\n",
      "(200000, 2)\n",
      "[[0.22815703 0.7718429 ]\n",
      " [0.52546155 0.47453848]\n",
      " [0.38212335 0.6178767 ]\n",
      " [0.31820792 0.68179214]\n",
      " [0.32624236 0.6737576 ]\n",
      " [0.47076336 0.5292366 ]\n",
      " [0.48294252 0.5170575 ]\n",
      " [0.37160322 0.62839675]\n",
      " [0.42164838 0.5783516 ]\n",
      " [0.48025045 0.5197495 ]]\n",
      "--------test---------\n",
      "================================\n",
      "Confusion Matrix:\n",
      "True Negative = 26288\n",
      "False Negative = 73\n",
      "True Positive = 304\n",
      "False Positive = 173335\n",
      "================================\n",
      "f1 score = 0.003\n",
      "================================\n",
      "Precision = 0.499, Recall = 0.469\n",
      "================================\n",
      "ROC AUC Score = 0.455\n",
      "200000/200000 [==============================] - 10s 51us/step\n",
      "(200000, 2)\n",
      "[[0.73519355 0.2648064 ]\n",
      " [0.40147045 0.5985295 ]\n",
      " [0.5285958  0.47140417]\n",
      " [0.49007013 0.5099299 ]\n",
      " [0.5157534  0.48424658]\n",
      " [0.35613066 0.64386934]\n",
      " [0.58893627 0.4110637 ]\n",
      " [0.48463598 0.51536393]\n",
      " [0.47717017 0.5228298 ]\n",
      " [0.45687023 0.5431298 ]]\n",
      "--------test---------\n",
      "================================\n",
      "Confusion Matrix:\n",
      "True Negative = 89527\n",
      "False Negative = 180\n",
      "True Positive = 197\n",
      "False Positive = 110096\n",
      "================================\n",
      "f1 score = 0.004\n",
      "================================\n",
      "Precision = 0.500, Recall = 0.486\n",
      "================================\n",
      "ROC AUC Score = 0.482\n",
      "200000/200000 [==============================] - 10s 50us/step\n",
      "(200000, 2)\n",
      "[[0.09219398 0.90780604]\n",
      " [0.40401682 0.59598315]\n",
      " [0.47208914 0.52791095]\n",
      " [0.4854245  0.51457554]\n",
      " [0.34955463 0.6504454 ]\n",
      " [0.33990014 0.6600998 ]\n",
      " [0.38205653 0.61794347]\n",
      " [0.4749024  0.52509755]\n",
      " [0.4902205  0.5097795 ]\n",
      " [0.546019   0.45398098]]\n",
      "--------test---------\n",
      "================================\n",
      "Confusion Matrix:\n",
      "True Negative = 53320\n",
      "False Negative = 101\n",
      "True Positive = 276\n",
      "False Positive = 146303\n",
      "================================\n",
      "f1 score = 0.004\n",
      "================================\n",
      "Precision = 0.500, Recall = 0.500\n",
      "================================\n",
      "ROC AUC Score = 0.530\n",
      "200000/200000 [==============================] - 10s 49us/step\n",
      "(200000, 2)\n",
      "[[0.5056879  0.49431214]\n",
      " [0.3310113  0.6689887 ]\n",
      " [0.55880415 0.44119582]\n",
      " [0.4916649  0.5083351 ]\n",
      " [0.25402096 0.745979  ]\n",
      " [0.47774327 0.5222567 ]\n",
      " [0.59960467 0.4003953 ]\n",
      " [0.34521392 0.65478617]\n",
      " [0.59841555 0.4015845 ]\n",
      " [0.57169396 0.428306  ]]\n",
      "--------test---------\n",
      "================================\n",
      "Confusion Matrix:\n",
      "True Negative = 132540\n",
      "False Negative = 269\n",
      "True Positive = 108\n",
      "False Positive = 67083\n",
      "================================\n",
      "f1 score = 0.003\n",
      "================================\n",
      "Precision = 0.500, Recall = 0.475\n",
      "================================\n",
      "ROC AUC Score = 0.464\n",
      "200000/200000 [==============================] - 9s 47us/step\n",
      "(200000, 2)\n",
      "[[7.0458051e-04 9.9929535e-01]\n",
      " [1.0444024e-03 9.9895561e-01]\n",
      " [3.2551558e-04 9.9967444e-01]\n",
      " [3.2164255e-04 9.9967837e-01]\n",
      " [5.9075543e-04 9.9940920e-01]\n",
      " [1.3487629e-03 9.9865121e-01]\n",
      " [6.7098619e-04 9.9932909e-01]\n",
      " [9.3419949e-04 9.9906582e-01]\n",
      " [8.7054115e-04 9.9912947e-01]\n",
      " [4.5253537e-04 9.9954742e-01]]\n",
      "--------test---------\n",
      "================================\n",
      "Confusion Matrix:\n",
      "True Negative = 9\n",
      "False Negative = 0\n",
      "True Positive = 377\n",
      "False Positive = 199614\n",
      "================================\n",
      "f1 score = 0.004\n",
      "================================\n",
      "Precision = 0.501, Recall = 0.500\n",
      "================================\n",
      "ROC AUC Score = 0.516\n",
      "(200000, 2)\n",
      "[[0.4901611  0.50983894]\n",
      " [0.3838976  0.6161024 ]\n",
      " [0.44493732 0.55506265]\n",
      " [0.4163832  0.58361685]\n",
      " [0.41655126 0.58344877]\n",
      " [0.41477388 0.5852261 ]\n",
      " [0.48621002 0.51379   ]\n",
      " [0.4303758  0.56962425]\n",
      " [0.45645398 0.5435461 ]\n",
      " [0.45134085 0.5486592 ]]\n",
      "--------test---------\n",
      "================================\n",
      "Confusion Matrix:\n",
      "True Negative = 8381\n",
      "False Negative = 16\n",
      "True Positive = 361\n",
      "False Positive = 191242\n",
      "================================\n",
      "f1 score = 0.004\n",
      "================================\n",
      "Precision = 0.500, Recall = 0.500\n",
      "================================\n",
      "ROC AUC Score = 0.442\n"
     ]
    }
   ],
   "source": [
    "predicted_test_scores = predict_batched_models(models, test_features, test_labels, n_batches=n_batches)\n",
    "print(predicted_test_scores.shape)\n",
    "print(predicted_test_scores[0:10])\n",
    "\n",
    "print_metrics(test_labels, predicted_test_scores, is_train=False)\n",
    "\n",
    "# print(test_labels.argmax(axis=-1).shape, predicted_test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
