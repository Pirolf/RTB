{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import numpy as np\n",
    "from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
    "from imblearn.under_sampling import NearMiss, RandomUnderSampler\n",
    "from imblearn.combine import SMOTEENN,SMOTETomek\n",
    "from imblearn.ensemble import BalanceCascade\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from mlxtend.plotting import plot_decision_regions\n",
    "import h5py\n",
    "import keras\n",
    "from sklearn.utils import class_weight\n",
    "from keras.utils import to_categorical\n",
    "from keras.optimizers import *\n",
    "from keras.regularizers import *\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from sklearn.metrics import confusion_matrix, f1_score, precision_recall_fscore_support\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "KFOLD_SEED = 42\n",
    "\n",
    "def shuffle(features, labels):\n",
    "    p = np.random.permutation(len(features))\n",
    "    return features[p], labels[p]\n",
    "\n",
    "def rtb_confusion_matrix(test_labels, y_preds):\n",
    "    m = confusion_matrix(test_labels[:,1], y_preds.argmax(axis=-1))\n",
    "    \n",
    "    print(\"================================\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(\"True Negative = %d\" % m[0][0])\n",
    "    print(\"False Negative = %d\" % m[1][0])\n",
    "    print(\"True Positive = %d\" % m[1][1])\n",
    "    print(\"False Positive = %d\" % m[0][1])\n",
    "\n",
    "\n",
    "def rtb_f1_score(test_labels, y_preds):\n",
    "    f = f1_score(test_labels[:, 1], y_preds.argmax(axis=-1))\n",
    "    print(\"================================\")\n",
    "    print(\"f1 score = %0.3f\" % f)\n",
    "\n",
    "\n",
    "def rtb_precision_recall(test_labels, y_preds):\n",
    "    precision, recall, fbeta_score, support = precision_recall_fscore_support(\n",
    "        test_labels[:, 1], y_preds.argmax(axis=-1))\n",
    "    print(\"================================\")\n",
    "    print(\"Precision = %0.3f, Recall = %0.3f\" % (np.mean(precision), np.mean(recall)))\n",
    "    return precision, recall\n",
    "\n",
    "\n",
    "def print_metrics(true_labels, y_preds, is_train=True):\n",
    "    if is_train:\n",
    "        print(\"--------train---------\")\n",
    "    else:\n",
    "        print(\"--------test---------\")\n",
    "    \n",
    "    rtb_confusion_matrix(true_labels, y_preds)\n",
    "    rtb_f1_score(true_labels, y_preds)\n",
    "    rtb_precision_recall(true_labels, y_preds)\n",
    "    print(\"================================\")\n",
    "    print(\"ROC AUC Score = %0.3f\" % roc_auc_score(true_labels, y_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000000, 89)\n"
     ]
    }
   ],
   "source": [
    "input_path = '~/data/biddings.csv'\n",
    "data = pd.read_csv(input_path)\n",
    "print(data.shape)\n",
    "\n",
    "train = data[:800000]\n",
    "test = data[800000:]\n",
    "\n",
    "sample = train.sample(frac=1)\n",
    "features = sample.drop('convert', axis=1).values\n",
    "labels = to_categorical(sample.convert.ravel(), 2)\n",
    "\n",
    "test_features = test.drop('convert', axis=1).values\n",
    "test_labels = to_categorical(test.convert.ravel(), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0.50095871 261.26714566]\n"
     ]
    }
   ],
   "source": [
    "# Data prep\n",
    "'''\n",
    "when sample weights is balanced, model predicts everything as positive. This is too strong\n",
    "'''\n",
    "sample_weights = class_weight.compute_sample_weight(\n",
    "    class_weight={0:1, 1:100},\n",
    "    y=labels[:,1])\n",
    "class_weights = class_weight.compute_class_weight('balanced', np.unique(labels[:,1]), labels[:,1])\n",
    "\n",
    "print(class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "epochs = 5\n",
    "\n",
    "# Build model\n",
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, input_shape=(88,),\n",
    "                    activation='relu',\n",
    "                    kernel_regularizer=l2(0.01),\n",
    "                    kernel_initializer='glorot_uniform'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(32,\n",
    "                    activation='relu',\n",
    "                    kernel_regularizer=l2(0.01),\n",
    "                    kernel_initializer='glorot_uniform'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "    #               loss_weights=class_weights,\n",
    "                  optimizer=SGD(lr=0.1, decay=0.02),\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "136259 71063741\n",
      "12127051\n",
      "12263310\n",
      "12127051\n",
      "12263310\n",
      "12127051\n",
      "12263310\n",
      "12127051\n",
      "12263310\n",
      "12127051\n",
      "12263310\n",
      "12127051\n",
      "12263310\n",
      "12127051\n",
      "12263310\n",
      "12127051\n",
      "12263310\n",
      "12127051\n",
      "12263310\n",
      "12127051\n",
      "12263310\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot copy sequence with size 137790 to array axis with dimension 89",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-70-90de8d4a24c3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m \u001b[0mbatches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_batches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0mmodels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_batched_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-70-90de8d4a24c3>\u001b[0m in \u001b[0;36mgen_batches\u001b[0;34m(features, labels, n_batches)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mbatches\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mshuffled\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot copy sequence with size 137790 to array axis with dimension 89"
     ]
    }
   ],
   "source": [
    "def gen_batches(features, labels, n_batches=10):\n",
    "    positive_samples = sample[sample.convert == 1]\n",
    "    negative_samples = sample[sample.convert == 0]\n",
    "    \n",
    "    print(positive_samples.size, negative_samples.size)\n",
    "    batches = []\n",
    "    for i in range(n_batches):\n",
    "        b = negative_samples[i*n_batches : (positive_samples.size + i*n_batches)]\n",
    "        print(b.size)\n",
    "        shuffled = pd.concat([b, positive_samples]).sample(frac=1)\n",
    "        print(shuffled.size)\n",
    "        batches.append([shuffled])\n",
    "    \n",
    "    return np.array(batches)\n",
    "\n",
    "\n",
    "def train_batched_models(batches):\n",
    "    models = []\n",
    "    for b in batches:\n",
    "        model = create_model()\n",
    "        batch_features = b.drop('convert', axis=1).values\n",
    "        batch_labels = to_categorical(b.convert.ravel(), 2)\n",
    "        \n",
    "        model.fit(batch_features, batch_labels,\n",
    "            batch_size=batch_size,\n",
    "    #         class_weight={0:1, 1:400},\n",
    "    #       sample_weight=sample_weights,\n",
    "            epochs=epochs,\n",
    "            callbacks=[keras.callbacks.EarlyStopping()],\n",
    "            validation_split=0.2,\n",
    "            verbose=1)\n",
    "        models.append(model)\n",
    "    return models\n",
    "\n",
    "\n",
    "def predict_batched_models(models, test_features, test_labels):\n",
    "    cum_preds = None\n",
    "    for model in models:\n",
    "        test_preds = model.predict(test_features, verbose=1)\n",
    "        print_metrics(test_labels, test_preds, is_train=False)\n",
    "        \n",
    "        if cum_preds is None:\n",
    "            cum_preds = test_preds\n",
    "            print(cum_preds.shape)\n",
    "        else:\n",
    "            cum_preds += test_preds\n",
    "    \n",
    "    return np.mean(cum_preds, axis=1)\n",
    "\n",
    "\n",
    "batches = gen_batches(features, labels)\n",
    "models = train_batched_models(batches)\n",
    "\n",
    "# predicted_test_scores = predict_batched_models(models)\n",
    "# predicted_test_labels = map(lambda s: 1 if s > 0.5 else 0, predicted_test_labels)\n",
    "\n",
    "# print_metrics(test_labels, predicted_test_labels, is_train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200000/200000 [==============================] - 5s 27us/step\n",
      "--------test---------\n",
      "================================\n",
      "Confusion Matrix:\n",
      "True Negative = 199623\n",
      "False Negative = 377\n",
      "True Positive = 0\n",
      "False Positive = 0\n",
      "================================\n",
      "f1 score = 0.000\n",
      "================================\n",
      "Precision = 0.499, Recall = 0.500\n",
      "================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.local/share/virtualenvs/RTB-V2Lvgo6A/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/root/.local/share/virtualenvs/RTB-V2Lvgo6A/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score = 0.618\n",
      "(200000, 2)\n",
      "200000/200000 [==============================] - 6s 29us/step\n",
      "--------test---------\n",
      "================================\n",
      "Confusion Matrix:\n",
      "True Negative = 199623\n",
      "False Negative = 377\n",
      "True Positive = 0\n",
      "False Positive = 0\n",
      "================================\n",
      "f1 score = 0.000\n",
      "================================\n",
      "Precision = 0.499, Recall = 0.500\n",
      "================================\n",
      "ROC AUC Score = 0.645\n",
      "200000/200000 [==============================] - 6s 29us/step\n",
      "--------test---------\n",
      "================================\n",
      "Confusion Matrix:\n",
      "True Negative = 199623\n",
      "False Negative = 377\n",
      "True Positive = 0\n",
      "False Positive = 0\n",
      "================================\n",
      "f1 score = 0.000\n",
      "================================\n",
      "Precision = 0.499, Recall = 0.500\n",
      "================================\n",
      "ROC AUC Score = 0.628\n",
      "200000/200000 [==============================] - 6s 28us/step\n",
      "--------test---------\n",
      "================================\n",
      "Confusion Matrix:\n",
      "True Negative = 199623\n",
      "False Negative = 377\n",
      "True Positive = 0\n",
      "False Positive = 0\n",
      "================================\n",
      "f1 score = 0.000\n",
      "================================\n",
      "Precision = 0.499, Recall = 0.500\n",
      "================================\n",
      "ROC AUC Score = 0.597\n",
      "200000/200000 [==============================] - 6s 29us/step\n",
      "--------test---------\n",
      "================================\n",
      "Confusion Matrix:\n",
      "True Negative = 199623\n",
      "False Negative = 377\n",
      "True Positive = 0\n",
      "False Positive = 0\n",
      "================================\n",
      "f1 score = 0.000\n",
      "================================\n",
      "Precision = 0.499, Recall = 0.500\n",
      "================================\n",
      "ROC AUC Score = 0.641\n",
      "200000/200000 [==============================] - 6s 28us/step\n",
      "--------test---------\n",
      "================================\n",
      "Confusion Matrix:\n",
      "True Negative = 199623\n",
      "False Negative = 377\n",
      "True Positive = 0\n",
      "False Positive = 0\n",
      "================================\n",
      "f1 score = 0.000\n",
      "================================\n",
      "Precision = 0.499, Recall = 0.500\n",
      "================================\n",
      "ROC AUC Score = 0.633\n",
      "200000/200000 [==============================] - 6s 29us/step\n",
      "--------test---------\n",
      "================================\n",
      "Confusion Matrix:\n",
      "True Negative = 199623\n",
      "False Negative = 377\n",
      "True Positive = 0\n",
      "False Positive = 0\n",
      "================================\n",
      "f1 score = 0.000\n",
      "================================\n",
      "Precision = 0.499, Recall = 0.500\n",
      "================================\n",
      "ROC AUC Score = 0.625\n",
      "200000/200000 [==============================] - 6s 29us/step\n",
      "--------test---------\n",
      "================================\n",
      "Confusion Matrix:\n",
      "True Negative = 199623\n",
      "False Negative = 377\n",
      "True Positive = 0\n",
      "False Positive = 0\n",
      "================================\n",
      "f1 score = 0.000\n",
      "================================\n",
      "Precision = 0.499, Recall = 0.500\n",
      "================================\n",
      "ROC AUC Score = 0.607\n",
      "200000/200000 [==============================] - 6s 28us/step\n",
      "--------test---------\n",
      "================================\n",
      "Confusion Matrix:\n",
      "True Negative = 199623\n",
      "False Negative = 377\n",
      "True Positive = 0\n",
      "False Positive = 0\n",
      "================================\n",
      "f1 score = 0.000\n",
      "================================\n",
      "Precision = 0.499, Recall = 0.500\n",
      "================================\n",
      "ROC AUC Score = 0.614\n",
      "200000/200000 [==============================] - 6s 29us/step\n",
      "--------test---------\n",
      "================================\n",
      "Confusion Matrix:\n",
      "True Negative = 199623\n",
      "False Negative = 377\n",
      "True Positive = 0\n",
      "False Positive = 0\n",
      "================================\n",
      "f1 score = 0.000\n",
      "================================\n",
      "Precision = 0.499, Recall = 0.500\n",
      "================================\n",
      "ROC AUC Score = 0.630\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'predicted_test_labels' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-66-d78115fe7b22>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpredicted_test_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_batched_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpredicted_test_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.5\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted_test_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted_test_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'predicted_test_labels' is not defined"
     ]
    }
   ],
   "source": [
    "predicted_test_scores = predict_batched_models(models, test_features, test_labels)\n",
    "predicted_test_labels = map(lambda s: 1 if s > 0.5 else 0, predicted_test_scores)\n",
    "\n",
    "print_metrics(test_labels, predicted_test_labels, is_train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800000/800000 [==============================] - 19s 24us/step\n",
      "--------train---------\n",
      "================================\n",
      "Confusion Matrix:\n",
      "True Negative = 738988\n",
      "False Negative = 1214\n",
      "True Positive = 317\n",
      "False Positive = 59481\n",
      "================================\n",
      "f1 score = 0.010\n",
      "================================\n",
      "Precision = 0.502, Recall = 0.566\n",
      "================================\n",
      "ROC AUC Score = 0.668\n",
      "200000/200000 [==============================] - 5s 24us/step\n",
      "--------test---------\n",
      "================================\n",
      "Confusion Matrix:\n",
      "True Negative = 184489\n",
      "False Negative = 299\n",
      "True Positive = 78\n",
      "False Positive = 15134\n",
      "================================\n",
      "f1 score = 0.010\n",
      "================================\n",
      "Precision = 0.502, Recall = 0.566\n",
      "================================\n",
      "ROC AUC Score = 0.664\n"
     ]
    }
   ],
   "source": [
    "train_preds = model.predict(features, verbose=1) \n",
    "print_metrics(labels, train_preds, is_train=True)\n",
    "\n",
    "test_preds = model.predict(test_features, verbose=1)\n",
    "print_metrics(test_labels, test_preds, is_train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200000, 2)\n",
      "[0.36920437 0.44836164 0.3320884 ]\n",
      "[0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(test_preds.shape)\n",
    "print(test_preds[0:3:,1])\n",
    "print(test_preds[0:3].argmax(axis=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'positive_samples' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-67-0c94a27f4a2b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpositive_samples\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'positive_samples' is not defined"
     ]
    }
   ],
   "source": [
    "gen_batches(features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
