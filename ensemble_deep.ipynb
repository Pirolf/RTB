{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import numpy as np\n",
    "from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
    "from imblearn.under_sampling import NearMiss, RandomUnderSampler\n",
    "from imblearn.combine import SMOTEENN,SMOTETomek\n",
    "from imblearn.ensemble import BalanceCascade, EasyEnsemble\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import h5py\n",
    "import keras\n",
    "from sklearn.utils import class_weight\n",
    "from keras.utils import to_categorical\n",
    "from keras.optimizers import *\n",
    "from keras.regularizers import *\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, f1_score, precision_recall_fscore_support\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "KFOLD_SEED = 42\n",
    "\n",
    "def keras_confusion_matrix(test_labels_1d, predicted_labels):\n",
    "    m = confusion_matrix(test_labels_1d, predicted_labels)\n",
    "\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(\"True Negative = %d\" % m[0][0])\n",
    "    print(\"False Negative = %d\" % m[1][0])\n",
    "    print(\"True Positive = %d\" % m[1][1])\n",
    "    print(\"False Positive = %d\" % m[0][1])\n",
    "    \n",
    "\n",
    "def keras_f1_score(test_labels_1d, predicted_labels):\n",
    "    f = f1_score(test_labels_1d, predicted_labels)\n",
    "    print(\"f1 score = %0.3f\" % f)\n",
    "\n",
    "\n",
    "def print_metrics(test_labels_1d, y_scores, is_train=False):\n",
    "    predicted_labels = y_scores.argmax(axis=-1)\n",
    "    if is_train:\n",
    "        print(\"---------train---------\")\n",
    "    else:\n",
    "        print(\"---------test---------\")\n",
    "    \n",
    "    keras_confusion_matrix(test_labels_1d, predicted_labels)\n",
    "    keras_f1_score(test_labels_1d, predicted_labels)\n",
    "    print(\"ROC Score = %0.3f\" % roc_auc_score(test_labels_1d, predicted_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000000, 89)\n"
     ]
    }
   ],
   "source": [
    "input_path = '~/data/biddings.csv'\n",
    "data = pd.read_csv(input_path)\n",
    "print(data.shape)\n",
    "\n",
    "train = data[:800000]\n",
    "test = data[800000:]\n",
    "\n",
    "sample = train.sample(frac=1)\n",
    "features = sample.drop('convert', axis=1).values\n",
    "labels = sample.convert.ravel()\n",
    "categorical_labels = to_categorical(sample.convert.ravel(), 2)\n",
    "\n",
    "test_features = test.drop('convert', axis=1).values\n",
    "test_labels = test.convert.ravel()\n",
    "categorical_test_labels = to_categorical(test.convert.ravel(), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier(max_features=0.2, random_state=KFOLD_SEED)\n",
    "bc = BalanceCascade(estimator=dt, n_max_subset=10, random_state=KFOLD_SEED)\n",
    "\n",
    "def deep_ensemble(model_fn, model_fit_fn, ensembler, smote=None):\n",
    "    print(\"fitting sample\")\n",
    "    X_res, y_res = ensembler.fit_sample(features, labels)\n",
    "    print(X_res.shape, y_res.shape)\n",
    "    \n",
    "    model = model_fn()\n",
    "    print(\"training\")\n",
    "\n",
    "    for j, X_train in enumerate(X_res):\n",
    "        if smote is not None:\n",
    "            X, y = smote.fit_sample(X_train, y_res[j])\n",
    "            y = to_categorical(y, 2)\n",
    "            model = model_fit_fn(model, X, y)\n",
    "        else:\n",
    "            y = to_categorical(y_res[j], 2)\n",
    "            model = model_fit_fn(model, X_train, y)\n",
    "\n",
    "    predicted_scores = model.predict(test_features, verbose=1)\n",
    "    print(predicted_scores.shape)\n",
    "    print_metrics(test_labels, predicted_scores, is_train=False)\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Neural Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "epochs = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bare minimum: 0.644 <br>\n",
    "10 Epochs: 0.655 <br>\n",
    "With l2(0.01): 0.660"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting sample\n",
      "(10, 3062, 88) (10, 3062, 2)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_23 (Dense)             (None, 88)                7832      \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 2)                 178       \n",
      "=================================================================\n",
      "Total params: 8,010\n",
      "Trainable params: 8,010\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "training\n",
      "Epoch 1/10\n",
      "3062/3062 [==============================] - 1s 238us/step - loss: 0.7281 - acc: 0.5993\n",
      "Epoch 2/10\n",
      "3062/3062 [==============================] - 0s 113us/step - loss: 0.6580 - acc: 0.6306\n",
      "Epoch 3/10\n",
      "3062/3062 [==============================] - 0s 110us/step - loss: 0.6549 - acc: 0.6283\n",
      "Epoch 4/10\n",
      "3062/3062 [==============================] - 0s 109us/step - loss: 0.6514 - acc: 0.6290\n",
      "Epoch 5/10\n",
      "3062/3062 [==============================] - 0s 104us/step - loss: 0.6490 - acc: 0.6349\n",
      "Epoch 6/10\n",
      "3062/3062 [==============================] - 0s 114us/step - loss: 0.6501 - acc: 0.6274\n",
      "Epoch 7/10\n",
      "3062/3062 [==============================] - 0s 129us/step - loss: 0.6490 - acc: 0.6336\n",
      "Epoch 8/10\n",
      "3062/3062 [==============================] - 0s 118us/step - loss: 0.6472 - acc: 0.6329\n",
      "Epoch 9/10\n",
      "3062/3062 [==============================] - 0s 112us/step - loss: 0.6498 - acc: 0.6342\n",
      "Epoch 10/10\n",
      "3062/3062 [==============================] - 0s 104us/step - loss: 0.6447 - acc: 0.6352\n",
      "Epoch 1/10\n",
      "3062/3062 [==============================] - 0s 102us/step - loss: 0.6396 - acc: 0.6368\n",
      "Epoch 2/10\n",
      "3062/3062 [==============================] - 0s 108us/step - loss: 0.6341 - acc: 0.6440\n",
      "Epoch 3/10\n",
      "3062/3062 [==============================] - 0s 109us/step - loss: 0.6335 - acc: 0.6368\n",
      "Epoch 4/10\n",
      "3062/3062 [==============================] - 0s 91us/step - loss: 0.6332 - acc: 0.6421\n",
      "Epoch 5/10\n",
      "3062/3062 [==============================] - 0s 97us/step - loss: 0.6323 - acc: 0.6362\n",
      "Epoch 6/10\n",
      "3062/3062 [==============================] - 0s 112us/step - loss: 0.6334 - acc: 0.6359\n",
      "Epoch 7/10\n",
      "3062/3062 [==============================] - 0s 114us/step - loss: 0.6331 - acc: 0.6408\n",
      "Epoch 8/10\n",
      "3062/3062 [==============================] - 0s 94us/step - loss: 0.6311 - acc: 0.6375\n",
      "Epoch 9/10\n",
      "3062/3062 [==============================] - 0s 112us/step - loss: 0.6318 - acc: 0.6434\n",
      "Epoch 10/10\n",
      "3062/3062 [==============================] - 0s 117us/step - loss: 0.6324 - acc: 0.6417\n",
      "Epoch 1/10\n",
      "3062/3062 [==============================] - 0s 116us/step - loss: 0.6456 - acc: 0.6303\n",
      "Epoch 2/10\n",
      "3062/3062 [==============================] - 0s 109us/step - loss: 0.6371 - acc: 0.6329\n",
      "Epoch 3/10\n",
      "3062/3062 [==============================] - 0s 120us/step - loss: 0.6374 - acc: 0.6372\n",
      "Epoch 4/10\n",
      "3062/3062 [==============================] - 0s 110us/step - loss: 0.6368 - acc: 0.6355\n",
      "Epoch 5/10\n",
      "3062/3062 [==============================] - 0s 110us/step - loss: 0.6336 - acc: 0.6362\n",
      "Epoch 6/10\n",
      "3062/3062 [==============================] - 0s 114us/step - loss: 0.6360 - acc: 0.6352\n",
      "Epoch 7/10\n",
      "3062/3062 [==============================] - 0s 120us/step - loss: 0.6342 - acc: 0.6319\n",
      "Epoch 8/10\n",
      "3062/3062 [==============================] - 0s 98us/step - loss: 0.6341 - acc: 0.6375\n",
      "Epoch 9/10\n",
      "3062/3062 [==============================] - 0s 111us/step - loss: 0.6321 - acc: 0.6411\n",
      "Epoch 10/10\n",
      "3062/3062 [==============================] - 0s 113us/step - loss: 0.6350 - acc: 0.6319\n",
      "Epoch 1/10\n",
      "3062/3062 [==============================] - 0s 118us/step - loss: 0.6410 - acc: 0.6404\n",
      "Epoch 2/10\n",
      "3062/3062 [==============================] - 0s 107us/step - loss: 0.6353 - acc: 0.6444\n",
      "Epoch 3/10\n",
      "3062/3062 [==============================] - 0s 103us/step - loss: 0.6317 - acc: 0.6375\n",
      "Epoch 4/10\n",
      "3062/3062 [==============================] - 0s 88us/step - loss: 0.6332 - acc: 0.6391\n",
      "Epoch 5/10\n",
      "3062/3062 [==============================] - 0s 121us/step - loss: 0.6320 - acc: 0.6375\n",
      "Epoch 6/10\n",
      "3062/3062 [==============================] - 0s 115us/step - loss: 0.6306 - acc: 0.6444\n",
      "Epoch 7/10\n",
      "3062/3062 [==============================] - 0s 106us/step - loss: 0.6316 - acc: 0.6398\n",
      "Epoch 8/10\n",
      "3062/3062 [==============================] - 0s 115us/step - loss: 0.6320 - acc: 0.6365\n",
      "Epoch 9/10\n",
      "3062/3062 [==============================] - ETA: 0s - loss: 0.6350 - acc: 0.635 - 0s 116us/step - loss: 0.6312 - acc: 0.6391\n",
      "Epoch 10/10\n",
      "3062/3062 [==============================] - 0s 118us/step - loss: 0.6316 - acc: 0.6473\n",
      "Epoch 1/10\n",
      "3062/3062 [==============================] - 0s 107us/step - loss: 0.6438 - acc: 0.6297\n",
      "Epoch 2/10\n",
      "3062/3062 [==============================] - 0s 106us/step - loss: 0.6388 - acc: 0.6297\n",
      "Epoch 3/10\n",
      "3062/3062 [==============================] - 0s 108us/step - loss: 0.6365 - acc: 0.6372\n",
      "Epoch 4/10\n",
      "3062/3062 [==============================] - 0s 110us/step - loss: 0.6364 - acc: 0.6352\n",
      "Epoch 5/10\n",
      "3062/3062 [==============================] - 0s 121us/step - loss: 0.6358 - acc: 0.6332\n",
      "Epoch 6/10\n",
      "3062/3062 [==============================] - 0s 124us/step - loss: 0.6334 - acc: 0.6460\n",
      "Epoch 7/10\n",
      "3062/3062 [==============================] - 0s 119us/step - loss: 0.6334 - acc: 0.6414\n",
      "Epoch 8/10\n",
      "3062/3062 [==============================] - 0s 115us/step - loss: 0.6354 - acc: 0.6355\n",
      "Epoch 9/10\n",
      "3062/3062 [==============================] - 0s 121us/step - loss: 0.6344 - acc: 0.6362\n",
      "Epoch 10/10\n",
      "3062/3062 [==============================] - 0s 104us/step - loss: 0.6343 - acc: 0.6297\n",
      "Epoch 1/10\n",
      "3062/3062 [==============================] - 0s 109us/step - loss: 0.6366 - acc: 0.6303\n",
      "Epoch 2/10\n",
      "3062/3062 [==============================] - 0s 104us/step - loss: 0.6319 - acc: 0.6385\n",
      "Epoch 3/10\n",
      "3062/3062 [==============================] - 0s 113us/step - loss: 0.6310 - acc: 0.6447\n",
      "Epoch 4/10\n",
      "3062/3062 [==============================] - 0s 116us/step - loss: 0.6302 - acc: 0.6476\n",
      "Epoch 5/10\n",
      "3062/3062 [==============================] - 0s 106us/step - loss: 0.6301 - acc: 0.6401\n",
      "Epoch 6/10\n",
      "3062/3062 [==============================] - 0s 101us/step - loss: 0.6297 - acc: 0.6470\n",
      "Epoch 7/10\n",
      "3062/3062 [==============================] - 0s 114us/step - loss: 0.6297 - acc: 0.6473\n",
      "Epoch 8/10\n",
      "3062/3062 [==============================] - 0s 123us/step - loss: 0.6300 - acc: 0.6427\n",
      "Epoch 9/10\n",
      "3062/3062 [==============================] - 0s 119us/step - loss: 0.6293 - acc: 0.6463\n",
      "Epoch 10/10\n",
      "3062/3062 [==============================] - 0s 115us/step - loss: 0.6282 - acc: 0.6408\n",
      "Epoch 1/10\n",
      "3062/3062 [==============================] - 0s 111us/step - loss: 0.6415 - acc: 0.6306\n",
      "Epoch 2/10\n",
      "3062/3062 [==============================] - 0s 118us/step - loss: 0.6373 - acc: 0.6378\n",
      "Epoch 3/10\n",
      "3062/3062 [==============================] - 0s 111us/step - loss: 0.6357 - acc: 0.6411\n",
      "Epoch 4/10\n",
      "3062/3062 [==============================] - 0s 110us/step - loss: 0.6358 - acc: 0.6401\n",
      "Epoch 5/10\n",
      "3062/3062 [==============================] - 0s 109us/step - loss: 0.6349 - acc: 0.6404\n",
      "Epoch 6/10\n",
      "3062/3062 [==============================] - 0s 94us/step - loss: 0.6357 - acc: 0.6450\n",
      "Epoch 7/10\n",
      "3062/3062 [==============================] - 0s 103us/step - loss: 0.6359 - acc: 0.6362\n",
      "Epoch 8/10\n",
      "3062/3062 [==============================] - 0s 117us/step - loss: 0.6344 - acc: 0.6424\n",
      "Epoch 9/10\n",
      "3062/3062 [==============================] - 0s 112us/step - loss: 0.6353 - acc: 0.6352\n",
      "Epoch 10/10\n",
      "3062/3062 [==============================] - 0s 113us/step - loss: 0.6357 - acc: 0.6427\n",
      "Epoch 1/10\n",
      "3062/3062 [==============================] - 0s 98us/step - loss: 0.6413 - acc: 0.6316\n",
      "Epoch 2/10\n",
      "3062/3062 [==============================] - 0s 112us/step - loss: 0.6389 - acc: 0.6319\n",
      "Epoch 3/10\n",
      "3062/3062 [==============================] - 0s 119us/step - loss: 0.6373 - acc: 0.6332\n",
      "Epoch 4/10\n",
      "3062/3062 [==============================] - 0s 116us/step - loss: 0.6380 - acc: 0.6385\n",
      "Epoch 5/10\n",
      "3062/3062 [==============================] - 0s 120us/step - loss: 0.6360 - acc: 0.6388\n",
      "Epoch 6/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3062/3062 [==============================] - 0s 87us/step - loss: 0.6365 - acc: 0.6434\n",
      "Epoch 7/10\n",
      "3062/3062 [==============================] - 0s 101us/step - loss: 0.6359 - acc: 0.6342\n",
      "Epoch 8/10\n",
      "3062/3062 [==============================] - 0s 95us/step - loss: 0.6367 - acc: 0.6359\n",
      "Epoch 9/10\n",
      "3062/3062 [==============================] - 0s 110us/step - loss: 0.6358 - acc: 0.6427\n",
      "Epoch 10/10\n",
      "3062/3062 [==============================] - 0s 112us/step - loss: 0.6358 - acc: 0.6411\n",
      "Epoch 1/10\n",
      "3062/3062 [==============================] - 0s 113us/step - loss: 0.6329 - acc: 0.6381\n",
      "Epoch 2/10\n",
      "3062/3062 [==============================] - 0s 117us/step - loss: 0.6277 - acc: 0.6444\n",
      "Epoch 3/10\n",
      "3062/3062 [==============================] - 0s 99us/step - loss: 0.6268 - acc: 0.6499\n",
      "Epoch 4/10\n",
      "3062/3062 [==============================] - 0s 97us/step - loss: 0.6291 - acc: 0.6453\n",
      "Epoch 5/10\n",
      "3062/3062 [==============================] - 0s 111us/step - loss: 0.6290 - acc: 0.6463\n",
      "Epoch 6/10\n",
      "3062/3062 [==============================] - 0s 115us/step - loss: 0.6277 - acc: 0.6479\n",
      "Epoch 7/10\n",
      "3062/3062 [==============================] - 0s 107us/step - loss: 0.6264 - acc: 0.6460\n",
      "Epoch 8/10\n",
      "3062/3062 [==============================] - 0s 110us/step - loss: 0.6269 - acc: 0.6535\n",
      "Epoch 9/10\n",
      "3062/3062 [==============================] - 0s 121us/step - loss: 0.6269 - acc: 0.6440\n",
      "Epoch 10/10\n",
      "3062/3062 [==============================] - 0s 109us/step - loss: 0.6273 - acc: 0.6515\n",
      "Epoch 1/10\n",
      "3062/3062 [==============================] - 0s 103us/step - loss: 0.6371 - acc: 0.6434\n",
      "Epoch 2/10\n",
      "3062/3062 [==============================] - 0s 108us/step - loss: 0.6340 - acc: 0.6385\n",
      "Epoch 3/10\n",
      "3062/3062 [==============================] - 0s 114us/step - loss: 0.6325 - acc: 0.6381\n",
      "Epoch 4/10\n",
      "3062/3062 [==============================] - 0s 106us/step - loss: 0.6335 - acc: 0.6372\n",
      "Epoch 5/10\n",
      "3062/3062 [==============================] - 0s 102us/step - loss: 0.6325 - acc: 0.6417\n",
      "Epoch 6/10\n",
      "3062/3062 [==============================] - 0s 130us/step - loss: 0.6326 - acc: 0.6411\n",
      "Epoch 7/10\n",
      "3062/3062 [==============================] - 0s 117us/step - loss: 0.6323 - acc: 0.6391\n",
      "Epoch 8/10\n",
      "3062/3062 [==============================] - 0s 104us/step - loss: 0.6318 - acc: 0.6401\n",
      "Epoch 9/10\n",
      "3062/3062 [==============================] - 0s 108us/step - loss: 0.6312 - acc: 0.6483\n",
      "Epoch 10/10\n",
      "3062/3062 [==============================] - 0s 98us/step - loss: 0.6321 - acc: 0.6385\n",
      "200000/200000 [==============================] - 4s 22us/step\n",
      "(200000, 2)\n",
      "---------test---------\n",
      "Confusion Matrix:\n",
      "True Negative = 128160\n",
      "False Negative = 125\n",
      "True Positive = 252\n",
      "False Positive = 71463\n",
      "f1 score = 0.007\n",
      "ROC Score = 0.655\n"
     ]
    }
   ],
   "source": [
    "def base_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(88, kernel_initializer='glorot_uniform', input_shape=(88,)))\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=SGD(lr=0.01),\n",
    "                  metrics=['accuracy'])\n",
    "    return model;\n",
    "\n",
    "def model_fit(model, X, y):\n",
    "    model.fit(X, y,\n",
    "              batch_size=batch_size,\n",
    "              epochs=10,\n",
    "#               validation_split=0.2,\n",
    "              verbose=1)\n",
    "    return model\n",
    "\n",
    "model = deep_ensemble(base_model, model_fit, bc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With validation split, we can see that there is overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting sample\n",
      "(10, 3062, 88) (10, 3062, 2)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_29 (Dense)             (None, 88)                7832      \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 2)                 178       \n",
      "=================================================================\n",
      "Total params: 8,010\n",
      "Trainable params: 8,010\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "training\n",
      "Epoch 1/10\n",
      "3062/3062 [==============================] - 1s 217us/step - loss: 1.7448 - acc: 0.5438\n",
      "Epoch 2/10\n",
      "3062/3062 [==============================] - 0s 115us/step - loss: 1.6180 - acc: 0.5813\n",
      "Epoch 3/10\n",
      "3062/3062 [==============================] - 0s 110us/step - loss: 1.5726 - acc: 0.5960\n",
      "Epoch 4/10\n",
      "3062/3062 [==============================] - 0s 113us/step - loss: 1.5426 - acc: 0.6029\n",
      "Epoch 5/10\n",
      "3062/3062 [==============================] - 0s 110us/step - loss: 1.5200 - acc: 0.6140\n",
      "Epoch 6/10\n",
      "3062/3062 [==============================] - 0s 118us/step - loss: 1.5024 - acc: 0.6238\n",
      "Epoch 7/10\n",
      "3062/3062 [==============================] - 0s 127us/step - loss: 1.4877 - acc: 0.6274\n",
      "Epoch 8/10\n",
      "3062/3062 [==============================] - 0s 117us/step - loss: 1.4758 - acc: 0.6310\n",
      "Epoch 9/10\n",
      "3062/3062 [==============================] - 0s 92us/step - loss: 1.4648 - acc: 0.6362\n",
      "Epoch 10/10\n",
      "3062/3062 [==============================] - 0s 111us/step - loss: 1.4555 - acc: 0.6378\n",
      "Epoch 1/10\n",
      "3062/3062 [==============================] - 0s 117us/step - loss: 1.4578 - acc: 0.6270\n",
      "Epoch 2/10\n",
      "3062/3062 [==============================] - 0s 112us/step - loss: 1.4442 - acc: 0.6339\n",
      "Epoch 3/10\n",
      "3062/3062 [==============================] - 0s 110us/step - loss: 1.4334 - acc: 0.6359\n",
      "Epoch 4/10\n",
      "3062/3062 [==============================] - 0s 110us/step - loss: 1.4238 - acc: 0.6408\n",
      "Epoch 5/10\n",
      "3062/3062 [==============================] - 0s 116us/step - loss: 1.4150 - acc: 0.6434\n",
      "Epoch 6/10\n",
      "3062/3062 [==============================] - 0s 116us/step - loss: 1.4070 - acc: 0.6437\n",
      "Epoch 7/10\n",
      "3062/3062 [==============================] - 0s 112us/step - loss: 1.3994 - acc: 0.6492\n",
      "Epoch 8/10\n",
      "3062/3062 [==============================] - 0s 101us/step - loss: 1.3924 - acc: 0.6499\n",
      "Epoch 9/10\n",
      "3062/3062 [==============================] - 0s 115us/step - loss: 1.3856 - acc: 0.6453\n",
      "Epoch 10/10\n",
      "3062/3062 [==============================] - 0s 115us/step - loss: 1.3789 - acc: 0.6473\n",
      "Epoch 1/10\n",
      "3062/3062 [==============================] - 0s 119us/step - loss: 1.3851 - acc: 0.6391\n",
      "Epoch 2/10\n",
      "3062/3062 [==============================] - 0s 108us/step - loss: 1.3762 - acc: 0.6440\n",
      "Epoch 3/10\n",
      "3062/3062 [==============================] - 0s 112us/step - loss: 1.3681 - acc: 0.6411\n",
      "Epoch 4/10\n",
      "3062/3062 [==============================] - 0s 104us/step - loss: 1.3609 - acc: 0.6450\n",
      "Epoch 5/10\n",
      "3062/3062 [==============================] - 0s 108us/step - loss: 1.3545 - acc: 0.6434\n",
      "Epoch 6/10\n",
      "3062/3062 [==============================] - 0s 124us/step - loss: 1.3481 - acc: 0.6450\n",
      "Epoch 7/10\n",
      "3062/3062 [==============================] - 0s 103us/step - loss: 1.3416 - acc: 0.6486\n",
      "Epoch 8/10\n",
      "3062/3062 [==============================] - 0s 117us/step - loss: 1.3361 - acc: 0.6466\n",
      "Epoch 9/10\n",
      "3062/3062 [==============================] - 0s 110us/step - loss: 1.3300 - acc: 0.6411\n",
      "Epoch 10/10\n",
      "3062/3062 [==============================] - 0s 111us/step - loss: 1.3244 - acc: 0.6509\n",
      "Epoch 1/10\n",
      "3062/3062 [==============================] - 0s 114us/step - loss: 1.3254 - acc: 0.6430\n",
      "Epoch 2/10\n",
      "3062/3062 [==============================] - 0s 97us/step - loss: 1.3172 - acc: 0.6450\n",
      "Epoch 3/10\n",
      "3062/3062 [==============================] - 0s 119us/step - loss: 1.3104 - acc: 0.6489\n",
      "Epoch 4/10\n",
      "3062/3062 [==============================] - 0s 110us/step - loss: 1.3041 - acc: 0.6499\n",
      "Epoch 5/10\n",
      "3062/3062 [==============================] - 0s 116us/step - loss: 1.2979 - acc: 0.6473\n",
      "Epoch 6/10\n",
      "3062/3062 [==============================] - 0s 116us/step - loss: 1.2926 - acc: 0.6512\n",
      "Epoch 7/10\n",
      "3062/3062 [==============================] - 0s 122us/step - loss: 1.2869 - acc: 0.6509\n",
      "Epoch 8/10\n",
      "3062/3062 [==============================] - 0s 118us/step - loss: 1.2814 - acc: 0.6535\n",
      "Epoch 9/10\n",
      "3062/3062 [==============================] - 0s 115us/step - loss: 1.2760 - acc: 0.6509\n",
      "Epoch 10/10\n",
      "3062/3062 [==============================] - 0s 113us/step - loss: 1.2709 - acc: 0.6515\n",
      "Epoch 1/10\n",
      "3062/3062 [==============================] - 0s 102us/step - loss: 1.2773 - acc: 0.6391\n",
      "Epoch 2/10\n",
      "3062/3062 [==============================] - 0s 97us/step - loss: 1.2691 - acc: 0.6440\n",
      "Epoch 3/10\n",
      "3062/3062 [==============================] - 0s 91us/step - loss: 1.2625 - acc: 0.6492\n",
      "Epoch 4/10\n",
      "3062/3062 [==============================] - 0s 87us/step - loss: 1.2564 - acc: 0.6450\n",
      "Epoch 5/10\n",
      "3062/3062 [==============================] - 0s 116us/step - loss: 1.2509 - acc: 0.6492\n",
      "Epoch 6/10\n",
      "3062/3062 [==============================] - 0s 97us/step - loss: 1.2455 - acc: 0.6447\n",
      "Epoch 7/10\n",
      "3062/3062 [==============================] - 0s 107us/step - loss: 1.2404 - acc: 0.6515\n",
      "Epoch 8/10\n",
      "3062/3062 [==============================] - 0s 111us/step - loss: 1.2354 - acc: 0.6502\n",
      "Epoch 9/10\n",
      "3062/3062 [==============================] - 0s 116us/step - loss: 1.2304 - acc: 0.6479\n",
      "Epoch 10/10\n",
      "3062/3062 [==============================] - 0s 115us/step - loss: 1.2255 - acc: 0.6499\n",
      "Epoch 1/10\n",
      "3062/3062 [==============================] - 0s 114us/step - loss: 1.2245 - acc: 0.6401\n",
      "Epoch 2/10\n",
      "3062/3062 [==============================] - 0s 113us/step - loss: 1.2174 - acc: 0.6430\n",
      "Epoch 3/10\n",
      "3062/3062 [==============================] - 0s 109us/step - loss: 1.2112 - acc: 0.6437\n",
      "Epoch 4/10\n",
      "3062/3062 [==============================] - 0s 115us/step - loss: 1.2056 - acc: 0.6470\n",
      "Epoch 5/10\n",
      "3062/3062 [==============================] - 0s 124us/step - loss: 1.2005 - acc: 0.6473\n",
      "Epoch 6/10\n",
      "3062/3062 [==============================] - 0s 115us/step - loss: 1.1956 - acc: 0.6486\n",
      "Epoch 7/10\n",
      "3062/3062 [==============================] - 0s 106us/step - loss: 1.1907 - acc: 0.6502\n",
      "Epoch 8/10\n",
      "3062/3062 [==============================] - 0s 119us/step - loss: 1.1861 - acc: 0.6509\n",
      "Epoch 9/10\n",
      "3062/3062 [==============================] - 0s 130us/step - loss: 1.1816 - acc: 0.6525\n",
      "Epoch 10/10\n",
      "3062/3062 [==============================] - 0s 112us/step - loss: 1.1771 - acc: 0.6515\n",
      "Epoch 1/10\n",
      "3062/3062 [==============================] - 0s 102us/step - loss: 1.1906 - acc: 0.6372\n",
      "Epoch 2/10\n",
      "3062/3062 [==============================] - 0s 113us/step - loss: 1.1823 - acc: 0.6372\n",
      "Epoch 3/10\n",
      "3062/3062 [==============================] - 0s 94us/step - loss: 1.1755 - acc: 0.6398\n",
      "Epoch 4/10\n",
      "3062/3062 [==============================] - 0s 112us/step - loss: 1.1691 - acc: 0.6437\n",
      "Epoch 5/10\n",
      "3062/3062 [==============================] - 0s 132us/step - loss: 1.1635 - acc: 0.6430\n",
      "Epoch 6/10\n",
      "3062/3062 [==============================] - 0s 109us/step - loss: 1.1590 - acc: 0.6463\n",
      "Epoch 7/10\n",
      "3062/3062 [==============================] - 0s 114us/step - loss: 1.1545 - acc: 0.6476\n",
      "Epoch 8/10\n",
      "3062/3062 [==============================] - 0s 123us/step - loss: 1.1502 - acc: 0.6479\n",
      "Epoch 9/10\n",
      "3062/3062 [==============================] - 0s 105us/step - loss: 1.1459 - acc: 0.6466\n",
      "Epoch 10/10\n",
      "3062/3062 [==============================] - 0s 96us/step - loss: 1.1419 - acc: 0.6470\n",
      "Epoch 1/10\n",
      "3062/3062 [==============================] - 0s 98us/step - loss: 1.1457 - acc: 0.6368\n",
      "Epoch 2/10\n",
      "3062/3062 [==============================] - 0s 110us/step - loss: 1.1398 - acc: 0.6414\n",
      "Epoch 3/10\n",
      "3062/3062 [==============================] - 0s 115us/step - loss: 1.1348 - acc: 0.6421\n",
      "Epoch 4/10\n",
      "3062/3062 [==============================] - 0s 122us/step - loss: 1.1300 - acc: 0.6437\n",
      "Epoch 5/10\n",
      "3062/3062 [==============================] - 0s 107us/step - loss: 1.1255 - acc: 0.6450\n",
      "Epoch 6/10\n",
      "3062/3062 [==============================] - 0s 100us/step - loss: 1.1211 - acc: 0.6483\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3062/3062 [==============================] - 0s 116us/step - loss: 1.1171 - acc: 0.6463\n",
      "Epoch 8/10\n",
      "3062/3062 [==============================] - 0s 109us/step - loss: 1.1132 - acc: 0.6457\n",
      "Epoch 9/10\n",
      "3062/3062 [==============================] - 0s 109us/step - loss: 1.1090 - acc: 0.6457\n",
      "Epoch 10/10\n",
      "3062/3062 [==============================] - 0s 101us/step - loss: 1.1051 - acc: 0.6457\n",
      "Epoch 1/10\n",
      "3062/3062 [==============================] - 0s 119us/step - loss: 1.0987 - acc: 0.6444\n",
      "Epoch 2/10\n",
      "3062/3062 [==============================] - 0s 119us/step - loss: 1.0929 - acc: 0.6496\n",
      "Epoch 3/10\n",
      "3062/3062 [==============================] - 0s 113us/step - loss: 1.0878 - acc: 0.6483\n",
      "Epoch 4/10\n",
      "3062/3062 [==============================] - 0s 113us/step - loss: 1.0833 - acc: 0.6545\n",
      "Epoch 5/10\n",
      "3062/3062 [==============================] - 0s 110us/step - loss: 1.0792 - acc: 0.6564\n",
      "Epoch 6/10\n",
      "3062/3062 [==============================] - 0s 107us/step - loss: 1.0753 - acc: 0.6571\n",
      "Epoch 7/10\n",
      "3062/3062 [==============================] - 0s 95us/step - loss: 1.0714 - acc: 0.6564\n",
      "Epoch 8/10\n",
      "3062/3062 [==============================] - 0s 112us/step - loss: 1.0677 - acc: 0.6568\n",
      "Epoch 9/10\n",
      "3062/3062 [==============================] - 0s 103us/step - loss: 1.0641 - acc: 0.6584\n",
      "Epoch 10/10\n",
      "3062/3062 [==============================] - 0s 112us/step - loss: 1.0605 - acc: 0.6571\n",
      "Epoch 1/10\n",
      "3062/3062 [==============================] - 0s 115us/step - loss: 1.0695 - acc: 0.6463\n",
      "Epoch 2/10\n",
      "3062/3062 [==============================] - 0s 109us/step - loss: 1.0638 - acc: 0.6463\n",
      "Epoch 3/10\n",
      "3062/3062 [==============================] - 0s 111us/step - loss: 1.0590 - acc: 0.6440\n",
      "Epoch 4/10\n",
      "3062/3062 [==============================] - 0s 95us/step - loss: 1.0547 - acc: 0.6434\n",
      "Epoch 5/10\n",
      "3062/3062 [==============================] - 0s 113us/step - loss: 1.0505 - acc: 0.6450\n",
      "Epoch 6/10\n",
      "3062/3062 [==============================] - 0s 116us/step - loss: 1.0469 - acc: 0.6444\n",
      "Epoch 7/10\n",
      "3062/3062 [==============================] - 0s 113us/step - loss: 1.0432 - acc: 0.6499\n",
      "Epoch 8/10\n",
      "3062/3062 [==============================] - 0s 113us/step - loss: 1.0398 - acc: 0.6473\n",
      "Epoch 9/10\n",
      "3062/3062 [==============================] - 0s 106us/step - loss: 1.0364 - acc: 0.6453\n",
      "Epoch 10/10\n",
      "3062/3062 [==============================] - 0s 115us/step - loss: 1.0330 - acc: 0.6453\n",
      "200000/200000 [==============================] - 4s 22us/step\n",
      "(200000, 2)\n",
      "---------test---------\n",
      "Confusion Matrix:\n",
      "True Negative = 129023\n",
      "False Negative = 123\n",
      "True Positive = 254\n",
      "False Positive = 70600\n",
      "f1 score = 0.007\n",
      "ROC Score = 0.660\n"
     ]
    }
   ],
   "source": [
    "def base_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(88, kernel_initializer='glorot_uniform', kernel_regularizer=l2(0.01),\n",
    "                    input_shape=(88,)))\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=SGD(lr=0.01),\n",
    "                  metrics=['accuracy'])\n",
    "    return model;\n",
    "\n",
    "def model_fit(model, X, y):\n",
    "    model.fit(X, y,\n",
    "              batch_size=batch_size,\n",
    "              epochs=10,\n",
    "#               validation_split=0.2,\n",
    "              verbose=1)\n",
    "    return model\n",
    "\n",
    "model = deep_ensemble(base_model, model_fit, bc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting sample\n",
      "(10, 3062, 88) (10, 3062)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_52 (Dense)             (None, 88)                7832      \n",
      "_________________________________________________________________\n",
      "dense_53 (Dense)             (None, 64)                5696      \n",
      "_________________________________________________________________\n",
      "dense_54 (Dense)             (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 13,658\n",
      "Trainable params: 13,658\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.local/share/virtualenvs/RTB-V2Lvgo6A/lib/python3.5/site-packages/imblearn/utils/validation.py:224: UserWarning: After over-sampling, the number of samples (10000) in class 0 will be larger than the number of samples in the majority class (class #0 -> 1531)\n",
      "  n_samples_majority))\n",
      "/root/.local/share/virtualenvs/RTB-V2Lvgo6A/lib/python3.5/site-packages/imblearn/utils/validation.py:224: UserWarning: After over-sampling, the number of samples (10000) in class 1 will be larger than the number of samples in the majority class (class #0 -> 1531)\n",
      "  n_samples_majority))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16000 samples, validate on 4000 samples\n",
      "Epoch 1/10\n",
      "16000/16000 [==============================] - 3s 176us/step - loss: 5.1488 - acc: 0.6694 - val_loss: 2.8621 - val_acc: 0.3345\n",
      "Epoch 2/10\n",
      "16000/16000 [==============================] - 2s 133us/step - loss: 1.4709 - acc: 0.6796 - val_loss: 1.3298 - val_acc: 0.2157\n",
      "Epoch 3/10\n",
      "16000/16000 [==============================] - 2s 133us/step - loss: 0.9266 - acc: 0.6662 - val_loss: 1.1430 - val_acc: 0.3118\n",
      "Epoch 4/10\n",
      "16000/16000 [==============================] - 2s 132us/step - loss: 0.8296 - acc: 0.6687 - val_loss: 1.1511 - val_acc: 0.2125\n",
      "Epoch 5/10\n",
      "16000/16000 [==============================] - 2s 125us/step - loss: 0.7653 - acc: 0.6709 - val_loss: 1.1014 - val_acc: 0.1792\n",
      "Epoch 6/10\n",
      "16000/16000 [==============================] - 2s 132us/step - loss: 0.7209 - acc: 0.6743 - val_loss: 1.0186 - val_acc: 0.2998\n",
      "Epoch 7/10\n",
      "16000/16000 [==============================] - 2s 128us/step - loss: 0.6906 - acc: 0.6758 - val_loss: 0.9412 - val_acc: 0.3725\n",
      "Epoch 8/10\n",
      "16000/16000 [==============================] - 2s 131us/step - loss: 0.6694 - acc: 0.6773 - val_loss: 0.9684 - val_acc: 0.3352\n",
      "Epoch 9/10\n",
      "16000/16000 [==============================] - 2s 134us/step - loss: 0.6568 - acc: 0.6771 - val_loss: 0.8911 - val_acc: 0.3922\n",
      "Epoch 10/10\n",
      "16000/16000 [==============================] - 2s 142us/step - loss: 0.6475 - acc: 0.6778 - val_loss: 0.9754 - val_acc: 0.3543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.local/share/virtualenvs/RTB-V2Lvgo6A/lib/python3.5/site-packages/imblearn/utils/validation.py:224: UserWarning: After over-sampling, the number of samples (10000) in class 0 will be larger than the number of samples in the majority class (class #0 -> 1531)\n",
      "  n_samples_majority))\n",
      "/root/.local/share/virtualenvs/RTB-V2Lvgo6A/lib/python3.5/site-packages/imblearn/utils/validation.py:224: UserWarning: After over-sampling, the number of samples (10000) in class 1 will be larger than the number of samples in the majority class (class #0 -> 1531)\n",
      "  n_samples_majority))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16000 samples, validate on 4000 samples\n",
      "Epoch 1/10\n",
      "16000/16000 [==============================] - 2s 136us/step - loss: 0.6316 - acc: 0.6866 - val_loss: 0.8913 - val_acc: 0.4298\n",
      "Epoch 2/10\n",
      "16000/16000 [==============================] - 2s 136us/step - loss: 0.6265 - acc: 0.6936 - val_loss: 0.9187 - val_acc: 0.3733\n",
      "Epoch 3/10\n",
      "16000/16000 [==============================] - 2s 134us/step - loss: 0.6236 - acc: 0.6901 - val_loss: 1.0108 - val_acc: 0.2963\n",
      "Epoch 4/10\n",
      "16000/16000 [==============================] - 2s 130us/step - loss: 0.6213 - acc: 0.6936 - val_loss: 0.9105 - val_acc: 0.3367\n",
      "Epoch 5/10\n",
      "16000/16000 [==============================] - 2s 136us/step - loss: 0.6204 - acc: 0.6921 - val_loss: 0.8435 - val_acc: 0.4555\n",
      "Epoch 6/10\n",
      "16000/16000 [==============================] - 2s 132us/step - loss: 0.6185 - acc: 0.6926 - val_loss: 0.8920 - val_acc: 0.3950\n",
      "Epoch 7/10\n",
      "16000/16000 [==============================] - 2s 134us/step - loss: 0.6185 - acc: 0.6922 - val_loss: 0.8612 - val_acc: 0.4368\n",
      "Epoch 8/10\n",
      "16000/16000 [==============================] - 2s 136us/step - loss: 0.6173 - acc: 0.6914 - val_loss: 0.9645 - val_acc: 0.3937\n",
      "Epoch 9/10\n",
      "16000/16000 [==============================] - 2s 141us/step - loss: 0.6166 - acc: 0.6930 - val_loss: 0.8844 - val_acc: 0.4273\n",
      "Epoch 10/10\n",
      "16000/16000 [==============================] - 2s 131us/step - loss: 0.6174 - acc: 0.6903 - val_loss: 0.8534 - val_acc: 0.4310\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.local/share/virtualenvs/RTB-V2Lvgo6A/lib/python3.5/site-packages/imblearn/utils/validation.py:224: UserWarning: After over-sampling, the number of samples (10000) in class 0 will be larger than the number of samples in the majority class (class #0 -> 1531)\n",
      "  n_samples_majority))\n",
      "/root/.local/share/virtualenvs/RTB-V2Lvgo6A/lib/python3.5/site-packages/imblearn/utils/validation.py:224: UserWarning: After over-sampling, the number of samples (10000) in class 1 will be larger than the number of samples in the majority class (class #0 -> 1531)\n",
      "  n_samples_majority))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16000 samples, validate on 4000 samples\n",
      "Epoch 1/10\n",
      "16000/16000 [==============================] - 2s 130us/step - loss: 0.6233 - acc: 0.6866 - val_loss: 0.9261 - val_acc: 0.3655\n",
      "Epoch 2/10\n",
      "16000/16000 [==============================] - 2s 142us/step - loss: 0.6217 - acc: 0.6880 - val_loss: 0.8889 - val_acc: 0.4203\n",
      "Epoch 3/10\n",
      "16000/16000 [==============================] - 2s 134us/step - loss: 0.6216 - acc: 0.6882 - val_loss: 1.0065 - val_acc: 0.3330\n",
      "Epoch 4/10\n",
      "16000/16000 [==============================] - 2s 127us/step - loss: 0.6209 - acc: 0.6876 - val_loss: 0.8884 - val_acc: 0.4263\n",
      "Epoch 5/10\n",
      "16000/16000 [==============================] - 2s 131us/step - loss: 0.6217 - acc: 0.6872 - val_loss: 0.8608 - val_acc: 0.4452\n",
      "Epoch 6/10\n",
      "16000/16000 [==============================] - 2s 134us/step - loss: 0.6208 - acc: 0.6886 - val_loss: 0.8847 - val_acc: 0.4298\n",
      "Epoch 7/10\n",
      "16000/16000 [==============================] - 2s 137us/step - loss: 0.6203 - acc: 0.6891 - val_loss: 0.8403 - val_acc: 0.4572\n",
      "Epoch 8/10\n",
      "16000/16000 [==============================] - 2s 128us/step - loss: 0.6207 - acc: 0.6897 - val_loss: 0.9449 - val_acc: 0.3468\n",
      "Epoch 9/10\n",
      "16000/16000 [==============================] - 2s 131us/step - loss: 0.6211 - acc: 0.6889 - val_loss: 0.7945 - val_acc: 0.5015\n",
      "Epoch 10/10\n",
      "16000/16000 [==============================] - 2s 142us/step - loss: 0.6213 - acc: 0.6865 - val_loss: 0.8725 - val_acc: 0.4370\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.local/share/virtualenvs/RTB-V2Lvgo6A/lib/python3.5/site-packages/imblearn/utils/validation.py:224: UserWarning: After over-sampling, the number of samples (10000) in class 0 will be larger than the number of samples in the majority class (class #0 -> 1531)\n",
      "  n_samples_majority))\n",
      "/root/.local/share/virtualenvs/RTB-V2Lvgo6A/lib/python3.5/site-packages/imblearn/utils/validation.py:224: UserWarning: After over-sampling, the number of samples (10000) in class 1 will be larger than the number of samples in the majority class (class #0 -> 1531)\n",
      "  n_samples_majority))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16000 samples, validate on 4000 samples\n",
      "Epoch 1/10\n",
      "16000/16000 [==============================] - 2s 136us/step - loss: 0.6238 - acc: 0.6819 - val_loss: 0.9846 - val_acc: 0.2815\n",
      "Epoch 2/10\n",
      "16000/16000 [==============================] - 2s 120us/step - loss: 0.6221 - acc: 0.6856 - val_loss: 0.8944 - val_acc: 0.4045\n",
      "Epoch 3/10\n",
      "16000/16000 [==============================] - 2s 130us/step - loss: 0.6226 - acc: 0.6864 - val_loss: 0.9321 - val_acc: 0.3738\n",
      "Epoch 4/10\n",
      "16000/16000 [==============================] - 2s 114us/step - loss: 0.6226 - acc: 0.6854 - val_loss: 0.8495 - val_acc: 0.4710\n",
      "Epoch 5/10\n",
      "16000/16000 [==============================] - 2s 126us/step - loss: 0.6228 - acc: 0.6826 - val_loss: 0.9085 - val_acc: 0.3935\n",
      "Epoch 6/10\n",
      "16000/16000 [==============================] - 2s 130us/step - loss: 0.6229 - acc: 0.6836 - val_loss: 0.9481 - val_acc: 0.3690\n",
      "Epoch 7/10\n",
      "16000/16000 [==============================] - 2s 134us/step - loss: 0.6229 - acc: 0.6847 - val_loss: 0.9562 - val_acc: 0.3305\n",
      "Epoch 8/10\n",
      "16000/16000 [==============================] - 2s 132us/step - loss: 0.6228 - acc: 0.6878 - val_loss: 0.9465 - val_acc: 0.3080\n",
      "Epoch 9/10\n",
      "16000/16000 [==============================] - 2s 126us/step - loss: 0.6229 - acc: 0.6834 - val_loss: 0.8262 - val_acc: 0.4425\n",
      "Epoch 10/10\n",
      "16000/16000 [==============================] - 2s 128us/step - loss: 0.6226 - acc: 0.6833 - val_loss: 0.8838 - val_acc: 0.3802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.local/share/virtualenvs/RTB-V2Lvgo6A/lib/python3.5/site-packages/imblearn/utils/validation.py:224: UserWarning: After over-sampling, the number of samples (10000) in class 0 will be larger than the number of samples in the majority class (class #0 -> 1531)\n",
      "  n_samples_majority))\n",
      "/root/.local/share/virtualenvs/RTB-V2Lvgo6A/lib/python3.5/site-packages/imblearn/utils/validation.py:224: UserWarning: After over-sampling, the number of samples (10000) in class 1 will be larger than the number of samples in the majority class (class #0 -> 1531)\n",
      "  n_samples_majority))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16000 samples, validate on 4000 samples\n",
      "Epoch 1/10\n",
      "16000/16000 [==============================] - 2s 132us/step - loss: 0.6229 - acc: 0.6812 - val_loss: 0.9046 - val_acc: 0.3900\n",
      "Epoch 2/10\n",
      "16000/16000 [==============================] - 2s 126us/step - loss: 0.6222 - acc: 0.6814 - val_loss: 0.9192 - val_acc: 0.3820\n",
      "Epoch 3/10\n",
      "16000/16000 [==============================] - 2s 127us/step - loss: 0.6221 - acc: 0.6831 - val_loss: 0.8773 - val_acc: 0.4385\n",
      "Epoch 4/10\n",
      "16000/16000 [==============================] - 2s 128us/step - loss: 0.6220 - acc: 0.6844 - val_loss: 0.8051 - val_acc: 0.4985\n",
      "Epoch 5/10\n",
      "16000/16000 [==============================] - 2s 131us/step - loss: 0.6217 - acc: 0.6838 - val_loss: 1.0124 - val_acc: 0.3247\n",
      "Epoch 6/10\n",
      "16000/16000 [==============================] - 2s 126us/step - loss: 0.6221 - acc: 0.6825 - val_loss: 0.9111 - val_acc: 0.3950\n",
      "Epoch 7/10\n",
      "16000/16000 [==============================] - 2s 118us/step - loss: 0.6215 - acc: 0.6831 - val_loss: 0.8550 - val_acc: 0.4268\n",
      "Epoch 8/10\n",
      "16000/16000 [==============================] - 2s 125us/step - loss: 0.6211 - acc: 0.6799 - val_loss: 0.8474 - val_acc: 0.4990\n",
      "Epoch 9/10\n",
      "16000/16000 [==============================] - 2s 128us/step - loss: 0.6218 - acc: 0.6820 - val_loss: 0.9142 - val_acc: 0.4040\n",
      "Epoch 10/10\n",
      "16000/16000 [==============================] - 2s 124us/step - loss: 0.6218 - acc: 0.6817 - val_loss: 0.9243 - val_acc: 0.3400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.local/share/virtualenvs/RTB-V2Lvgo6A/lib/python3.5/site-packages/imblearn/utils/validation.py:224: UserWarning: After over-sampling, the number of samples (10000) in class 0 will be larger than the number of samples in the majority class (class #0 -> 1531)\n",
      "  n_samples_majority))\n",
      "/root/.local/share/virtualenvs/RTB-V2Lvgo6A/lib/python3.5/site-packages/imblearn/utils/validation.py:224: UserWarning: After over-sampling, the number of samples (10000) in class 1 will be larger than the number of samples in the majority class (class #0 -> 1531)\n",
      "  n_samples_majority))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16000 samples, validate on 4000 samples\n",
      "Epoch 1/10\n",
      "16000/16000 [==============================] - 2s 123us/step - loss: 0.6199 - acc: 0.6844 - val_loss: 0.9613 - val_acc: 0.3438\n",
      "Epoch 2/10\n",
      "16000/16000 [==============================] - 2s 129us/step - loss: 0.6196 - acc: 0.6826 - val_loss: 0.8907 - val_acc: 0.4375\n",
      "Epoch 3/10\n",
      "16000/16000 [==============================] - 2s 131us/step - loss: 0.6194 - acc: 0.6839 - val_loss: 0.8300 - val_acc: 0.5435\n",
      "Epoch 4/10\n",
      "16000/16000 [==============================] - 2s 123us/step - loss: 0.6200 - acc: 0.6816 - val_loss: 0.9464 - val_acc: 0.3355\n",
      "Epoch 5/10\n",
      "16000/16000 [==============================] - 2s 138us/step - loss: 0.6203 - acc: 0.6820 - val_loss: 0.9816 - val_acc: 0.3162\n",
      "Epoch 6/10\n",
      "16000/16000 [==============================] - 2s 137us/step - loss: 0.6186 - acc: 0.6857 - val_loss: 0.8863 - val_acc: 0.4597\n",
      "Epoch 7/10\n",
      "16000/16000 [==============================] - 2s 126us/step - loss: 0.6195 - acc: 0.6843 - val_loss: 0.8771 - val_acc: 0.4647\n",
      "Epoch 8/10\n",
      "16000/16000 [==============================] - 2s 130us/step - loss: 0.6191 - acc: 0.6816 - val_loss: 0.9267 - val_acc: 0.3588\n",
      "Epoch 9/10\n",
      "16000/16000 [==============================] - 2s 130us/step - loss: 0.6191 - acc: 0.6849 - val_loss: 0.9458 - val_acc: 0.3955\n",
      "Epoch 10/10\n",
      "16000/16000 [==============================] - 2s 123us/step - loss: 0.6199 - acc: 0.6839 - val_loss: 0.8441 - val_acc: 0.4532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.local/share/virtualenvs/RTB-V2Lvgo6A/lib/python3.5/site-packages/imblearn/utils/validation.py:224: UserWarning: After over-sampling, the number of samples (10000) in class 0 will be larger than the number of samples in the majority class (class #0 -> 1531)\n",
      "  n_samples_majority))\n",
      "/root/.local/share/virtualenvs/RTB-V2Lvgo6A/lib/python3.5/site-packages/imblearn/utils/validation.py:224: UserWarning: After over-sampling, the number of samples (10000) in class 1 will be larger than the number of samples in the majority class (class #0 -> 1531)\n",
      "  n_samples_majority))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16000 samples, validate on 4000 samples\n",
      "Epoch 1/10\n",
      "16000/16000 [==============================] - 2s 127us/step - loss: 0.6245 - acc: 0.6800 - val_loss: 0.9123 - val_acc: 0.3930\n",
      "Epoch 2/10\n",
      "16000/16000 [==============================] - 2s 126us/step - loss: 0.6236 - acc: 0.6825 - val_loss: 0.8864 - val_acc: 0.3935\n",
      "Epoch 3/10\n",
      "16000/16000 [==============================] - 2s 120us/step - loss: 0.6236 - acc: 0.6841 - val_loss: 0.9038 - val_acc: 0.3897\n",
      "Epoch 4/10\n",
      "16000/16000 [==============================] - 2s 131us/step - loss: 0.6231 - acc: 0.6818 - val_loss: 0.8600 - val_acc: 0.4263\n",
      "Epoch 5/10\n",
      "16000/16000 [==============================] - 2s 133us/step - loss: 0.6244 - acc: 0.6808 - val_loss: 0.9463 - val_acc: 0.2903\n",
      "Epoch 6/10\n",
      "16000/16000 [==============================] - 2s 125us/step - loss: 0.6239 - acc: 0.6801 - val_loss: 0.9016 - val_acc: 0.3573\n",
      "Epoch 7/10\n",
      "16000/16000 [==============================] - 2s 123us/step - loss: 0.6235 - acc: 0.6836 - val_loss: 0.9080 - val_acc: 0.3743\n",
      "Epoch 8/10\n",
      "16000/16000 [==============================] - 2s 129us/step - loss: 0.6240 - acc: 0.6830 - val_loss: 0.8660 - val_acc: 0.3495\n",
      "Epoch 9/10\n",
      "16000/16000 [==============================] - 2s 130us/step - loss: 0.6237 - acc: 0.6851 - val_loss: 0.7679 - val_acc: 0.5135\n",
      "Epoch 10/10\n",
      "16000/16000 [==============================] - 2s 122us/step - loss: 0.6237 - acc: 0.6798 - val_loss: 0.8676 - val_acc: 0.4295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.local/share/virtualenvs/RTB-V2Lvgo6A/lib/python3.5/site-packages/imblearn/utils/validation.py:224: UserWarning: After over-sampling, the number of samples (10000) in class 0 will be larger than the number of samples in the majority class (class #0 -> 1531)\n",
      "  n_samples_majority))\n",
      "/root/.local/share/virtualenvs/RTB-V2Lvgo6A/lib/python3.5/site-packages/imblearn/utils/validation.py:224: UserWarning: After over-sampling, the number of samples (10000) in class 1 will be larger than the number of samples in the majority class (class #0 -> 1531)\n",
      "  n_samples_majority))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16000 samples, validate on 4000 samples\n",
      "Epoch 1/10\n",
      "16000/16000 [==============================] - 2s 127us/step - loss: 0.6259 - acc: 0.6743 - val_loss: 0.9682 - val_acc: 0.3053\n",
      "Epoch 2/10\n",
      "16000/16000 [==============================] - 2s 133us/step - loss: 0.6250 - acc: 0.6766 - val_loss: 0.8207 - val_acc: 0.4728\n",
      "Epoch 3/10\n",
      "16000/16000 [==============================] - 2s 141us/step - loss: 0.6256 - acc: 0.6776 - val_loss: 0.8926 - val_acc: 0.3927\n",
      "Epoch 4/10\n",
      "16000/16000 [==============================] - 2s 129us/step - loss: 0.6260 - acc: 0.6769 - val_loss: 0.9035 - val_acc: 0.4010\n",
      "Epoch 5/10\n",
      "16000/16000 [==============================] - 2s 123us/step - loss: 0.6257 - acc: 0.6746 - val_loss: 0.9933 - val_acc: 0.2840\n",
      "Epoch 6/10\n",
      "16000/16000 [==============================] - 2s 130us/step - loss: 0.6258 - acc: 0.6744 - val_loss: 0.9905 - val_acc: 0.3598\n",
      "Epoch 7/10\n",
      "16000/16000 [==============================] - 2s 132us/step - loss: 0.6253 - acc: 0.6748 - val_loss: 0.9063 - val_acc: 0.3807\n",
      "Epoch 8/10\n",
      "16000/16000 [==============================] - 2s 128us/step - loss: 0.6253 - acc: 0.6777 - val_loss: 0.9380 - val_acc: 0.3757\n",
      "Epoch 9/10\n",
      "16000/16000 [==============================] - 2s 131us/step - loss: 0.6252 - acc: 0.6772 - val_loss: 0.8370 - val_acc: 0.4645\n",
      "Epoch 10/10\n",
      "16000/16000 [==============================] - 2s 123us/step - loss: 0.6251 - acc: 0.6745 - val_loss: 0.9173 - val_acc: 0.3410\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.local/share/virtualenvs/RTB-V2Lvgo6A/lib/python3.5/site-packages/imblearn/utils/validation.py:224: UserWarning: After over-sampling, the number of samples (10000) in class 0 will be larger than the number of samples in the majority class (class #0 -> 1531)\n",
      "  n_samples_majority))\n",
      "/root/.local/share/virtualenvs/RTB-V2Lvgo6A/lib/python3.5/site-packages/imblearn/utils/validation.py:224: UserWarning: After over-sampling, the number of samples (10000) in class 1 will be larger than the number of samples in the majority class (class #0 -> 1531)\n",
      "  n_samples_majority))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16000 samples, validate on 4000 samples\n",
      "Epoch 1/10\n",
      "16000/16000 [==============================] - 2s 128us/step - loss: 0.6156 - acc: 0.6909 - val_loss: 0.8732 - val_acc: 0.3992\n",
      "Epoch 2/10\n",
      "16000/16000 [==============================] - 2s 128us/step - loss: 0.6146 - acc: 0.6905 - val_loss: 0.9288 - val_acc: 0.3992\n",
      "Epoch 3/10\n",
      "16000/16000 [==============================] - 2s 122us/step - loss: 0.6144 - acc: 0.6961 - val_loss: 0.7882 - val_acc: 0.5058\n",
      "Epoch 4/10\n",
      "16000/16000 [==============================] - 2s 129us/step - loss: 0.6146 - acc: 0.6955 - val_loss: 0.8594 - val_acc: 0.4368\n",
      "Epoch 5/10\n",
      "16000/16000 [==============================] - 2s 133us/step - loss: 0.6145 - acc: 0.6974 - val_loss: 0.8080 - val_acc: 0.5068\n",
      "Epoch 6/10\n",
      "16000/16000 [==============================] - 2s 130us/step - loss: 0.6139 - acc: 0.6951 - val_loss: 0.9544 - val_acc: 0.4047\n",
      "Epoch 7/10\n",
      "16000/16000 [==============================] - 2s 120us/step - loss: 0.6142 - acc: 0.6947 - val_loss: 0.9006 - val_acc: 0.3880\n",
      "Epoch 8/10\n",
      "16000/16000 [==============================] - 2s 122us/step - loss: 0.6144 - acc: 0.6979 - val_loss: 0.8897 - val_acc: 0.4093\n",
      "Epoch 9/10\n",
      "16000/16000 [==============================] - 2s 120us/step - loss: 0.6135 - acc: 0.6953 - val_loss: 0.8917 - val_acc: 0.4285\n",
      "Epoch 10/10\n",
      "16000/16000 [==============================] - 2s 126us/step - loss: 0.6137 - acc: 0.6978 - val_loss: 0.9052 - val_acc: 0.3947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.local/share/virtualenvs/RTB-V2Lvgo6A/lib/python3.5/site-packages/imblearn/utils/validation.py:224: UserWarning: After over-sampling, the number of samples (10000) in class 0 will be larger than the number of samples in the majority class (class #0 -> 1531)\n",
      "  n_samples_majority))\n",
      "/root/.local/share/virtualenvs/RTB-V2Lvgo6A/lib/python3.5/site-packages/imblearn/utils/validation.py:224: UserWarning: After over-sampling, the number of samples (10000) in class 1 will be larger than the number of samples in the majority class (class #0 -> 1531)\n",
      "  n_samples_majority))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16000 samples, validate on 4000 samples\n",
      "Epoch 1/10\n",
      "16000/16000 [==============================] - 2s 130us/step - loss: 0.6215 - acc: 0.6816 - val_loss: 0.9032 - val_acc: 0.3430\n",
      "Epoch 2/10\n",
      "16000/16000 [==============================] - 2s 124us/step - loss: 0.6197 - acc: 0.6820 - val_loss: 0.9286 - val_acc: 0.3420\n",
      "Epoch 3/10\n",
      "16000/16000 [==============================] - 2s 123us/step - loss: 0.6203 - acc: 0.6809 - val_loss: 0.9270 - val_acc: 0.3780\n",
      "Epoch 4/10\n",
      "16000/16000 [==============================] - 2s 125us/step - loss: 0.6207 - acc: 0.6801 - val_loss: 0.9801 - val_acc: 0.2717\n",
      "Epoch 5/10\n",
      "16000/16000 [==============================] - 2s 122us/step - loss: 0.6203 - acc: 0.6811 - val_loss: 0.9291 - val_acc: 0.4002\n",
      "Epoch 6/10\n",
      "16000/16000 [==============================] - 2s 129us/step - loss: 0.6205 - acc: 0.6781 - val_loss: 0.8839 - val_acc: 0.3743\n",
      "Epoch 7/10\n",
      "16000/16000 [==============================] - 2s 128us/step - loss: 0.6199 - acc: 0.6835 - val_loss: 0.9578 - val_acc: 0.3743\n",
      "Epoch 8/10\n",
      "16000/16000 [==============================] - 2s 131us/step - loss: 0.6203 - acc: 0.6806 - val_loss: 0.8361 - val_acc: 0.4285\n",
      "Epoch 9/10\n",
      "16000/16000 [==============================] - 2s 127us/step - loss: 0.6211 - acc: 0.6813 - val_loss: 0.9123 - val_acc: 0.3990\n",
      "Epoch 10/10\n",
      "16000/16000 [==============================] - 2s 134us/step - loss: 0.6205 - acc: 0.6813 - val_loss: 0.9881 - val_acc: 0.3088\n",
      "200000/200000 [==============================] - 5s 26us/step\n",
      "(200000, 2)\n",
      "---------test---------\n",
      "Confusion Matrix:\n",
      "True Negative = 173375\n",
      "False Negative = 244\n",
      "True Positive = 133\n",
      "False Positive = 26248\n",
      "f1 score = 0.010\n",
      "ROC Score = 0.611\n"
     ]
    }
   ],
   "source": [
    "def base_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(88, activation='tanh',\n",
    "                    kernel_initializer='glorot_uniform', kernel_regularizer=l1(0.01),\n",
    "                    input_shape=(88,)))\n",
    "    model.add(Dense(64, activation='relu', kernel_regularizer=l2(0.01)))\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=SGD(lr=0.01),\n",
    "                  metrics=['accuracy'])\n",
    "    return model;\n",
    "\n",
    "def model_fit(model, X, y):\n",
    "    model.fit(X, y,\n",
    "              batch_size=batch_size,\n",
    "              epochs=10,\n",
    "              validation_split=0.2,\n",
    "              verbose=1)\n",
    "    return model\n",
    "\n",
    "smote = SMOTE(ratio={0: 10000, 1: 10000}, n_jobs=-1, random_state=KFOLD_SEED)\n",
    "model = deep_ensemble(base_model, model_fit, bc, smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
