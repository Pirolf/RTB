{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import numpy as np\n",
    "from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
    "from imblearn.under_sampling import NearMiss, RandomUnderSampler\n",
    "from imblearn.combine import SMOTEENN,SMOTETomek\n",
    "from imblearn.ensemble import BalanceCascade, EasyEnsemble\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "import h5py\n",
    "import keras\n",
    "from sklearn.utils import class_weight\n",
    "from keras.utils import to_categorical\n",
    "from keras.optimizers import *\n",
    "from keras.callbacks import *\n",
    "from keras.regularizers import *\n",
    "from keras.initializers import *\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, BatchNormalization\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, f1_score, precision_recall_fscore_support\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "KFOLD_SEED = 42\n",
    "\n",
    "def shuffle(features, labels):\n",
    "    p = np.random.permutation(len(features))\n",
    "    return features[p], labels[p]\n",
    "\n",
    "\n",
    "def keras_confusion_matrix(test_labels_1d, predicted_labels):\n",
    "    m = confusion_matrix(test_labels_1d, predicted_labels)\n",
    "\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(\"True Negative = %d\" % m[0][0])\n",
    "    print(\"False Negative = %d\" % m[1][0])\n",
    "    print(\"True Positive = %d\" % m[1][1])\n",
    "    print(\"False Positive = %d\" % m[0][1])\n",
    "    \n",
    "\n",
    "def keras_f1_score(test_labels_1d, predicted_labels):\n",
    "    f = f1_score(test_labels_1d, predicted_labels)\n",
    "    print(\"f1 score = %0.3f\" % f)\n",
    "\n",
    "    \n",
    "def print_xgb_metrics(test_labels_1d, y_scores, score_to_label_threshold=0.5):\n",
    "    predicted_labels = np.array([])\n",
    "    for s in y_scores:\n",
    "        if s > score_to_label_threshold:\n",
    "            predicted_labels = np.append(predicted_labels, 1)\n",
    "        else:\n",
    "            predicted_labels = np.append(predicted_labels, 0)\n",
    "\n",
    "    print(predicted_labels.shape)\n",
    "    \n",
    "    keras_confusion_matrix(test_labels_1d, predicted_labels)\n",
    "    keras_f1_score(test_labels_1d, predicted_labels)\n",
    "    print(\"ROC Score = %0.3f\" % roc_auc_score(test_labels_1d, predicted_labels))\n",
    "\n",
    "\n",
    "def print_metrics(test_labels_1d, y_scores, is_train=False, score_to_label_threshold=None):\n",
    "    if score_to_label_threshold is None:\n",
    "        predicted_labels = y_scores.argmax(axis=-1)\n",
    "    else:\n",
    "        print(y_scores[:,1][0:5])\n",
    "        predicted_labels = np.array([])\n",
    "        for s in y_scores[:,1]:\n",
    "            if s > score_to_label_threshold:\n",
    "                predicted_labels = np.append(predicted_labels, 1)\n",
    "            else:\n",
    "                predicted_labels = np.append(predicted_labels, 0)\n",
    "    \n",
    "    if is_train:\n",
    "        print(\"---------train---------\")\n",
    "    else:\n",
    "        print(\"---------test---------\")\n",
    "    \n",
    "    keras_confusion_matrix(test_labels_1d, predicted_labels)\n",
    "    keras_f1_score(test_labels_1d, predicted_labels)\n",
    "    print(\"ROC Score = %0.3f\" % roc_auc_score(test_labels_1d, predicted_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000000, 89)\n"
     ]
    }
   ],
   "source": [
    "input_path = '~/data/biddings.csv'\n",
    "data = pd.read_csv(input_path)\n",
    "print(data.shape)\n",
    "\n",
    "train = data[:800000]\n",
    "test = data[800000:]\n",
    "\n",
    "sample = train.sample(frac=1)\n",
    "features = sample.drop('convert', axis=1).values\n",
    "labels = sample.convert.ravel()\n",
    "categorical_labels = to_categorical(sample.convert.ravel(), 2)\n",
    "\n",
    "test_features = test.drop('convert', axis=1).values\n",
    "test_labels = test.convert.ravel()\n",
    "categorical_test_labels = to_categorical(test.convert.ravel(), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier(max_features=0.2, random_state=KFOLD_SEED)\n",
    "bc = BalanceCascade(estimator=dt, n_max_subset=10, random_state=KFOLD_SEED)\n",
    "\n",
    "def deep_ensemble_merged(model_fn, model_fit_fn, ensembler, smote=None):\n",
    "    print(\"fitting sample\")\n",
    "    X_res, y_res = ensembler.fit_sample(features, labels)\n",
    "    print(X_res.shape, y_res.shape)\n",
    "    \n",
    "    model = model_fn()\n",
    "    print(\"training\")\n",
    "\n",
    "    # Merge sample batches\n",
    "    Xs = None\n",
    "    ys = None\n",
    "    for i, X_train in enumerate(X_res):\n",
    "        if Xs is None:\n",
    "            Xs = np.array(X_res[i])\n",
    "            ys = np.array(y_res[i])\n",
    "            print(Xs.shape, ys.shape)\n",
    "        else:\n",
    "            Xs = np.concatenate((Xs, np.array(X_res[i])))\n",
    "            ys = np.concatenate((ys, np.array(y_res[i])))\n",
    "    \n",
    "    print(Xs.shape, ys.shape)\n",
    "    shuffle(Xs, ys)\n",
    "    \n",
    "    # Generate more synthetic samples\n",
    "    if smote is not None:\n",
    "        Xs, ys = smote.fit_sample(Xs, ys)\n",
    "    \n",
    "    shuffle(Xs, ys)\n",
    "    ys = to_categorical(ys, 2)\n",
    "    model = model_fit_fn(model, Xs, ys)\n",
    "\n",
    "    predicted_scores = model.predict(test_features, verbose=1)\n",
    "    print(predicted_scores.shape)\n",
    "    print_metrics(test_labels, predicted_scores, is_train=False)\n",
    "    return model\n",
    "\n",
    "\n",
    "def deep_ensemble(model_fn, model_fit_fn, ensembler, smote=None):\n",
    "    print(\"fitting sample\")\n",
    "    X_res, y_res = ensembler.fit_sample(features, labels)\n",
    "    print(X_res.shape, y_res.shape)\n",
    "    \n",
    "    model = model_fn()\n",
    "    print(\"training\")\n",
    "\n",
    "    for j, X_train in enumerate(X_res):\n",
    "        if smote is not None:\n",
    "            X, y = smote.fit_sample(X_train, y_res[j])\n",
    "            y = to_categorical(y, 2)\n",
    "            model = model_fit_fn(model, X, y)\n",
    "        else:\n",
    "            y = to_categorical(y_res[j], 2)\n",
    "            model = model_fit_fn(model, X_train, y)\n",
    "\n",
    "    predicted_scores = model.predict(test_features, verbose=1)\n",
    "    print(predicted_scores.shape)\n",
    "    print_metrics(test_labels, predicted_scores, is_train=False)\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Neural Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "epochs = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bare minimum: 0.644 <br>\n",
    "10 Epochs: 0.655 <br>\n",
    "With l2(0.01): 0.660"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting sample\n",
      "(20, 3062, 88) (20, 3062)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 88)                7832      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 178       \n",
      "=================================================================\n",
      "Total params: 8,010\n",
      "Trainable params: 8,010\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "training\n",
      "Epoch 1/10\n",
      "3062/3062 [==============================] - 0s 133us/step - loss: 0.7320 - acc: 0.6032\n",
      "Epoch 2/10\n",
      "3062/3062 [==============================] - 0s 113us/step - loss: 0.6511 - acc: 0.6225\n",
      "Epoch 3/10\n",
      "3062/3062 [==============================] - 0s 100us/step - loss: 0.6452 - acc: 0.6326\n",
      "Epoch 4/10\n",
      "3062/3062 [==============================] - 0s 108us/step - loss: 0.6436 - acc: 0.6316\n",
      "Epoch 5/10\n",
      "3062/3062 [==============================] - 0s 100us/step - loss: 0.6437 - acc: 0.6391\n",
      "Epoch 6/10\n",
      "3062/3062 [==============================] - 0s 95us/step - loss: 0.6438 - acc: 0.6306\n",
      "Epoch 7/10\n",
      "3062/3062 [==============================] - 0s 113us/step - loss: 0.6430 - acc: 0.6359\n",
      "Epoch 8/10\n",
      "3062/3062 [==============================] - 0s 105us/step - loss: 0.6444 - acc: 0.6264\n",
      "Epoch 9/10\n",
      "3062/3062 [==============================] - 0s 99us/step - loss: 0.6408 - acc: 0.6355\n",
      "Epoch 10/10\n",
      "3062/3062 [==============================] - 0s 111us/step - loss: 0.6423 - acc: 0.6323\n",
      "Epoch 1/10\n",
      "3062/3062 [==============================] - 0s 103us/step - loss: 0.6403 - acc: 0.6470\n",
      "Epoch 2/10\n",
      "3062/3062 [==============================] - 0s 91us/step - loss: 0.6358 - acc: 0.6447\n",
      "Epoch 3/10\n",
      "3062/3062 [==============================] - 0s 108us/step - loss: 0.6332 - acc: 0.6401\n",
      "Epoch 4/10\n",
      "3062/3062 [==============================] - 0s 99us/step - loss: 0.6347 - acc: 0.6395\n",
      "Epoch 5/10\n",
      "3062/3062 [==============================] - 0s 103us/step - loss: 0.6338 - acc: 0.6398\n",
      "Epoch 6/10\n",
      "3062/3062 [==============================] - 0s 110us/step - loss: 0.6331 - acc: 0.6430\n",
      "Epoch 7/10\n",
      "3062/3062 [==============================] - 0s 111us/step - loss: 0.6318 - acc: 0.6424\n",
      "Epoch 8/10\n",
      "3062/3062 [==============================] - 0s 105us/step - loss: 0.6335 - acc: 0.6470\n",
      "Epoch 9/10\n",
      "3062/3062 [==============================] - 0s 107us/step - loss: 0.6329 - acc: 0.6408\n",
      "Epoch 10/10\n",
      "3062/3062 [==============================] - 0s 104us/step - loss: 0.6302 - acc: 0.6414\n",
      "Epoch 1/10\n",
      "3062/3062 [==============================] - 0s 111us/step - loss: 0.6423 - acc: 0.6323\n",
      "Epoch 2/10\n",
      "3062/3062 [==============================] - 0s 94us/step - loss: 0.6370 - acc: 0.6329\n",
      "Epoch 3/10\n",
      "3062/3062 [==============================] - 0s 90us/step - loss: 0.6360 - acc: 0.6398\n",
      "Epoch 4/10\n",
      "3062/3062 [==============================] - 0s 105us/step - loss: 0.6355 - acc: 0.6313\n",
      "Epoch 5/10\n",
      "3062/3062 [==============================] - 0s 103us/step - loss: 0.6364 - acc: 0.6336\n",
      "Epoch 6/10\n",
      "3062/3062 [==============================] - 0s 105us/step - loss: 0.6347 - acc: 0.6355\n",
      "Epoch 7/10\n",
      "3062/3062 [==============================] - 0s 99us/step - loss: 0.6341 - acc: 0.6359\n",
      "Epoch 8/10\n",
      "3062/3062 [==============================] - 0s 106us/step - loss: 0.6337 - acc: 0.6342\n",
      "Epoch 9/10\n",
      "3062/3062 [==============================] - 0s 105us/step - loss: 0.6335 - acc: 0.6355\n",
      "Epoch 10/10\n",
      "3062/3062 [==============================] - 0s 97us/step - loss: 0.6343 - acc: 0.6316\n",
      "Epoch 1/10\n",
      "3062/3062 [==============================] - 0s 98us/step - loss: 0.6368 - acc: 0.6453\n",
      "Epoch 2/10\n",
      "3062/3062 [==============================] - 0s 100us/step - loss: 0.6329 - acc: 0.6414\n",
      "Epoch 3/10\n",
      "3062/3062 [==============================] - 0s 102us/step - loss: 0.6331 - acc: 0.6430\n",
      "Epoch 4/10\n",
      "3062/3062 [==============================] - 0s 97us/step - loss: 0.6319 - acc: 0.6450\n",
      "Epoch 5/10\n",
      "3062/3062 [==============================] - 0s 106us/step - loss: 0.6316 - acc: 0.6466\n",
      "Epoch 6/10\n",
      "3062/3062 [==============================] - 0s 100us/step - loss: 0.6315 - acc: 0.6532\n",
      "Epoch 7/10\n",
      "3062/3062 [==============================] - 0s 102us/step - loss: 0.6317 - acc: 0.6473\n",
      "Epoch 8/10\n",
      "3062/3062 [==============================] - 0s 107us/step - loss: 0.6316 - acc: 0.6450\n",
      "Epoch 9/10\n",
      "3062/3062 [==============================] - 0s 107us/step - loss: 0.6298 - acc: 0.6548\n",
      "Epoch 10/10\n",
      "3062/3062 [==============================] - 0s 113us/step - loss: 0.6306 - acc: 0.6444\n",
      "Epoch 1/10\n",
      "3062/3062 [==============================] - 0s 105us/step - loss: 0.6394 - acc: 0.6365\n",
      "Epoch 2/10\n",
      "3062/3062 [==============================] - 0s 105us/step - loss: 0.6339 - acc: 0.6362\n",
      "Epoch 3/10\n",
      "3062/3062 [==============================] - 0s 106us/step - loss: 0.6323 - acc: 0.6368\n",
      "Epoch 4/10\n",
      "3062/3062 [==============================] - 0s 110us/step - loss: 0.6331 - acc: 0.6421\n",
      "Epoch 5/10\n",
      "3062/3062 [==============================] - 0s 109us/step - loss: 0.6319 - acc: 0.6368\n",
      "Epoch 6/10\n",
      "3062/3062 [==============================] - 0s 100us/step - loss: 0.6311 - acc: 0.6447\n",
      "Epoch 7/10\n",
      "3062/3062 [==============================] - 0s 104us/step - loss: 0.6321 - acc: 0.6404\n",
      "Epoch 8/10\n",
      "3062/3062 [==============================] - 0s 107us/step - loss: 0.6321 - acc: 0.6424\n",
      "Epoch 9/10\n",
      "3062/3062 [==============================] - 0s 107us/step - loss: 0.6317 - acc: 0.6437\n",
      "Epoch 10/10\n",
      "3062/3062 [==============================] - 0s 108us/step - loss: 0.6304 - acc: 0.6463\n",
      "Epoch 1/10\n",
      "3062/3062 [==============================] - 0s 104us/step - loss: 0.6379 - acc: 0.6352\n",
      "Epoch 2/10\n",
      "3062/3062 [==============================] - 0s 101us/step - loss: 0.6343 - acc: 0.6355\n",
      "Epoch 3/10\n",
      "3062/3062 [==============================] - 0s 100us/step - loss: 0.6320 - acc: 0.6395\n",
      "Epoch 4/10\n",
      "3062/3062 [==============================] - 0s 92us/step - loss: 0.6322 - acc: 0.6316\n",
      "Epoch 5/10\n",
      "3062/3062 [==============================] - 0s 83us/step - loss: 0.6311 - acc: 0.6395\n",
      "Epoch 6/10\n",
      "3062/3062 [==============================] - 0s 94us/step - loss: 0.6319 - acc: 0.6359\n",
      "Epoch 7/10\n",
      "3062/3062 [==============================] - 0s 105us/step - loss: 0.6307 - acc: 0.6424\n",
      "Epoch 8/10\n",
      "3062/3062 [==============================] - 0s 112us/step - loss: 0.6316 - acc: 0.6408\n",
      "Epoch 9/10\n",
      "3062/3062 [==============================] - 0s 107us/step - loss: 0.6298 - acc: 0.6352\n",
      "Epoch 10/10\n",
      "3062/3062 [==============================] - 0s 104us/step - loss: 0.6310 - acc: 0.6424\n",
      "Epoch 1/10\n",
      "3062/3062 [==============================] - 0s 90us/step - loss: 0.6378 - acc: 0.6342\n",
      "Epoch 2/10\n",
      "3062/3062 [==============================] - 0s 87us/step - loss: 0.6322 - acc: 0.6427\n",
      "Epoch 3/10\n",
      "3062/3062 [==============================] - 0s 103us/step - loss: 0.6291 - acc: 0.6391\n",
      "Epoch 4/10\n",
      "3062/3062 [==============================] - 0s 102us/step - loss: 0.6292 - acc: 0.6381\n",
      "Epoch 5/10\n",
      "3062/3062 [==============================] - 0s 102us/step - loss: 0.6288 - acc: 0.6434\n",
      "Epoch 6/10\n",
      "3062/3062 [==============================] - 0s 88us/step - loss: 0.6277 - acc: 0.6444\n",
      "Epoch 7/10\n",
      "3062/3062 [==============================] - 0s 82us/step - loss: 0.6276 - acc: 0.6457\n",
      "Epoch 8/10\n",
      "3062/3062 [==============================] - 0s 97us/step - loss: 0.6264 - acc: 0.6411\n",
      "Epoch 9/10\n",
      "3062/3062 [==============================] - 0s 102us/step - loss: 0.6280 - acc: 0.6447\n",
      "Epoch 10/10\n",
      "3062/3062 [==============================] - 0s 107us/step - loss: 0.6279 - acc: 0.6404\n",
      "Epoch 1/10\n",
      "3062/3062 [==============================] - 0s 102us/step - loss: 0.6405 - acc: 0.6368\n",
      "Epoch 2/10\n",
      "3062/3062 [==============================] - 0s 90us/step - loss: 0.6362 - acc: 0.6398\n",
      "Epoch 3/10\n",
      "3062/3062 [==============================] - 0s 107us/step - loss: 0.6344 - acc: 0.6444\n",
      "Epoch 4/10\n",
      "3062/3062 [==============================] - 0s 104us/step - loss: 0.6337 - acc: 0.6395\n",
      "Epoch 5/10\n",
      "3062/3062 [==============================] - 0s 96us/step - loss: 0.6333 - acc: 0.6457\n",
      "Epoch 6/10\n",
      "3062/3062 [==============================] - 0s 97us/step - loss: 0.6323 - acc: 0.6476\n",
      "Epoch 7/10\n",
      "3062/3062 [==============================] - 0s 103us/step - loss: 0.6324 - acc: 0.6404\n",
      "Epoch 8/10\n",
      "3062/3062 [==============================] - 0s 113us/step - loss: 0.6329 - acc: 0.6457\n",
      "Epoch 9/10\n",
      "3062/3062 [==============================] - 0s 111us/step - loss: 0.6325 - acc: 0.6453\n",
      "Epoch 10/10\n",
      "3062/3062 [==============================] - 0s 105us/step - loss: 0.6314 - acc: 0.6398\n",
      "Epoch 1/10\n",
      "3062/3062 [==============================] - 0s 96us/step - loss: 0.6374 - acc: 0.6388\n",
      "Epoch 2/10\n",
      "3062/3062 [==============================] - 0s 130us/step - loss: 0.6349 - acc: 0.6430\n",
      "Epoch 3/10\n",
      "3062/3062 [==============================] - 0s 110us/step - loss: 0.6332 - acc: 0.6368\n",
      "Epoch 4/10\n",
      "3062/3062 [==============================] - 0s 101us/step - loss: 0.6321 - acc: 0.6466\n",
      "Epoch 5/10\n",
      "3062/3062 [==============================] - 0s 93us/step - loss: 0.6324 - acc: 0.6444\n",
      "Epoch 6/10\n",
      "3062/3062 [==============================] - 0s 104us/step - loss: 0.6319 - acc: 0.6434\n",
      "Epoch 7/10\n",
      "3062/3062 [==============================] - 0s 100us/step - loss: 0.6315 - acc: 0.6473\n",
      "Epoch 8/10\n",
      "3062/3062 [==============================] - 0s 98us/step - loss: 0.6319 - acc: 0.6437\n",
      "Epoch 9/10\n",
      "3062/3062 [==============================] - 0s 98us/step - loss: 0.6311 - acc: 0.6444\n",
      "Epoch 10/10\n",
      "3062/3062 [==============================] - 0s 93us/step - loss: 0.6313 - acc: 0.6424\n",
      "Epoch 1/10\n",
      "3062/3062 [==============================] - 0s 91us/step - loss: 0.6322 - acc: 0.6424\n",
      "Epoch 2/10\n",
      "3062/3062 [==============================] - 0s 85us/step - loss: 0.6275 - acc: 0.6551\n",
      "Epoch 3/10\n",
      "3062/3062 [==============================] - 0s 88us/step - loss: 0.6271 - acc: 0.6492\n",
      "Epoch 4/10\n",
      "3062/3062 [==============================] - 0s 103us/step - loss: 0.6259 - acc: 0.6538\n",
      "Epoch 5/10\n",
      "3062/3062 [==============================] - 0s 101us/step - loss: 0.6270 - acc: 0.6528\n",
      "Epoch 6/10\n",
      "3062/3062 [==============================] - 0s 108us/step - loss: 0.6257 - acc: 0.6568\n",
      "Epoch 7/10\n",
      "3062/3062 [==============================] - 0s 105us/step - loss: 0.6265 - acc: 0.6535\n",
      "Epoch 8/10\n",
      "3062/3062 [==============================] - 0s 107us/step - loss: 0.6268 - acc: 0.6440\n",
      "Epoch 9/10\n",
      "3062/3062 [==============================] - 0s 99us/step - loss: 0.6246 - acc: 0.6548\n",
      "Epoch 10/10\n",
      "3062/3062 [==============================] - 0s 100us/step - loss: 0.6261 - acc: 0.6519\n",
      "Epoch 1/10\n",
      "3062/3062 [==============================] - 0s 100us/step - loss: 0.6388 - acc: 0.6375\n",
      "Epoch 2/10\n",
      "3062/3062 [==============================] - 0s 110us/step - loss: 0.6349 - acc: 0.6437\n",
      "Epoch 3/10\n",
      "3062/3062 [==============================] - 0s 105us/step - loss: 0.6344 - acc: 0.6398\n",
      "Epoch 4/10\n",
      "3062/3062 [==============================] - 0s 99us/step - loss: 0.6325 - acc: 0.6463\n",
      "Epoch 5/10\n",
      "3062/3062 [==============================] - 0s 112us/step - loss: 0.6328 - acc: 0.6411\n",
      "Epoch 6/10\n",
      "3062/3062 [==============================] - 0s 110us/step - loss: 0.6337 - acc: 0.6427\n",
      "Epoch 7/10\n",
      "3062/3062 [==============================] - 0s 99us/step - loss: 0.6331 - acc: 0.6450\n",
      "Epoch 8/10\n",
      "3062/3062 [==============================] - 0s 99us/step - loss: 0.6327 - acc: 0.6473\n",
      "Epoch 9/10\n",
      "3062/3062 [==============================] - 0s 102us/step - loss: 0.6338 - acc: 0.6414\n",
      "Epoch 10/10\n",
      "3062/3062 [==============================] - 0s 118us/step - loss: 0.6328 - acc: 0.6509\n",
      "Epoch 1/10\n",
      "3062/3062 [==============================] - 0s 95us/step - loss: 0.6446 - acc: 0.6234\n",
      "Epoch 2/10\n",
      "3062/3062 [==============================] - 0s 108us/step - loss: 0.6408 - acc: 0.6362\n",
      "Epoch 3/10\n",
      "3062/3062 [==============================] - 0s 95us/step - loss: 0.6392 - acc: 0.6385\n",
      "Epoch 4/10\n",
      "3062/3062 [==============================] - 0s 93us/step - loss: 0.6394 - acc: 0.6300\n",
      "Epoch 5/10\n",
      "3062/3062 [==============================] - 0s 99us/step - loss: 0.6389 - acc: 0.6306\n",
      "Epoch 6/10\n",
      "3062/3062 [==============================] - 0s 98us/step - loss: 0.6384 - acc: 0.6332\n",
      "Epoch 7/10\n",
      "3062/3062 [==============================] - 0s 82us/step - loss: 0.6384 - acc: 0.6323\n",
      "Epoch 8/10\n",
      "3062/3062 [==============================] - 0s 95us/step - loss: 0.6386 - acc: 0.6326\n",
      "Epoch 9/10\n",
      "3062/3062 [==============================] - 0s 107us/step - loss: 0.6380 - acc: 0.6368\n",
      "Epoch 10/10\n",
      "3062/3062 [==============================] - 0s 101us/step - loss: 0.6386 - acc: 0.6332\n",
      "Epoch 1/10\n",
      "3062/3062 [==============================] - 0s 110us/step - loss: 0.6383 - acc: 0.6267\n",
      "Epoch 2/10\n",
      "3062/3062 [==============================] - 0s 97us/step - loss: 0.6364 - acc: 0.6375\n",
      "Epoch 3/10\n",
      "3062/3062 [==============================] - 0s 104us/step - loss: 0.6359 - acc: 0.6336\n",
      "Epoch 4/10\n",
      "3062/3062 [==============================] - 0s 103us/step - loss: 0.6363 - acc: 0.6359\n",
      "Epoch 5/10\n",
      "3062/3062 [==============================] - 0s 87us/step - loss: 0.6355 - acc: 0.6332\n",
      "Epoch 6/10\n",
      "3062/3062 [==============================] - 0s 99us/step - loss: 0.6353 - acc: 0.6352\n",
      "Epoch 7/10\n",
      "3062/3062 [==============================] - 0s 97us/step - loss: 0.6360 - acc: 0.6395\n",
      "Epoch 8/10\n",
      "3062/3062 [==============================] - 0s 96us/step - loss: 0.6345 - acc: 0.6355\n",
      "Epoch 9/10\n",
      "3062/3062 [==============================] - 0s 101us/step - loss: 0.6345 - acc: 0.6372\n",
      "Epoch 10/10\n",
      "3062/3062 [==============================] - 0s 90us/step - loss: 0.6343 - acc: 0.6323\n",
      "Epoch 1/10\n",
      "3062/3062 [==============================] - 0s 101us/step - loss: 0.6315 - acc: 0.6444\n",
      "Epoch 2/10\n",
      "3062/3062 [==============================] - 0s 102us/step - loss: 0.6297 - acc: 0.6483\n",
      "Epoch 3/10\n",
      "3062/3062 [==============================] - 0s 106us/step - loss: 0.6279 - acc: 0.6509\n",
      "Epoch 4/10\n",
      "3062/3062 [==============================] - 0s 107us/step - loss: 0.6283 - acc: 0.6453\n",
      "Epoch 5/10\n",
      "3062/3062 [==============================] - 0s 103us/step - loss: 0.6274 - acc: 0.6496\n",
      "Epoch 6/10\n",
      "3062/3062 [==============================] - 0s 110us/step - loss: 0.6280 - acc: 0.6525\n",
      "Epoch 7/10\n",
      "3062/3062 [==============================] - 0s 107us/step - loss: 0.6259 - acc: 0.6587\n",
      "Epoch 8/10\n",
      "3062/3062 [==============================] - 0s 103us/step - loss: 0.6274 - acc: 0.6450\n",
      "Epoch 9/10\n",
      "3062/3062 [==============================] - 0s 104us/step - loss: 0.6277 - acc: 0.6375\n",
      "Epoch 10/10\n",
      "3062/3062 [==============================] - 0s 108us/step - loss: 0.6268 - acc: 0.6496\n",
      "Epoch 1/10\n",
      "3062/3062 [==============================] - 0s 110us/step - loss: 0.6388 - acc: 0.6411\n",
      "Epoch 2/10\n",
      "3062/3062 [==============================] - 0s 105us/step - loss: 0.6352 - acc: 0.6342\n",
      "Epoch 3/10\n",
      "3062/3062 [==============================] - 0s 95us/step - loss: 0.6347 - acc: 0.6316\n",
      "Epoch 4/10\n",
      "3062/3062 [==============================] - 0s 98us/step - loss: 0.6337 - acc: 0.6362\n",
      "Epoch 5/10\n",
      "3062/3062 [==============================] - 0s 106us/step - loss: 0.6328 - acc: 0.6378\n",
      "Epoch 6/10\n",
      "3062/3062 [==============================] - 0s 95us/step - loss: 0.6349 - acc: 0.6362\n",
      "Epoch 7/10\n",
      "3062/3062 [==============================] - 0s 104us/step - loss: 0.6325 - acc: 0.6336\n",
      "Epoch 8/10\n",
      "3062/3062 [==============================] - 0s 97us/step - loss: 0.6331 - acc: 0.6342\n",
      "Epoch 9/10\n",
      "3062/3062 [==============================] - 0s 112us/step - loss: 0.6336 - acc: 0.6398\n",
      "Epoch 10/10\n",
      "3062/3062 [==============================] - 0s 105us/step - loss: 0.6337 - acc: 0.6368\n",
      "Epoch 1/10\n",
      "3062/3062 [==============================] - 0s 100us/step - loss: 0.6342 - acc: 0.6339\n",
      "Epoch 2/10\n",
      "3062/3062 [==============================] - 0s 104us/step - loss: 0.6304 - acc: 0.6453\n",
      "Epoch 3/10\n",
      "3062/3062 [==============================] - 0s 108us/step - loss: 0.6295 - acc: 0.6414\n",
      "Epoch 4/10\n",
      "3062/3062 [==============================] - 0s 103us/step - loss: 0.6277 - acc: 0.6381\n",
      "Epoch 5/10\n",
      "3062/3062 [==============================] - 0s 106us/step - loss: 0.6276 - acc: 0.6434\n",
      "Epoch 6/10\n",
      "3062/3062 [==============================] - 0s 105us/step - loss: 0.6282 - acc: 0.6414\n",
      "Epoch 7/10\n",
      "3062/3062 [==============================] - 0s 109us/step - loss: 0.6274 - acc: 0.6447\n",
      "Epoch 8/10\n",
      "3062/3062 [==============================] - 0s 111us/step - loss: 0.6278 - acc: 0.6388\n",
      "Epoch 9/10\n",
      "3062/3062 [==============================] - 0s 113us/step - loss: 0.6273 - acc: 0.6388\n",
      "Epoch 10/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3062/3062 [==============================] - 0s 103us/step - loss: 0.6277 - acc: 0.6388\n",
      "Epoch 1/10\n",
      "3062/3062 [==============================] - 0s 96us/step - loss: 0.6372 - acc: 0.6283\n",
      "Epoch 2/10\n",
      "3062/3062 [==============================] - 0s 109us/step - loss: 0.6341 - acc: 0.6303\n",
      "Epoch 3/10\n",
      "3062/3062 [==============================] - 0s 105us/step - loss: 0.6324 - acc: 0.6362\n",
      "Epoch 4/10\n",
      "3062/3062 [==============================] - 0s 111us/step - loss: 0.6318 - acc: 0.6362\n",
      "Epoch 5/10\n",
      "3062/3062 [==============================] - 0s 103us/step - loss: 0.6316 - acc: 0.6381\n",
      "Epoch 6/10\n",
      "3062/3062 [==============================] - 0s 96us/step - loss: 0.6315 - acc: 0.6395\n",
      "Epoch 7/10\n",
      "3062/3062 [==============================] - 0s 94us/step - loss: 0.6311 - acc: 0.6440\n",
      "Epoch 8/10\n",
      "3062/3062 [==============================] - 0s 107us/step - loss: 0.6317 - acc: 0.6381\n",
      "Epoch 9/10\n",
      "3062/3062 [==============================] - 0s 105us/step - loss: 0.6307 - acc: 0.6440\n",
      "Epoch 10/10\n",
      "3062/3062 [==============================] - 0s 102us/step - loss: 0.6306 - acc: 0.6424\n",
      "Epoch 1/10\n",
      "3062/3062 [==============================] - 0s 95us/step - loss: 0.6204 - acc: 0.6479\n",
      "Epoch 2/10\n",
      "3062/3062 [==============================] - 0s 110us/step - loss: 0.6178 - acc: 0.6489\n",
      "Epoch 3/10\n",
      "3062/3062 [==============================] - 0s 109us/step - loss: 0.6160 - acc: 0.6512\n",
      "Epoch 4/10\n",
      "3062/3062 [==============================] - 0s 104us/step - loss: 0.6155 - acc: 0.6555\n",
      "Epoch 5/10\n",
      "3062/3062 [==============================] - 0s 109us/step - loss: 0.6162 - acc: 0.6594\n",
      "Epoch 6/10\n",
      "3062/3062 [==============================] - 0s 107us/step - loss: 0.6155 - acc: 0.6571\n",
      "Epoch 7/10\n",
      "3062/3062 [==============================] - 0s 116us/step - loss: 0.6148 - acc: 0.6555\n",
      "Epoch 8/10\n",
      "3062/3062 [==============================] - 0s 105us/step - loss: 0.6148 - acc: 0.6636\n",
      "Epoch 9/10\n",
      "3062/3062 [==============================] - 0s 102us/step - loss: 0.6157 - acc: 0.6528\n",
      "Epoch 10/10\n",
      "3062/3062 [==============================] - 0s 97us/step - loss: 0.6154 - acc: 0.6584\n",
      "Epoch 1/10\n",
      "3062/3062 [==============================] - 0s 97us/step - loss: 0.6336 - acc: 0.6319\n",
      "Epoch 2/10\n",
      "3062/3062 [==============================] - 0s 105us/step - loss: 0.6314 - acc: 0.6372\n",
      "Epoch 3/10\n",
      "3062/3062 [==============================] - 0s 100us/step - loss: 0.6295 - acc: 0.6368\n",
      "Epoch 4/10\n",
      "3062/3062 [==============================] - 0s 107us/step - loss: 0.6292 - acc: 0.6450\n",
      "Epoch 5/10\n",
      "3062/3062 [==============================] - 0s 102us/step - loss: 0.6291 - acc: 0.6362\n",
      "Epoch 6/10\n",
      "3062/3062 [==============================] - 0s 89us/step - loss: 0.6287 - acc: 0.6427\n",
      "Epoch 7/10\n",
      "3062/3062 [==============================] - 0s 97us/step - loss: 0.6274 - acc: 0.6457\n",
      "Epoch 8/10\n",
      "3062/3062 [==============================] - 0s 92us/step - loss: 0.6282 - acc: 0.6444\n",
      "Epoch 9/10\n",
      "3062/3062 [==============================] - 0s 96us/step - loss: 0.6285 - acc: 0.6408\n",
      "Epoch 10/10\n",
      "3062/3062 [==============================] - 0s 100us/step - loss: 0.6280 - acc: 0.6417\n",
      "Epoch 1/10\n",
      "3062/3062 [==============================] - 0s 89us/step - loss: 0.6375 - acc: 0.6251\n",
      "Epoch 2/10\n",
      "3062/3062 [==============================] - 0s 92us/step - loss: 0.6313 - acc: 0.6368\n",
      "Epoch 3/10\n",
      "3062/3062 [==============================] - 0s 92us/step - loss: 0.6299 - acc: 0.6297\n",
      "Epoch 4/10\n",
      "3062/3062 [==============================] - 0s 98us/step - loss: 0.6285 - acc: 0.6385\n",
      "Epoch 5/10\n",
      "3062/3062 [==============================] - 0s 99us/step - loss: 0.6276 - acc: 0.6352\n",
      "Epoch 6/10\n",
      "3062/3062 [==============================] - 0s 93us/step - loss: 0.6283 - acc: 0.6381\n",
      "Epoch 7/10\n",
      "3062/3062 [==============================] - 0s 105us/step - loss: 0.6269 - acc: 0.6342\n",
      "Epoch 8/10\n",
      "3062/3062 [==============================] - 0s 102us/step - loss: 0.6272 - acc: 0.6375\n",
      "Epoch 9/10\n",
      "3062/3062 [==============================] - 0s 106us/step - loss: 0.6268 - acc: 0.6391\n",
      "Epoch 10/10\n",
      "3062/3062 [==============================] - 0s 103us/step - loss: 0.6274 - acc: 0.6388\n",
      "200000/200000 [==============================] - 4s 19us/step\n",
      "(200000, 2)\n",
      "---------test---------\n",
      "Confusion Matrix:\n",
      "True Negative = 124780\n",
      "False Negative = 128\n",
      "True Positive = 249\n",
      "False Positive = 74843\n",
      "f1 score = 0.007\n",
      "ROC Score = 0.643\n"
     ]
    }
   ],
   "source": [
    "def base_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(88, kernel_initializer='glorot_uniform', input_shape=(88,)))\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=SGD(lr=0.01),\n",
    "                  metrics=['accuracy'])\n",
    "    return model;\n",
    "\n",
    "def model_fit(model, X, y):\n",
    "    model.fit(X, y,\n",
    "              batch_size=batch_size,\n",
    "              epochs=10,\n",
    "#               validation_split=0.2,\n",
    "              verbose=1)\n",
    "    return model\n",
    "\n",
    "model = deep_ensemble(base_model, model_fit, bc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With validation split, we can see that there is overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting sample\n",
      "(10, 3062, 88) (10, 3062)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_26 (Dense)             (None, 88)                7832      \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 2)                 178       \n",
      "=================================================================\n",
      "Total params: 8,010\n",
      "Trainable params: 8,010\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "training\n",
      "(3062, 88) (3062,)\n",
      "(30620, 88) (30620,)\n",
      "Epoch 1/10\n",
      "30620/30620 [==============================] - 4s 117us/step - loss: 1.2666 - acc: 0.6315\n",
      "Epoch 2/10\n",
      "30620/30620 [==============================] - 3s 111us/step - loss: 0.9214 - acc: 0.6415\n",
      "Epoch 3/10\n",
      "30620/30620 [==============================] - 3s 109us/step - loss: 0.7649 - acc: 0.6417\n",
      "Epoch 4/10\n",
      "30620/30620 [==============================] - 3s 101us/step - loss: 0.6935 - acc: 0.6423\n",
      "Epoch 5/10\n",
      "30620/30620 [==============================] - 3s 95us/step - loss: 0.6605 - acc: 0.6419\n",
      "Epoch 6/10\n",
      "30620/30620 [==============================] - 3s 100us/step - loss: 0.6453 - acc: 0.6431\n",
      "Epoch 7/10\n",
      "30620/30620 [==============================] - 3s 99us/step - loss: 0.6382 - acc: 0.6430\n",
      "Epoch 8/10\n",
      "30620/30620 [==============================] - 3s 106us/step - loss: 0.6346 - acc: 0.6432\n",
      "Epoch 9/10\n",
      "30620/30620 [==============================] - 3s 114us/step - loss: 0.6334 - acc: 0.6428\n",
      "Epoch 10/10\n",
      "30620/30620 [==============================] - 3s 106us/step - loss: 0.6327 - acc: 0.6421\n",
      "200000/200000 [==============================] - 4s 21us/step\n",
      "(200000, 2)\n",
      "---------test---------\n",
      "Confusion Matrix:\n",
      "True Negative = 132306\n",
      "False Negative = 126\n",
      "True Positive = 251\n",
      "False Positive = 67317\n",
      "f1 score = 0.007\n",
      "ROC Score = 0.664\n"
     ]
    }
   ],
   "source": [
    "def base_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(88, kernel_initializer='glorot_uniform', kernel_regularizer=l2(0.01),\n",
    "                    input_shape=(88,)))\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=SGD(lr=0.01),\n",
    "                  metrics=['accuracy'])\n",
    "    return model;\n",
    "\n",
    "def model_fit(model, X, y):\n",
    "    model.fit(X, y,\n",
    "              batch_size=batch_size,\n",
    "              epochs=10,\n",
    "#               validation_split=0.2,\n",
    "              verbose=1)\n",
    "    return model\n",
    "\n",
    "model = deep_ensemble_merged(base_model, model_fit, bc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting sample\n",
      "(10, 3062, 88) (10, 3062)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_34 (Dense)             (None, 88)                7832      \n",
      "_________________________________________________________________\n",
      "dropout_23 (Dropout)         (None, 88)                0         \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 64)                5696      \n",
      "_________________________________________________________________\n",
      "dropout_24 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 13,658\n",
      "Trainable params: 13,658\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "training\n",
      "(3062, 88) (3062,)\n",
      "(30620, 88) (30620,)\n",
      "Train on 24496 samples, validate on 6124 samples\n",
      "Epoch 1/20\n",
      "24496/24496 [==============================] - 4s 175us/step - loss: 34.1834 - acc: 0.5987 - val_loss: 3.7535 - val_acc: 0.6568\n",
      "Epoch 2/20\n",
      "24496/24496 [==============================] - 3s 141us/step - loss: 1.3166 - acc: 0.6592 - val_loss: 0.6681 - val_acc: 0.6703\n",
      "Epoch 3/20\n",
      "24496/24496 [==============================] - 4s 147us/step - loss: 0.6546 - acc: 0.6699 - val_loss: 0.6365 - val_acc: 0.6813\n",
      "Epoch 4/20\n",
      "24496/24496 [==============================] - 3s 138us/step - loss: 0.6366 - acc: 0.6769 - val_loss: 0.6277 - val_acc: 0.6850\n",
      "Epoch 5/20\n",
      "24496/24496 [==============================] - 4s 143us/step - loss: 0.6297 - acc: 0.6800 - val_loss: 0.6227 - val_acc: 0.6865\n",
      "Epoch 6/20\n",
      "24496/24496 [==============================] - 4s 147us/step - loss: 0.6248 - acc: 0.6851 - val_loss: 0.6189 - val_acc: 0.6884\n",
      "Epoch 7/20\n",
      "24496/24496 [==============================] - 4s 148us/step - loss: 0.6211 - acc: 0.6855 - val_loss: 0.6161 - val_acc: 0.6914\n",
      "Epoch 8/20\n",
      "24496/24496 [==============================] - 4s 144us/step - loss: 0.6181 - acc: 0.6897 - val_loss: 0.6138 - val_acc: 0.6914\n",
      "Epoch 9/20\n",
      "24496/24496 [==============================] - 4s 144us/step - loss: 0.6152 - acc: 0.6929 - val_loss: 0.6120 - val_acc: 0.6950\n",
      "Epoch 10/20\n",
      "24496/24496 [==============================] - 4s 154us/step - loss: 0.6151 - acc: 0.6926 - val_loss: 0.6105 - val_acc: 0.6937\n",
      "Epoch 11/20\n",
      "24496/24496 [==============================] - 4s 150us/step - loss: 0.6149 - acc: 0.6921 - val_loss: 0.6090 - val_acc: 0.6960\n",
      "Epoch 12/20\n",
      "24496/24496 [==============================] - 4s 146us/step - loss: 0.6114 - acc: 0.6937 - val_loss: 0.6077 - val_acc: 0.6961\n",
      "Epoch 13/20\n",
      "24496/24496 [==============================] - 4s 151us/step - loss: 0.6110 - acc: 0.6953 - val_loss: 0.6067 - val_acc: 0.6973\n",
      "Epoch 14/20\n",
      "24496/24496 [==============================] - 4s 144us/step - loss: 0.6085 - acc: 0.6969 - val_loss: 0.6057 - val_acc: 0.6960\n",
      "Epoch 15/20\n",
      "24496/24496 [==============================] - 3s 138us/step - loss: 0.6084 - acc: 0.6974 - val_loss: 0.6047 - val_acc: 0.6984\n",
      "Epoch 16/20\n",
      "24496/24496 [==============================] - 3s 138us/step - loss: 0.6076 - acc: 0.6988 - val_loss: 0.6038 - val_acc: 0.6987\n",
      "Epoch 17/20\n",
      "24496/24496 [==============================] - 4s 147us/step - loss: 0.6062 - acc: 0.6986 - val_loss: 0.6032 - val_acc: 0.6997\n",
      "Epoch 18/20\n",
      "24496/24496 [==============================] - 4s 157us/step - loss: 0.6062 - acc: 0.6998 - val_loss: 0.6024 - val_acc: 0.6997\n",
      "Epoch 19/20\n",
      "24496/24496 [==============================] - 4s 146us/step - loss: 0.6036 - acc: 0.7012 - val_loss: 0.6017 - val_acc: 0.7015\n",
      "Epoch 20/20\n",
      "24496/24496 [==============================] - 4s 148us/step - loss: 0.6040 - acc: 0.6996 - val_loss: 0.6012 - val_acc: 0.7030\n",
      "200000/200000 [==============================] - 5s 25us/step\n",
      "(200000, 2)\n",
      "---------test---------\n",
      "Confusion Matrix:\n",
      "True Negative = 128639\n",
      "False Negative = 139\n",
      "True Positive = 238\n",
      "False Positive = 70984\n",
      "f1 score = 0.007\n",
      "ROC Score = 0.638\n"
     ]
    }
   ],
   "source": [
    "def base_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(88, activation='relu',\n",
    "                    kernel_initializer='glorot_uniform', kernel_regularizer=l2(0.01),\n",
    "                    input_shape=(88,)))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(64, kernel_initializer=RandomNormal(mean=2.0), kernel_regularizer=l2(0.01)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=RMSprop(lr=0.01, decay=0.02),\n",
    "                  metrics=['accuracy'])\n",
    "    return model;\n",
    "\n",
    "def model_fit(model, X, y):\n",
    "    model.fit(X, y,\n",
    "              batch_size=batch_size,\n",
    "              epochs=20,\n",
    "              callbacks=[EarlyStopping(patience=2)],\n",
    "              validation_split=0.2,\n",
    "              verbose=1)\n",
    "    return model\n",
    "\n",
    "smote = SMOTE(ratio={0: 306200, 1: 306200}, n_jobs=-1, random_state=KFOLD_SEED)\n",
    "model = deep_ensemble_merged(base_model, model_fit, bc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(88, 64) (64,)\n",
      "0.0011367296 -0.04796268\n"
     ]
    }
   ],
   "source": [
    "w = model.get_layer(name='dense_26').get_weights()\n",
    "print(w[0].shape, w[1].shape)\n",
    "print(np.mean(w[0]), np.mean(w[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200000, 2) (200000,)\n"
     ]
    }
   ],
   "source": [
    "predicted_scores = model.predict(test_features)\n",
    "predicted_labels = predicted_scores.argmax(axis=-1)\n",
    "\n",
    "print(predicted_scores.shape, predicted_labels.shape)\n",
    "\n",
    "false_positive_scores = np.array([])\n",
    "false_negative_scores = np.array([])\n",
    "true_positive_scores = np.array([])\n",
    "true_negative_scores = np.array([])\n",
    "\n",
    "for i, s in enumerate(predicted_scores):\n",
    "    # False positive\n",
    "    if predicted_labels[i] == 1 and test_labels[i] == 0:\n",
    "        false_positive_scores = np.append(false_positive_scores, s[1])\n",
    "    # False negative\n",
    "    elif predicted_labels[i] == 0 and test_labels[i] == 1:\n",
    "        false_negative_scores = np.append(false_negative_scores, s[1])\n",
    "    # True positive\n",
    "    elif predicted_labels[i] == 1 and test_labels[i] == 1:\n",
    "        true_positive_scores = np.append(true_positive_scores, s[1])\n",
    "    # True negative\n",
    "    else:\n",
    "        true_negative_scores = np.append(true_negative_scores, s[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5354089736938477 0.6013307273387909\n",
      "0.3806043416261673\n",
      "0.5638539671897889 0.6640639901161194\n",
      "0.34379687905311584\n"
     ]
    }
   ],
   "source": [
    "# If threshold = 0.60, can catch an additional 10% of false positives\n",
    "print(np.percentile(false_positive_scores, 20), np.median(false_positive_scores))\n",
    "print(np.median(false_negative_scores))\n",
    "# If threshold = 0.66, can capture an additional 10% of true positives\n",
    "print(np.percentile(true_positive_scores, 20), np.median(true_positive_scores))\n",
    "print(np.median(true_negative_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5714545  0.5183983  0.46809098 0.18678115 0.38346967]\n",
      "---------test---------\n",
      "Confusion Matrix:\n",
      "True Negative = 146422\n",
      "False Negative = 158\n",
      "True Positive = 219\n",
      "False Positive = 53201\n",
      "f1 score = 0.008\n",
      "ROC Score = 0.657\n"
     ]
    }
   ],
   "source": [
    "print_metrics(test_labels, predicted_scores, score_to_label_threshold=0.52)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\teval-auc:0.5\ttrain-auc:0.500325\n",
      "Multiple eval metrics have been passed: 'train-auc' will be used for early stopping.\n",
      "\n",
      "Will train until train-auc hasn't improved in 5 rounds.\n",
      "[1]\teval-auc:0.5\ttrain-auc:0.500325\n",
      "[2]\teval-auc:0.499997\ttrain-auc:0.500648\n",
      "[3]\teval-auc:0.499997\ttrain-auc:0.500648\n",
      "[4]\teval-auc:0.499997\ttrain-auc:0.500648\n",
      "[5]\teval-auc:0.633761\ttrain-auc:0.641557\n",
      "[6]\teval-auc:0.641761\ttrain-auc:0.65134\n",
      "[7]\teval-auc:0.646147\ttrain-auc:0.656013\n",
      "[8]\teval-auc:0.646284\ttrain-auc:0.65658\n",
      "[9]\teval-auc:0.646614\ttrain-auc:0.657321\n",
      "[10]\teval-auc:0.648449\ttrain-auc:0.658278\n",
      "[11]\teval-auc:0.650978\ttrain-auc:0.659813\n",
      "[12]\teval-auc:0.650799\ttrain-auc:0.660001\n",
      "[13]\teval-auc:0.652829\ttrain-auc:0.663415\n",
      "[14]\teval-auc:0.656153\ttrain-auc:0.664207\n",
      "[15]\teval-auc:0.655381\ttrain-auc:0.664069\n",
      "[16]\teval-auc:0.654507\ttrain-auc:0.665269\n",
      "[17]\teval-auc:0.653276\ttrain-auc:0.664303\n",
      "[18]\teval-auc:0.653398\ttrain-auc:0.665308\n",
      "[19]\teval-auc:0.653341\ttrain-auc:0.665401\n"
     ]
    }
   ],
   "source": [
    "dtrain = xgb.DMatrix(features, labels)\n",
    "dtest = xgb.DMatrix(test_features, test_labels)\n",
    "\n",
    "params = {'max_depth':3, 'eta':0.1, 'objective':'binary:logistic',\n",
    "         'nthread': 4, 'eval_metric':'auc'}\n",
    "evallist = [(dtest, 'eval'), (dtrain, 'train')]\n",
    "\n",
    "num_round = 20\n",
    "bst = xgb.train(params, dtrain, num_round, evallist, early_stopping_rounds=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200000,)\n",
      "[0.06797221 0.06806614 0.06659859 0.06659859 0.06668172]\n",
      "(200000,)\n",
      "Confusion Matrix:\n",
      "True Negative = 199623\n",
      "False Negative = 377\n",
      "True Positive = 0\n",
      "False Positive = 0\n",
      "f1 score = 0.000\n",
      "ROC Score = 0.500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.local/share/virtualenvs/RTB-V2Lvgo6A/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "y_scores = bst.predict(dtest)\n",
    "\n",
    "print(y_scores.shape)\n",
    "print(y_scores[0:5])\n",
    "print_xgb_metrics(test_labels, y_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = XGBClassifier()\n",
    "bc = BalanceCascade(estimator=xgb_model, n_max_subset=10, random_state=KFOLD_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
