{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choosing a metric\n",
    "\n",
    "I first looked at class ditribution. They are binary classes, and the dataset is highly imbalanced because the true class makes up only ~0.19% of all labels.\n",
    "\n",
    "I suspected if I just run a simple logistic regression on the dataset, I could achieve 99.81% accuracy, because the model can simply cheat by classifying every sample as 0. I ran logistic regression using sklearn with default params, and the result confirmed my hypothesis - the model predicted every sample as 0.\n",
    "\n",
    "Obviously, accuracy is a bad metric for such an imbalanced dataset, especially in the RTB context, because being able to find samples that likely will result in a click-through is more important than overall correctness. If the model predicts the majority label for every sample, precision will be perfect but recall will be 0. If the model predicts the minority label for every sample, the recall will be perfect but precision will be 1. One potential metric I can use is the f1 score, but it states that precision and recall are equally important, which in reality may not be true. If capturing most of the click-throughs are more important than serving efficiency (most of the served impressions result in click-throughs, in other words, there is no infrastructure bottlenck), then recall is more important than precision. On the other hand, if serving efficiency is more important than capturing most of click-throughs, which may be true when the scale is large, then precision is more important. But in either case, f1 score can be very low even if we are happy with the model.\n",
    "\n",
    "Without making too much an assumption of what we would want in real life, ROC AUC is a better metric to use because it depicts the tradeoff between specificity and senstivity. A large ROC AUC value indicates the model is more robust, and the optimal value should approach 1.\n",
    "\n",
    "### Baseline models\n",
    "\n",
    "#### Logistic Regression\n",
    "I reran the default logistic regression model and print ROC AUC, f1 score and the confusion matrix. I use the binary labels as predicted values rather than scores, because I didn't want ROC AUC to be skewed by precision, and ultimatly I care more about the repdiced labels than probablities\n",
    "```\n",
    "================================\n",
    "Confusion Matrix:\n",
    "True Negative = 199623\n",
    "False Negative = 377\n",
    "True Positive = 0\n",
    "False Positive = 0\n",
    "================================\n",
    "f1 score = 0.000\n",
    "================================\n",
    "ROC AUC Score = 0.500\n",
    "```\n",
    "F1 score is coerced to 0 because there are no predicted positives at all. ROC AUC score is low - just as good as a random classifier. Just for fun, I added l2 regularization `penalty='l2'`, the result is the same. The imbalance is just to strong for the model to even try to predict positives.\n",
    "\n",
    "#### Neural Net\n",
    "The baseline neural net has 1 hidden layer that outputs 88 weights for all features, and an output layer with 2 outputs, one probability for each class, with a softmax activation. Categorical crossentropy is used as loss.\n",
    "\n",
    "The model is fit with 3 epochs, and a batch size of 32. The baseline neural net should be equivalent of a logisc regression, except that I'm using the SGD optimizer, so I picked a learning rate of 0.01 (it usually worked well for me when I train baseline models). I specifically set the inital weights as `Ones`, because Keras defaults the inital weights to `glorot_uniform`, which generally works really well (and too well for a baseline model).\n",
    "\n",
    "I used set split to 0.2 for validation after each epoch.\n",
    "Both training and validation error went down, and validation error is slightly smaller than training error in all epochs, indicating there is no overfitting. \n",
    "\n",
    "Unsurprisingly, the accuracy is still 99.81%, with the vast majority of samples predicted negative. ROC AUC score is still 0.5.\n",
    "\n",
    "The result:\n",
    "```\n",
    "================================\n",
    "Confusion Matrix:\n",
    "True Negative = 199619\n",
    "False Negative = 377\n",
    "True Positive = 0\n",
    "False Positive = 4\n",
    "================================\n",
    "f1 score = 0.000\n",
    "================================\n",
    "ROC AUC Score = 0.500\n",
    "```\n",
    "\n",
    "Because I set the initial weights to `Ones`, I wanted to eliminate the possibility that my weights are exploding or diminished. After checking the hidden layer's output weights, they are all between -1 and 1. So my baseline neural net is fine, even if I remove my initial weights so that they are set to `glorot_uniform`, the result is similar, there is one true positive and more false positives\n",
    "```\n",
    "================================\n",
    "Confusion Matrix:\n",
    "True Negative = 199418\n",
    "False Negative = 376\n",
    "True Positive = 1\n",
    "False Positive = 205\n",
    "================================\n",
    "f1 score = 0.003\n",
    "================================\n",
    "ROC AUC Score = 0.501\n",
    "```\n",
    "\n",
    "### Model improvements\n",
    "I think the main obstacle to achieving higher ROC AUC is the severe data imbalance. There are a few potential migations I can try:\n",
    "\n",
    "- Deepen the neural network model\n",
    "  <p>\n",
    "    If add more layers, the model will have a chance to explore nonlinearty, which might cover the positive space.\n",
    "  </p>\n",
    "- Down sampling\n",
    "  <p>\n",
    "    The negative class can be overpowering. We could find a good class ratio so that the model can be trained for positive classes without underfitting the negative class. A side benefit is the model will take less time to train.\n",
    "  </p>\n",
    "- Over sampling\n",
    "  <p>\n",
    "    Like down sampling, the goal is to make the data more balanced. If we observe underfitting for the negative class, we can try oversampling the positive class and find a good class ratio. Oversampling can be done with random selection and duplication. This could cause overfitting for the positive class, and definitely slows down training and can increase model size.\n",
    "  </p>\n",
    "- SMOTE\n",
    "  <p>\n",
    "    We can also try a hybrid approach, down sampling negative class while generating synthetic samples for the positive class eith nearest neighbours. This could help prevent positive class overfitting. But just like oversampling, it causes the model to train slower and the size to increase.\n",
    "  </p>\n",
    "  \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import numpy as np\n",
    "from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
    "from imblearn.under_sampling import NearMiss, RandomUnderSampler\n",
    "from imblearn.combine import SMOTEENN,SMOTETomek\n",
    "from imblearn.ensemble import BalanceCascade, EasyEnsemble\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import h5py\n",
    "import keras\n",
    "from sklearn.utils import class_weight\n",
    "from keras.utils import to_categorical\n",
    "from keras.optimizers import *\n",
    "from keras.regularizers import *\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, f1_score, precision_recall_fscore_support\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "KFOLD_SEED = 42\n",
    "\n",
    "\n",
    "def rtb_confusion_matrix(test_labels, y_preds):\n",
    "    m = confusion_matrix(test_labels, y_preds)\n",
    "    \n",
    "    print(\"================================\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(\"True Negative = %d\" % m[0][0])\n",
    "    print(\"False Negative = %d\" % m[1][0])\n",
    "    print(\"True Positive = %d\" % m[1][1])\n",
    "    print(\"False Positive = %d\" % m[0][1])\n",
    "\n",
    "\n",
    "def rtb_f1_score(test_labels, y_preds):\n",
    "    f = f1_score(test_labels, y_preds)\n",
    "    print(\"================================\")\n",
    "    print(\"f1 score = %0.3f\" % f)\n",
    "\n",
    "\n",
    "def print_metrics(true_labels, y_preds, y_scores, is_train=True):\n",
    "    if is_train:\n",
    "        print(\"--------train---------\")\n",
    "    else:\n",
    "        print(\"--------test---------\")\n",
    "    \n",
    "    rtb_confusion_matrix(true_labels, y_preds)\n",
    "    rtb_f1_score(true_labels, y_preds)\n",
    "    print(\"================================\")\n",
    "    print(\"ROC AUC Score = %0.3f\" % roc_auc_score(true_labels, y_scores.argmax(axis=-1)))\n",
    "    \n",
    "def keras_print_metrics(true_labels, y_scores, is_train=True):\n",
    "    y_preds = y_scores.argmax(axis=-1)\n",
    "    \n",
    "    if is_train:\n",
    "        print(\"--------train---------\")\n",
    "    else:\n",
    "        print(\"--------test---------\")\n",
    "    \n",
    "    rtb_confusion_matrix(true_labels, y_preds)\n",
    "    rtb_f1_score(true_labels, y_preds)\n",
    "    print(\"================================\")\n",
    "    print(\"ROC AUC Score = %0.3f\" % roc_auc_score(true_labels, y_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000000, 89)\n"
     ]
    }
   ],
   "source": [
    "input_path = '~/data/biddings.csv'\n",
    "data = pd.read_csv(input_path)\n",
    "print(data.shape)\n",
    "\n",
    "train = data[:800000]\n",
    "test = data[800000:]\n",
    "\n",
    "sample = train.sample(frac=1)\n",
    "features = sample.drop('convert', axis=1).values\n",
    "labels = sample.convert.ravel()\n",
    "categorical_labels = to_categorical(labels, 2)\n",
    "\n",
    "test_features = test.drop('convert', axis=1).values\n",
    "test_labels = test.convert.ravel()\n",
    "categorical_test_labels = to_categorical(test_labels, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear](200000, 2) (200000,)\n",
      "--------test---------\n",
      "================================\n",
      "Confusion Matrix:\n",
      "True Negative = 199623\n",
      "False Negative = 377\n",
      "True Positive = 0\n",
      "False Positive = 0\n",
      "================================\n",
      "f1 score = 0.000\n",
      "================================\n",
      "ROC AUC Score = 0.500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.local/share/virtualenvs/RTB-V2Lvgo6A/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(penalty='l2', random_state=KFOLD_SEED, verbose=2)\n",
    "\n",
    "model = lr.fit(features, labels)\n",
    "predicted_scores = model.predict_proba(test_features)\n",
    "predicted_labels = model.predict(test_features)\n",
    "print(predicted_scores.shape, predicted_labels.shape)\n",
    "\n",
    "print_metrics(test_labels, predicted_labels, predicted_scores, is_train=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_11 (Dense)             (None, 88)                7832      \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 2)                 178       \n",
      "=================================================================\n",
      "Total params: 8,010\n",
      "Trainable params: 8,010\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 640000 samples, validate on 160000 samples\n",
      "Epoch 1/3\n",
      "640000/640000 [==============================] - 39s 61us/step - loss: 0.0321 - acc: 0.9964 - val_loss: 0.0300 - val_acc: 0.9970\n",
      "Epoch 2/3\n",
      "640000/640000 [==============================] - 39s 61us/step - loss: 0.0279 - acc: 0.9972 - val_loss: 0.0300 - val_acc: 0.9970\n",
      "Epoch 3/3\n",
      "640000/640000 [==============================] - 40s 62us/step - loss: 0.0279 - acc: 0.9972 - val_loss: 0.0300 - val_acc: 0.9970\n",
      "200000/200000 [==============================] - 4s 19us/step\n",
      "--------train---------\n",
      "================================\n",
      "Confusion Matrix:\n",
      "True Negative = 199418\n",
      "False Negative = 376\n",
      "True Positive = 1\n",
      "False Positive = 205\n",
      "================================\n",
      "f1 score = 0.003\n",
      "================================\n",
      "ROC AUC Score = 0.501\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(88, input_shape=(88,)))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=SGD(lr=0.01),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(features, categorical_labels,\n",
    "                    batch_size=32,\n",
    "                    epochs=3,\n",
    "                    callbacks=[keras.callbacks.EarlyStopping()],\n",
    "                    validation_split=0.2,\n",
    "                    verbose=1)\n",
    "\n",
    "y_scores = model.predict(test_features, verbose=1)\n",
    "\n",
    "keras_print_metrics(test_labels, y_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = model.get_layer(name='dense_10').get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression():\n",
    "    lr = LogisticRegression(penalty='l2', random_state=KFOLD_SEED, verbose=2)\n",
    "    return lr\n",
    "    \n",
    "\n",
    "def ensembler_test(classifier_fn, ensemblers):\n",
    "    rus = RandomUnderSampler(ratio={0: 1531*10, 1: 1531}, random_state=KFOLD_SEED)\n",
    "    X_us, y_us = rus.fit_sample(features, labels)\n",
    "    \n",
    "    for i, e in enumerate(ensemblers):\n",
    "        print(\"fitting sample\")\n",
    "        X_res, y_res = e.fit_sample(X_us, y_us)\n",
    "        print(X_res.shape, y_res.shape)\n",
    "        clf = classifier_fn()\n",
    "        print(\"training\")\n",
    "        \n",
    "        for j, X_train in enumerate(X_res):\n",
    "            model = clf.fit(X_train, y_res[j])\n",
    "        \n",
    "        predicted_scores = model.predict_proba(test_features)\n",
    "        predicted_labels = model.predict(test_features)\n",
    "        \n",
    "        print(\"Ensembler %d\" % i)\n",
    "        print_metrics(test_labels, predicted_labels, predicted_scores, is_train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EasyEnsemble and decision tree are consistenly the best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting sample\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.local/share/virtualenvs/RTB-V2Lvgo6A/lib/python3.5/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/root/.local/share/virtualenvs/RTB-V2Lvgo6A/lib/python3.5/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/root/.local/share/virtualenvs/RTB-V2Lvgo6A/lib/python3.5/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/root/.local/share/virtualenvs/RTB-V2Lvgo6A/lib/python3.5/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/root/.local/share/virtualenvs/RTB-V2Lvgo6A/lib/python3.5/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/root/.local/share/virtualenvs/RTB-V2Lvgo6A/lib/python3.5/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/root/.local/share/virtualenvs/RTB-V2Lvgo6A/lib/python3.5/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/root/.local/share/virtualenvs/RTB-V2Lvgo6A/lib/python3.5/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/root/.local/share/virtualenvs/RTB-V2Lvgo6A/lib/python3.5/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/root/.local/share/virtualenvs/RTB-V2Lvgo6A/lib/python3.5/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/root/.local/share/virtualenvs/RTB-V2Lvgo6A/lib/python3.5/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/root/.local/share/virtualenvs/RTB-V2Lvgo6A/lib/python3.5/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/root/.local/share/virtualenvs/RTB-V2Lvgo6A/lib/python3.5/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/root/.local/share/virtualenvs/RTB-V2Lvgo6A/lib/python3.5/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/root/.local/share/virtualenvs/RTB-V2Lvgo6A/lib/python3.5/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/root/.local/share/virtualenvs/RTB-V2Lvgo6A/lib/python3.5/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/root/.local/share/virtualenvs/RTB-V2Lvgo6A/lib/python3.5/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/root/.local/share/virtualenvs/RTB-V2Lvgo6A/lib/python3.5/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/root/.local/share/virtualenvs/RTB-V2Lvgo6A/lib/python3.5/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/root/.local/share/virtualenvs/RTB-V2Lvgo6A/lib/python3.5/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/root/.local/share/virtualenvs/RTB-V2Lvgo6A/lib/python3.5/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/root/.local/share/virtualenvs/RTB-V2Lvgo6A/lib/python3.5/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/root/.local/share/virtualenvs/RTB-V2Lvgo6A/lib/python3.5/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/root/.local/share/virtualenvs/RTB-V2Lvgo6A/lib/python3.5/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/root/.local/share/virtualenvs/RTB-V2Lvgo6A/lib/python3.5/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/root/.local/share/virtualenvs/RTB-V2Lvgo6A/lib/python3.5/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/root/.local/share/virtualenvs/RTB-V2Lvgo6A/lib/python3.5/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.local/share/virtualenvs/RTB-V2Lvgo6A/lib/python3.5/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/root/.local/share/virtualenvs/RTB-V2Lvgo6A/lib/python3.5/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/root/.local/share/virtualenvs/RTB-V2Lvgo6A/lib/python3.5/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/root/.local/share/virtualenvs/RTB-V2Lvgo6A/lib/python3.5/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/root/.local/share/virtualenvs/RTB-V2Lvgo6A/lib/python3.5/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/root/.local/share/virtualenvs/RTB-V2Lvgo6A/lib/python3.5/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/root/.local/share/virtualenvs/RTB-V2Lvgo6A/lib/python3.5/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/root/.local/share/virtualenvs/RTB-V2Lvgo6A/lib/python3.5/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/root/.local/share/virtualenvs/RTB-V2Lvgo6A/lib/python3.5/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/root/.local/share/virtualenvs/RTB-V2Lvgo6A/lib/python3.5/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/root/.local/share/virtualenvs/RTB-V2Lvgo6A/lib/python3.5/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/root/.local/share/virtualenvs/RTB-V2Lvgo6A/lib/python3.5/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/root/.local/share/virtualenvs/RTB-V2Lvgo6A/lib/python3.5/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/root/.local/share/virtualenvs/RTB-V2Lvgo6A/lib/python3.5/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/root/.local/share/virtualenvs/RTB-V2Lvgo6A/lib/python3.5/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/root/.local/share/virtualenvs/RTB-V2Lvgo6A/lib/python3.5/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/root/.local/share/virtualenvs/RTB-V2Lvgo6A/lib/python3.5/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/root/.local/share/virtualenvs/RTB-V2Lvgo6A/lib/python3.5/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/root/.local/share/virtualenvs/RTB-V2Lvgo6A/lib/python3.5/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/root/.local/share/virtualenvs/RTB-V2Lvgo6A/lib/python3.5/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/root/.local/share/virtualenvs/RTB-V2Lvgo6A/lib/python3.5/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/root/.local/share/virtualenvs/RTB-V2Lvgo6A/lib/python3.5/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/root/.local/share/virtualenvs/RTB-V2Lvgo6A/lib/python3.5/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/root/.local/share/virtualenvs/RTB-V2Lvgo6A/lib/python3.5/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17, 3062, 88) (17, 3062)\n",
      "training\n",
      "[LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear]Ensembler 0\n",
      "--------test---------\n",
      "================================\n",
      "Confusion Matrix:\n",
      "True Negative = 102476\n",
      "False Negative = 162\n",
      "True Positive = 215\n",
      "False Positive = 97147\n",
      "================================\n",
      "f1 score = 0.004\n",
      "================================\n",
      "ROC AUC Score = 0.542\n",
      "fitting sample\n",
      "(10, 3062, 88) (10, 3062)\n",
      "training\n",
      "[LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear]Ensembler 1\n",
      "--------test---------\n",
      "================================\n",
      "Confusion Matrix:\n",
      "True Negative = 126466\n",
      "False Negative = 115\n",
      "True Positive = 262\n",
      "False Positive = 73157\n",
      "================================\n",
      "f1 score = 0.007\n",
      "================================\n",
      "ROC AUC Score = 0.664\n",
      "fitting sample\n",
      "(19, 3062, 88) (19, 3062)\n",
      "training\n",
      "[LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear]Ensembler 2\n",
      "--------test---------\n",
      "================================\n",
      "Confusion Matrix:\n",
      "True Negative = 110181\n",
      "False Negative = 151\n",
      "True Positive = 226\n",
      "False Positive = 89442\n",
      "================================\n",
      "f1 score = 0.005\n",
      "================================\n",
      "ROC AUC Score = 0.576\n",
      "fitting sample\n",
      "(17, 3062, 88) (17, 3062)\n",
      "training\n",
      "[LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear]Ensembler 3\n",
      "--------test---------\n",
      "================================\n",
      "Confusion Matrix:\n",
      "True Negative = 133218\n",
      "False Negative = 144\n",
      "True Positive = 233\n",
      "False Positive = 66405\n",
      "================================\n",
      "f1 score = 0.007\n",
      "================================\n",
      "ROC AUC Score = 0.643\n",
      "fitting sample\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15, 3062, 88) (15, 3062)\n",
      "training\n",
      "[LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear]Ensembler 4\n",
      "--------test---------\n",
      "================================\n",
      "Confusion Matrix:\n",
      "True Negative = 130478\n",
      "False Negative = 145\n",
      "True Positive = 232\n",
      "False Positive = 69145\n",
      "================================\n",
      "f1 score = 0.007\n",
      "================================\n",
      "ROC AUC Score = 0.635\n"
     ]
    }
   ],
   "source": [
    "ee = EasyEnsemble(random_state=KFOLD_SEED)\n",
    "bc = BalanceCascade(random_state=KFOLD_SEED)\n",
    "\n",
    "dt = DecisionTreeClassifier(random_state=KFOLD_SEED)\n",
    "bc_dt = BalanceCascade(estimator=dt, random_state=KFOLD_SEED)\n",
    "\n",
    "rf = RandomForestClassifier(n_jobs=-1, random_state=KFOLD_SEED, verbose=1)\n",
    "bc_rf = BalanceCascade(estimator=rf, random_state=KFOLD_SEED)\n",
    "\n",
    "xgbc = XGBClassifier()\n",
    "bc_xgbc = BalanceCascade(estimator=xgbc, random_state=KFOLD_SEED)\n",
    "\n",
    "\n",
    "ensemblers = [bc_xgbc, ee, bc, bc_dt, bc_rf]\n",
    "ensembler_test(logistic_regression, ensemblers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try to tune EasyEnsemble by adjusting subsets. It does not affect f1-score or ROC AUC socre\n",
    "```\n",
    "ee = EasyEnsemble(n_subsets = 100, random_state=KFOLD_SEED)\n",
    "ensembler_test(logistic_regression, [ee])\n",
    "\n",
    "ee = EasyEnsemble(n_subsets = 4, random_state=KFOLD_SEED)\n",
    "ensembler_test(logistic_regression, [ee])\n",
    "```\n",
    "Both result in:\n",
    "```\n",
    "================================\n",
    "Confusion Matrix:\n",
    "True Negative = 127470\n",
    "False Negative = 132\n",
    "True Positive = 245\n",
    "False Positive = 72153\n",
    "================================\n",
    "f1 score = 0.007\n",
    "================================\n",
    "ROC AUC Score = 0.644\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tune max subset for BalanceCascade with DecisionTreeClassifier\n",
    "\n",
    "10 is the best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting sample\n",
      "(17, 3062, 88) (17, 3062)\n",
      "training\n",
      "[LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear]Ensembler 0\n",
      "--------test---------\n",
      "================================\n",
      "Confusion Matrix:\n",
      "True Negative = 134778\n",
      "False Negative = 150\n",
      "True Positive = 227\n",
      "False Positive = 64845\n",
      "================================\n",
      "f1 score = 0.007\n",
      "================================\n",
      "ROC AUC Score = 0.639\n",
      "fitting sample\n",
      "(10, 3062, 88) (10, 3062)\n",
      "training\n",
      "[LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear]Ensembler 1\n",
      "--------test---------\n",
      "================================\n",
      "Confusion Matrix:\n",
      "True Negative = 131774\n",
      "False Negative = 133\n",
      "True Positive = 244\n",
      "False Positive = 67849\n",
      "================================\n",
      "f1 score = 0.007\n",
      "================================\n",
      "ROC AUC Score = 0.654\n",
      "fitting sample\n",
      "(5, 3062, 88) (5, 3062)\n",
      "training\n",
      "[LibLinear][LibLinear][LibLinear][LibLinear][LibLinear]Ensembler 2\n",
      "--------test---------\n",
      "================================\n",
      "Confusion Matrix:\n",
      "True Negative = 128482\n",
      "False Negative = 138\n",
      "True Positive = 239\n",
      "False Positive = 71141\n",
      "================================\n",
      "f1 score = 0.007\n",
      "================================\n",
      "ROC AUC Score = 0.639\n"
     ]
    }
   ],
   "source": [
    "dt_20 = DecisionTreeClassifier(random_state=KFOLD_SEED)\n",
    "bc_dt_20 = BalanceCascade(estimator=dt_20, n_max_subset=20, random_state=KFOLD_SEED)\n",
    "\n",
    "dt_10 = DecisionTreeClassifier(random_state=KFOLD_SEED)\n",
    "bc_dt_10 = BalanceCascade(estimator=dt_10, n_max_subset=10, random_state=KFOLD_SEED)\n",
    "\n",
    "dt_5 = DecisionTreeClassifier(random_state=KFOLD_SEED)\n",
    "bc_dt_5 = BalanceCascade(estimator=dt_5, n_max_subset=5, random_state=KFOLD_SEED)\n",
    "\n",
    "ensemblers = [bc_dt_20, bc_dt_10, bc_dt_5]\n",
    "ensembler_test(logistic_regression, ensemblers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tune max features, overall it doesn't affect ROC AUC much, but 17 features is slightly higher than others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting sample\n",
      "(10, 3062, 88) (10, 3062)\n",
      "training\n",
      "[LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear]Ensembler 0\n",
      "--------test---------\n",
      "================================\n",
      "Confusion Matrix:\n",
      "True Negative = 131814\n",
      "False Negative = 132\n",
      "True Positive = 245\n",
      "False Positive = 67809\n",
      "================================\n",
      "f1 score = 0.007\n",
      "================================\n",
      "ROC AUC Score = 0.655\n",
      "fitting sample\n",
      "(10, 3062, 88) (10, 3062)\n",
      "training\n",
      "[LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear]Ensembler 1\n",
      "--------test---------\n",
      "================================\n",
      "Confusion Matrix:\n",
      "True Negative = 133049\n",
      "False Negative = 142\n",
      "True Positive = 235\n",
      "False Positive = 66574\n",
      "================================\n",
      "f1 score = 0.007\n",
      "================================\n",
      "ROC AUC Score = 0.645\n",
      "fitting sample\n",
      "(10, 3062, 88) (10, 3062)\n",
      "training\n",
      "[LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear]Ensembler 2\n",
      "--------test---------\n",
      "================================\n",
      "Confusion Matrix:\n",
      "True Negative = 131934\n",
      "False Negative = 126\n",
      "True Positive = 251\n",
      "False Positive = 67689\n",
      "================================\n",
      "f1 score = 0.007\n",
      "================================\n",
      "ROC AUC Score = 0.663\n",
      "fitting sample\n",
      "(10, 3062, 88) (10, 3062)\n",
      "training\n",
      "[LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear]Ensembler 3\n",
      "--------test---------\n",
      "================================\n",
      "Confusion Matrix:\n",
      "True Negative = 132297\n",
      "False Negative = 138\n",
      "True Positive = 239\n",
      "False Positive = 67326\n",
      "================================\n",
      "f1 score = 0.007\n",
      "================================\n",
      "ROC AUC Score = 0.648\n"
     ]
    }
   ],
   "source": [
    "# 70 features\n",
    "dt_08 = DecisionTreeClassifier(max_features=0.8, random_state=KFOLD_SEED)\n",
    "bc_dt_08 = BalanceCascade(estimator=dt_08, n_max_subset=10, random_state=KFOLD_SEED)\n",
    "\n",
    "# 35 features\n",
    "dt_04 = DecisionTreeClassifier(max_features=0.4, random_state=KFOLD_SEED)\n",
    "bc_dt_04 = BalanceCascade(estimator=dt_04, n_max_subset=10, random_state=KFOLD_SEED)\n",
    "\n",
    "# 17 features\n",
    "dt_02 = DecisionTreeClassifier(max_features=0.2, random_state=KFOLD_SEED)\n",
    "bc_dt_02 = BalanceCascade(estimator=dt_02, n_max_subset=10, random_state=KFOLD_SEED)\n",
    "\n",
    "# Auto is sqrt(n_features) ~= 9\n",
    "dt_auto = DecisionTreeClassifier(max_features='auto', random_state=KFOLD_SEED)\n",
    "bc_dt_auto = BalanceCascade(estimator=dt_auto, n_max_subset=10, random_state=KFOLD_SEED)\n",
    "\n",
    "ensemblers = [bc_dt_08, bc_dt_04, bc_dt_02, bc_dt_auto]\n",
    "ensembler_test(logistic_regression, ensemblers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No need to tune decision tree's class weight, since ensembler already ensures both classes have equal samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Min samples at leaves do not seem to matter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting sample\n",
      "(10, 3062, 88) (10, 3062)\n",
      "training\n",
      "[LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear]Ensembler 0\n",
      "--------test---------\n",
      "================================\n",
      "Confusion Matrix:\n",
      "True Negative = 133422\n",
      "False Negative = 154\n",
      "True Positive = 223\n",
      "False Positive = 66201\n",
      "================================\n",
      "f1 score = 0.007\n",
      "================================\n",
      "ROC AUC Score = 0.630\n",
      "fitting sample\n",
      "(10, 3062, 88) (10, 3062)\n",
      "training\n",
      "[LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear]Ensembler 1\n",
      "--------test---------\n",
      "================================\n",
      "Confusion Matrix:\n",
      "True Negative = 130890\n",
      "False Negative = 152\n",
      "True Positive = 225\n",
      "False Positive = 68733\n",
      "================================\n",
      "f1 score = 0.006\n",
      "================================\n",
      "ROC AUC Score = 0.626\n",
      "fitting sample\n",
      "(10, 3062, 88) (10, 3062)\n",
      "training\n",
      "[LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear]Ensembler 2\n",
      "--------test---------\n",
      "================================\n",
      "Confusion Matrix:\n",
      "True Negative = 131893\n",
      "False Negative = 133\n",
      "True Positive = 244\n",
      "False Positive = 67730\n",
      "================================\n",
      "f1 score = 0.007\n",
      "================================\n",
      "ROC AUC Score = 0.654\n",
      "fitting sample\n",
      "(10, 3062, 88) (10, 3062)\n",
      "training\n",
      "[LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear]Ensembler 3\n",
      "--------test---------\n",
      "================================\n",
      "Confusion Matrix:\n",
      "True Negative = 131859\n",
      "False Negative = 154\n",
      "True Positive = 223\n",
      "False Positive = 67764\n",
      "================================\n",
      "f1 score = 0.007\n",
      "================================\n",
      "ROC AUC Score = 0.626\n"
     ]
    }
   ],
   "source": [
    "dt_min_samples_50 = DecisionTreeClassifier(min_samples_leaf=50, max_features=0.2, random_state=KFOLD_SEED)\n",
    "bc_dt_min_samples_50 = BalanceCascade(estimator=dt_min_samples_50, n_max_subset=10, random_state=KFOLD_SEED)\n",
    "\n",
    "dt_min_samples_20 = DecisionTreeClassifier(min_samples_leaf=20, max_features=0.2, random_state=KFOLD_SEED)\n",
    "bc_dt_min_samples_20 = BalanceCascade(estimator=dt_min_samples_20, n_max_subset=10, random_state=KFOLD_SEED)\n",
    "\n",
    "dt_min_samples_10 = DecisionTreeClassifier(min_samples_leaf=10, max_features=0.2, random_state=KFOLD_SEED)\n",
    "bc_dt_min_samples_10 = BalanceCascade(estimator=dt_min_samples_10, n_max_subset=10, random_state=KFOLD_SEED)\n",
    "\n",
    "dt_min_samples_5 = DecisionTreeClassifier(min_samples_leaf=5, max_features=0.2, random_state=KFOLD_SEED)\n",
    "bc_dt_min_samples_5 = BalanceCascade(estimator=dt_min_samples_5, n_max_subset=10, random_state=KFOLD_SEED)\n",
    "\n",
    "ensemblers = [bc_dt_min_samples_50, bc_dt_min_samples_20, bc_dt_min_samples_10, bc_dt_min_samples_5]\n",
    "ensembler_test(logistic_regression, ensemblers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Class weight has to be balanced!\n",
    "If negative class is heavier, both TPR and FNR decrease, but TPR decrease causes more harm to ROC AUC.\n",
    "If positive class is heavier, the observation is the opposite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting sample\n",
      "(10, 3062, 88) (10, 3062)\n",
      "training\n",
      "Ensembler 0\n",
      "--------test---------\n",
      "================================\n",
      "Confusion Matrix:\n",
      "True Negative = 187970\n",
      "False Negative = 288\n",
      "True Positive = 89\n",
      "False Positive = 11653\n",
      "================================\n",
      "f1 score = 0.015\n",
      "================================\n",
      "ROC AUC Score = 0.589\n",
      "fitting sample\n",
      "(10, 3062, 88) (10, 3062)\n",
      "training\n",
      "Ensembler 0\n",
      "--------test---------\n",
      "================================\n",
      "Confusion Matrix:\n",
      "True Negative = 131934\n",
      "False Negative = 126\n",
      "True Positive = 251\n",
      "False Positive = 67689\n",
      "================================\n",
      "f1 score = 0.007\n",
      "================================\n",
      "ROC AUC Score = 0.663\n",
      "fitting sample\n",
      "(10, 3062, 88) (10, 3062)\n",
      "training\n",
      "Ensembler 0\n",
      "--------test---------\n",
      "================================\n",
      "Confusion Matrix:\n",
      "True Negative = 38409\n",
      "False Negative = 25\n",
      "True Positive = 352\n",
      "False Positive = 161214\n",
      "================================\n",
      "f1 score = 0.004\n",
      "================================\n",
      "ROC AUC Score = 0.563\n",
      "fitting sample\n",
      "(10, 3062, 88) (10, 3062)\n",
      "training\n",
      "Ensembler 0\n",
      "--------test---------\n",
      "================================\n",
      "Confusion Matrix:\n",
      "True Negative = 13244\n",
      "False Negative = 6\n",
      "True Positive = 371\n",
      "False Positive = 186379\n",
      "================================\n",
      "f1 score = 0.004\n",
      "================================\n",
      "ROC AUC Score = 0.525\n"
     ]
    }
   ],
   "source": [
    "def create_lr_proxy(class_weight='balanced'):\n",
    "    def create_lr():\n",
    "        return LogisticRegression(penalty='l2', class_weight=class_weight)\n",
    "    return create_lr\n",
    "\n",
    "dt = DecisionTreeClassifier(max_features=0.2, random_state=KFOLD_SEED)\n",
    "bc = BalanceCascade(estimator=dt, n_max_subset=10, random_state=KFOLD_SEED)\n",
    "\n",
    "ensembler_test(create_lr_proxy({0: 2, 1: 1}), [bc])\n",
    "ensembler_test(create_lr_proxy(), [bc])\n",
    "ensembler_test(create_lr_proxy({0: 1, 1: 2}), [bc])\n",
    "ensembler_test(create_lr_proxy({0: 1, 1: 4}), [bc])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try L1 regularization, C=1.0 is just right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting sample\n",
      "(10, 3062, 88) (10, 3062)\n",
      "training\n",
      "Ensembler 0\n",
      "--------test---------\n",
      "================================\n",
      "Confusion Matrix:\n",
      "True Negative = 131967\n",
      "False Negative = 125\n",
      "True Positive = 252\n",
      "False Positive = 67656\n",
      "================================\n",
      "f1 score = 0.007\n",
      "================================\n",
      "ROC AUC Score = 0.665\n",
      "fitting sample\n",
      "(10, 3062, 88) (10, 3062)\n",
      "training\n",
      "Ensembler 0\n",
      "--------test---------\n",
      "================================\n",
      "Confusion Matrix:\n",
      "True Negative = 131859\n",
      "False Negative = 124\n",
      "True Positive = 253\n",
      "False Positive = 67764\n",
      "================================\n",
      "f1 score = 0.007\n",
      "================================\n",
      "ROC AUC Score = 0.666\n",
      "fitting sample\n",
      "(10, 3062, 88) (10, 3062)\n",
      "training\n",
      "Ensembler 0\n",
      "--------test---------\n",
      "================================\n",
      "Confusion Matrix:\n",
      "True Negative = 131884\n",
      "False Negative = 124\n",
      "True Positive = 253\n",
      "False Positive = 67739\n",
      "================================\n",
      "f1 score = 0.007\n",
      "================================\n",
      "ROC AUC Score = 0.666\n",
      "fitting sample\n",
      "(10, 3062, 88) (10, 3062)\n",
      "training\n",
      "Ensembler 0\n",
      "--------test---------\n",
      "================================\n",
      "Confusion Matrix:\n",
      "True Negative = 131745\n",
      "False Negative = 126\n",
      "True Positive = 251\n",
      "False Positive = 67878\n",
      "================================\n",
      "f1 score = 0.007\n",
      "================================\n",
      "ROC AUC Score = 0.663\n",
      "fitting sample\n",
      "(10, 3062, 88) (10, 3062)\n",
      "training\n",
      "Ensembler 0\n",
      "--------test---------\n",
      "================================\n",
      "Confusion Matrix:\n",
      "True Negative = 131609\n",
      "False Negative = 127\n",
      "True Positive = 250\n",
      "False Positive = 68014\n",
      "================================\n",
      "f1 score = 0.007\n",
      "================================\n",
      "ROC AUC Score = 0.661\n"
     ]
    }
   ],
   "source": [
    "def create_lr_proxy(C=1.0):\n",
    "    def create_lr():\n",
    "        return LogisticRegression(penalty='l1', C=C, random_state=KFOLD_SEED)\n",
    "    return create_lr\n",
    "\n",
    "dt = DecisionTreeClassifier(max_features=0.2, random_state=KFOLD_SEED)\n",
    "bc = BalanceCascade(estimator=dt, n_max_subset=10, random_state=KFOLD_SEED)\n",
    "\n",
    "ensembler_test(create_lr_proxy(2.0), [bc])\n",
    "ensembler_test(create_lr_proxy(1.0), [bc])\n",
    "ensembler_test(create_lr_proxy(0.8), [bc])\n",
    "ensembler_test(create_lr_proxy(0.5), [bc])\n",
    "ensembler_test(create_lr_proxy(0.2), [bc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
