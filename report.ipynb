{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choosing a metric\n",
    "\n",
    "I first looked at class ditribution. They are binary classes, and the dataset is highly imbalanced because the true class makes up only ~0.19% of all labels.\n",
    "\n",
    "I suspected if I just run a simple logistic regression on the dataset, I could achieve 99.81% accuracy, because the model can simply cheat by classifying every sample as 0. I ran logistic regression using sklearn with default params, and the result confirmed my hypothesis - the model predicted every sample as 0.\n",
    "\n",
    "Obviously, accuracy is a bad metric for such an imbalanced dataset, especially in the RTB context, because being able to find samples that likely will result in a click-through is more important than overall correctness. If the model predicts the majority label for every sample, precision will be perfect but recall will be 0. If the model predicts the minority label for every sample, the recall will be perfect but precision will be 1. One potential metric I can use is the f1 score, but it states that precision and recall are equally important, which in reality may not be true. If capturing most of the click-throughs are more important than serving efficiency (most of the served impressions result in click-throughs, in other words, there is no infrastructure bottlenck), then recall is more important than precision. On the other hand, if serving efficiency is more important than capturing most of click-throughs, which may be true when the scale is large, then precision is more important. But in either case, f1 score can be very low even if we are happy with the model.\n",
    "\n",
    "Without making too much an assumption of what we would want in real life, ROC AUC is a better metric to use because it depicts the tradeoff between specificity and senstivity. A large ROC AUC value indicates the model is more robust, and the optimal value should approach 1.\n",
    "\n",
    "### Baseline models\n",
    "\n",
    "#### Logistic Regression\n",
    "I reran the default logistic regression model and print ROC AUC, f1 score and the confusion matrix. I use the binary labels as predicted values rather than scores, because I didn't want ROC AUC to be skewed by precision, and ultimatly I care more about the repdiced labels than probablities\n",
    "```\n",
    "================================\n",
    "Confusion Matrix:\n",
    "True Negative = 199623\n",
    "False Negative = 377\n",
    "True Positive = 0\n",
    "False Positive = 0\n",
    "================================\n",
    "f1 score = 0.000\n",
    "================================\n",
    "ROC AUC Score = 0.500\n",
    "```\n",
    "F1 score is coerced to 0 because there are no predicted positives at all. ROC AUC score is low - just as good as a random classifier. Just for fun, I added l2 regularization `penalty='l2'`, the result is the same. The imbalance is just to strong for the model to even try to predict positives.\n",
    "\n",
    "#### Neural Net\n",
    "The baseline neural net has 1 hidden layer that outputs 88 weights for all features, and an output layer with 2 outputs, one probability for each class, with a softmax activation. Categorical crossentropy is used as loss.\n",
    "\n",
    "The model is fit with 3 epochs, and a batch size of 32. The baseline neural net should be equivalent of a logisc regression, except that I'm using the SGD optimizer, so I picked a learning rate of 0.01 (it usually worked well for me when I train baseline models). I specifically set the inital weights as `Ones`, because Keras defaults the inital weights to `glorot_uniform`, which generally works really well (and too well for a baseline model).\n",
    "\n",
    "I used set split to 0.2 for validation after each epoch.\n",
    "Both training and validation error went down, and validation error is slightly smaller than training error in all epochs, indicating there is no overfitting. \n",
    "\n",
    "Unsurprisingly, the accuracy is still 99.81%, with the vast majority of samples predicted negative. ROC AUC score is still 0.5.\n",
    "\n",
    "The result:\n",
    "```\n",
    "================================\n",
    "Confusion Matrix:\n",
    "True Negative = 199619\n",
    "False Negative = 377\n",
    "True Positive = 0\n",
    "False Positive = 4\n",
    "================================\n",
    "f1 score = 0.000\n",
    "================================\n",
    "ROC AUC Score = 0.500\n",
    "```\n",
    "\n",
    "Because I set the initial weights to `Ones`, I wanted to eliminate the possibility that my weights are exploding or diminished. After checking the hidden layer's output weights, they are all between -1 and 1. So my baseline neural net is fine, even if I remove my initial weights so that they are set to `glorot_uniform`, the result is similar, there is one true positive and more false positives\n",
    "```\n",
    "================================\n",
    "Confusion Matrix:\n",
    "True Negative = 199418\n",
    "False Negative = 376\n",
    "True Positive = 1\n",
    "False Positive = 205\n",
    "================================\n",
    "f1 score = 0.003\n",
    "================================\n",
    "ROC AUC Score = 0.501\n",
    "```\n",
    "\n",
    "### Model improvements\n",
    "I think the main obstacle to achieving higher ROC AUC is the severe data imbalance. There are a few potential migations I can try:\n",
    "\n",
    "- Deepen the neural network model\n",
    "  <p>\n",
    "    If add more layers, the model will have a chance to explore nonlinearty, which might cover the positive space.\n",
    "  </p>\n",
    "- Down sampling\n",
    "  <p>\n",
    "    The negative class can be overpowering. We could find a good class ratio so that the model can be trained for positive classes without underfitting the negative class. A side benefit is the model will take less time to train.\n",
    "  </p>\n",
    "- Over sampling\n",
    "  <p>\n",
    "    Like down sampling, the goal is to make the data more balanced. If we observe underfitting for the negative class, we can try oversampling the positive class and find a good class ratio. Oversampling can be done with random selection and duplication. This could cause overfitting for the positive class, and definitely slows down training and can increase model size.\n",
    "  </p>\n",
    "- SMOTE\n",
    "  <p>\n",
    "    We can also try a hybrid approach, down sampling negative class while generating synthetic samples for the positive class eith nearest neighbours. This could help prevent positive class overfitting. But just like oversampling, it causes the model to train slower and the size to increase.\n",
    "  </p>\n",
    "  \n",
    "  \n",
    "#### Deepen the neural network model\n",
    "I added one more hidden layer with 64 outputs, without any regularization, and left the initial weights to `glorot_uniform`. Both training and validation lossses are smaller (around 0.015 v.s. 0.030 in the baseline neural net). However, there is no improvement in metrics. The vast majority of predicted clases are still negative, and ROC AUC remains 0.5. The validation error also failed to decrease while training error did. This indicates overfitting, so I added `l2(0.01)` to the first hidden layer. This time validation error decreased with training error, but there's no improvement metrics, in fact, the model predicts all negatives again. In effect, the extra layer only enabled the model to explore some nonlinearity and as a result the error declined, but it heavily benefits the negative error, as the negative class severly outweighs the positive class.\n",
    "\n",
    "I tried to tune learning rate (0.1, 0.001, 0.0001) and batch size (64, 128, 256) on different scales and tried different weight initializers (random normal, he_normal, etc). There is no improvement. Adding yet another layer didn't help either, because as expected, the reduced loss benefits the negative class much more than the positive class.\n",
    "\n",
    "Since the imbalance is preventing the model to train for positives, I set used weighted loss to balance the classes by setting `class_weight` (roughly 1:526) in the `fit` function. The losses are huge, and validation error plateaued, and the model again tried to predict all negatives. I probably overshot the class weight, so I adjusted to 1:100, and added l2(0.01). There were more false positives, but there was still overfitting, so I changed l2 to l1 in the first layer, in an attempt to reduce features. This helped. I have more true positives, but also more false positives, but the ROC AUC is 0.541!\n",
    "\n",
    "```\n",
    "================================\n",
    "Confusion Matrix:\n",
    "True Negative = 190136\n",
    "False Negative = 328\n",
    "True Positive = 49\n",
    "False Positive = 9487\n",
    "================================\n",
    "f1 score = 0.010\n",
    "================================\n",
    "ROC AUC Score = 0.541\n",
    "```\n",
    "\n",
    "There's still a little overfitting, so I added a `Dropout` layer between the two hidden layers, with rate = 0.1. However, this nudged the model back to all negatives again. I tried to tune the dropout rate and although it decreases losses when the rate is 0.05, it also prevented the mode from predicting positives, probably because most of the loss it regulated is from negatives. I also tuned the learn rate, decay, and tried out RMSprop. It doesn't seem I had a problem with decreasing loss.\n",
    "\n",
    "I figured I could keep adding layers and tuning the extra hyper parameters, but I decided to explore the sampling route, as my mode will be exponentially slower and harder to tune as trained parameters hyper parameters increase.\n",
    "\n",
    "#### Undersampling/Oversampling\n",
    "I used Logistic Regression to evaluate my sampling stratigies.\n",
    "\n",
    "Initially I tried just random undersampling with a negative-positive ratio of 10:1. I tried 1:1 but this lead to overfitting due to extremely small positive size. 10:1 resulted in an ROC AUC score of 0.501. I used `class_weight` to counter balance so that to total weight of the two classes were equal (i.e. setting it to 1:10). This time the ROC AUC score improved to 0.663!\n",
    "\n",
    "```\n",
    "================================\n",
    "Confusion Matrix:\n",
    "True Negative = 129499\n",
    "False Negative = 122\n",
    "True Positive = 255\n",
    "False Positive = 70124\n",
    "================================\n",
    "f1 score = 0.007\n",
    "================================\n",
    "ROC AUC Score = 0.663\n",
    "```\n",
    "\n",
    "I tried random oversampling next. However, the sampling process was very slow this time, because I was upsampling the minority class to have an equal size with the majority class. So I put the undersampler before the oversampler, and built a pipeline.\n",
    "\n",
    "```\n",
    "Undersample majority to 10:1 -> Oversample minority to 1:1\n",
    "```\n",
    "\n",
    "Because of the lack of positive samples, I worried simple oversampling will cause overfitting, as the classifier tends to memorize them, I built another pipeline with SMOTE as the second step.\n",
    "\n",
    "```\n",
    "Undersample majority to 10:1 -> SMOTE 1:1\n",
    "```\n",
    "\n",
    "The results are:\n",
    "```\n",
    "================================\n",
    "Confusion Matrix:\n",
    "True Negative = 129713\n",
    "False Negative = 123\n",
    "True Positive = 254\n",
    "False Positive = 69910\n",
    "================================\n",
    "f1 score = 0.007\n",
    "================================\n",
    "ROC AUC Score = 0.662\n",
    "```\n",
    "\n",
    "```\n",
    "================================\n",
    "Confusion Matrix:\n",
    "True Negative = 130028\n",
    "False Negative = 125\n",
    "True Positive = 252\n",
    "False Positive = 69595\n",
    "================================\n",
    "f1 score = 0.007\n",
    "================================\n",
    "ROC AUC Score = 0.660\n",
    "```\n",
    "\n",
    "There is little difference between oversampling vs SMOTE, and having an oversampling step doesn't yield better results than just undersampling.\n",
    "\n",
    "Because of undersampling, the overall size is still small. I removed the random seed and repeated the tests above 10 times and the results are similar.\n",
    "\n",
    "I tuned the initial undersampling ratio higher, 20:1, and 40:1, the results were not better, but slightly worse. I think it's because higher undersampling ratio lead to more noisy oversampled data down the pipeline, as the minority class has to be sampled/synthesizes to a large size.\n",
    "\n",
    "After a closer look at the sampling results above, SMOTE actually results in fewer false positives and more true negatives. I played around with the two params, `k_neighbors` and `m_neighbors`, and was able to reduce the false positives a little  further. The best config is `k_neighbors=1`, `m_neighbors=3`\n",
    "\n",
    "```\n",
    "================================\n",
    "Confusion Matrix:\n",
    "True Negative = 130268\n",
    "False Negative = 125\n",
    "True Positive = 252\n",
    "False Positive = 69355\n",
    "================================\n",
    "f1 score = 0.007\n",
    "================================\n",
    "ROC AUC Score = 0.661\n",
    "```\n",
    "\n",
    "#### Ensembling\n",
    "So far I hadn't spent much energy on improving the undersampling. I saw decent improvement in ROC AUC score from 0.5 to 0.66, but false positives were still high. I stumbled upon `BalanceCascade` and wondered if more sophisticated estimators with iterative undersampling could help reduce potential noise in the features and negative samples.\n",
    "\n",
    "I still had to undersample as the first step so that ensembling doesn't take forever.\n",
    "\n",
    "__EasyEnsembler__\n",
    "No estimator, just iterative random undersampling\n",
    "Results are in line with random undersampling\n",
    "```\n",
    "================================\n",
    "Confusion Matrix:\n",
    "True Negative = 126066\n",
    "False Negative = 124\n",
    "True Positive = 253\n",
    "False Positive = 73557\n",
    "================================\n",
    "f1 score = 0.007\n",
    "================================\n",
    "ROC AUC Score = 0.651\n",
    "```\n",
    "__BalanceCascade__\n",
    "Without an estimator, it uses KNN\n",
    "```\n",
    "================================\n",
    "Confusion Matrix:\n",
    "True Negative = 115446\n",
    "False Negative = 149\n",
    "True Positive = 228\n",
    "False Positive = 84177\n",
    "================================\n",
    "f1 score = 0.005\n",
    "================================\n",
    "ROC AUC Score = 0.592\n",
    "```\n",
    "\n",
    "__BalanceCascade + DecisionTreeClassifier__\n",
    "This is not bad as I left all params default.\n",
    "```\n",
    "================================\n",
    "Confusion Matrix:\n",
    "True Negative = 128417\n",
    "False Negative = 152\n",
    "True Positive = 225\n",
    "False Positive = 71206\n",
    "================================\n",
    "f1 score = 0.006\n",
    "================================\n",
    "ROC AUC Score = 0.620\n",
    "```\n",
    "Since I'm not limiting max subsets. I tried 20, 10, 5.\n",
    "5 had the best result, with ROC AUC = 0.674, where as 20 -> 0.636, 10 -> 0.644.\n",
    "```\n",
    "================================\n",
    "Confusion Matrix:\n",
    "True Negative = 127183\n",
    "False Negative = 109\n",
    "True Positive = 268\n",
    "False Positive = 72440\n",
    "================================\n",
    "f1 score = 0.007\n",
    "================================\n",
    "ROC AUC Score = 0.674\n",
    "```\n",
    "Then I tried to limit `max_features`, with the assumption that maybe there is still too much feature noise. Unfortunately, as the `max_features` ratio goes down from 0.8 to 0.2, the ROC AUC also declines.\n",
    "\n",
    "I tried to tune `min_sample_leaves` as well but didn't see improvement.\n",
    "Maybe it's because I already severly limited max subsets? I increased max subsets to 10, and this time, the best max feature ratio is 0.8. ROC AUC is better than when max subsets was 5, but it still doesn't beat 0.674. \n",
    "\n",
    "__BalanceCascade + RandomForestClassifier__\n",
    "I could have tried to tune this. But since the baseline result below isn't better then decision tree, I just focused on decision tree instead.\n",
    "```\n",
    "================================\n",
    "Confusion Matrix:\n",
    "True Negative = 132453\n",
    "False Negative = 161\n",
    "True Positive = 216\n",
    "False Positive = 67170\n",
    "================================\n",
    "f1 score = 0.006\n",
    "================================\n",
    "ROC AUC Score = 0.618\n",
    "```\n",
    "\n",
    "__BalanceCascade + XGBClassifier__\n",
    "I was going to try XGB, but random forest didn't perform quite well, and XGB was taking a very long time.\n",
    "\n",
    "With the best sampling config (__BalanceCascade + DecisionTreeClassifier__ with a max subset of 5), I tried to tune logistic regression with different params on log scale: l2/l1, regularization strength (C from 0.001 to 2). Nothing beats l2 with C=1.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.local/share/virtualenvs/RTB-V2Lvgo6A/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import numpy as np\n",
    "from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
    "from imblearn.under_sampling import NearMiss, RandomUnderSampler\n",
    "from imblearn.combine import SMOTEENN,SMOTETomek\n",
    "from imblearn.ensemble import BalanceCascade, EasyEnsemble\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import h5py\n",
    "import keras\n",
    "from sklearn.utils import class_weight\n",
    "from keras.utils import to_categorical\n",
    "from keras.optimizers import *\n",
    "from keras.regularizers import *\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, f1_score, precision_recall_fscore_support\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "KFOLD_SEED = 42\n",
    "\n",
    "\n",
    "def rtb_confusion_matrix(test_labels, y_preds):\n",
    "    m = confusion_matrix(test_labels, y_preds)\n",
    "    \n",
    "    print(\"================================\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(\"True Negative = %d\" % m[0][0])\n",
    "    print(\"False Negative = %d\" % m[1][0])\n",
    "    print(\"True Positive = %d\" % m[1][1])\n",
    "    print(\"False Positive = %d\" % m[0][1])\n",
    "\n",
    "\n",
    "def rtb_f1_score(test_labels, y_preds):\n",
    "    f = f1_score(test_labels, y_preds)\n",
    "    print(\"================================\")\n",
    "    print(\"f1 score = %0.3f\" % f)\n",
    "\n",
    "\n",
    "def print_metrics(true_labels, y_preds, y_scores, is_train=True):\n",
    "    if is_train:\n",
    "        print(\"--------train---------\")\n",
    "    else:\n",
    "        print(\"--------test---------\")\n",
    "    \n",
    "    rtb_confusion_matrix(true_labels, y_preds)\n",
    "    rtb_f1_score(true_labels, y_preds)\n",
    "    print(\"================================\")\n",
    "    print(\"ROC AUC Score = %0.3f\" % roc_auc_score(true_labels, y_scores.argmax(axis=-1)))\n",
    "    \n",
    "def keras_print_metrics(true_labels, y_scores, is_train=True):\n",
    "    y_preds = y_scores.argmax(axis=-1)\n",
    "    \n",
    "    if is_train:\n",
    "        print(\"--------train---------\")\n",
    "    else:\n",
    "        print(\"--------test---------\")\n",
    "    \n",
    "    rtb_confusion_matrix(true_labels, y_preds)\n",
    "    rtb_f1_score(true_labels, y_preds)\n",
    "    print(\"================================\")\n",
    "    print(\"ROC AUC Score = %0.3f\" % roc_auc_score(true_labels, y_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000000, 89)\n"
     ]
    }
   ],
   "source": [
    "input_path = '~/data/biddings.csv'\n",
    "data = pd.read_csv(input_path)\n",
    "print(data.shape)\n",
    "\n",
    "train = data[:800000]\n",
    "test = data[800000:]\n",
    "\n",
    "sample = train.sample(frac=1)\n",
    "features = sample.drop('convert', axis=1).values\n",
    "labels = sample.convert.ravel()\n",
    "categorical_labels = to_categorical(labels, 2)\n",
    "\n",
    "test_features = test.drop('convert', axis=1).values\n",
    "test_labels = test.convert.ravel()\n",
    "categorical_test_labels = to_categorical(test_labels, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear](200000, 2) (200000,)\n",
      "--------test---------\n",
      "================================\n",
      "Confusion Matrix:\n",
      "True Negative = 199623\n",
      "False Negative = 377\n",
      "True Positive = 0\n",
      "False Positive = 0\n",
      "================================\n",
      "f1 score = 0.000\n",
      "================================\n",
      "ROC AUC Score = 0.500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.local/share/virtualenvs/RTB-V2Lvgo6A/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(penalty='l2', random_state=KFOLD_SEED, verbose=2)\n",
    "\n",
    "model = lr.fit(features, labels)\n",
    "predicted_scores = model.predict_proba(test_features)\n",
    "predicted_labels = model.predict(test_features)\n",
    "print(predicted_scores.shape, predicted_labels.shape)\n",
    "\n",
    "print_metrics(test_labels, predicted_labels, predicted_scores, is_train=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_11 (Dense)             (None, 88)                7832      \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 2)                 178       \n",
      "=================================================================\n",
      "Total params: 8,010\n",
      "Trainable params: 8,010\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 640000 samples, validate on 160000 samples\n",
      "Epoch 1/3\n",
      "640000/640000 [==============================] - 39s 61us/step - loss: 0.0321 - acc: 0.9964 - val_loss: 0.0300 - val_acc: 0.9970\n",
      "Epoch 2/3\n",
      "640000/640000 [==============================] - 39s 61us/step - loss: 0.0279 - acc: 0.9972 - val_loss: 0.0300 - val_acc: 0.9970\n",
      "Epoch 3/3\n",
      "640000/640000 [==============================] - 40s 62us/step - loss: 0.0279 - acc: 0.9972 - val_loss: 0.0300 - val_acc: 0.9970\n",
      "200000/200000 [==============================] - 4s 19us/step\n",
      "--------train---------\n",
      "================================\n",
      "Confusion Matrix:\n",
      "True Negative = 199418\n",
      "False Negative = 376\n",
      "True Positive = 1\n",
      "False Positive = 205\n",
      "================================\n",
      "f1 score = 0.003\n",
      "================================\n",
      "ROC AUC Score = 0.501\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(88, input_shape=(88,)))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=SGD(lr=0.01),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(features, categorical_labels,\n",
    "                    batch_size=32,\n",
    "                    epochs=3,\n",
    "                    callbacks=[keras.callbacks.EarlyStopping()],\n",
    "                    validation_split=0.2,\n",
    "                    verbose=1)\n",
    "\n",
    "y_scores = model.predict(test_features, verbose=1)\n",
    "\n",
    "keras_print_metrics(test_labels, y_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deeper neural nets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_28 (Dense)             (None, 88)                7832      \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 64)                5696      \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 13,658\n",
      "Trainable params: 13,658\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 640000 samples, validate on 160000 samples\n",
      "Epoch 1/3\n",
      "640000/640000 [==============================] - 46s 72us/step - loss: 0.8766 - acc: 0.9896 - val_loss: 0.5066 - val_acc: 0.9982\n",
      "Epoch 2/3\n",
      "640000/640000 [==============================] - 45s 70us/step - loss: 0.5423 - acc: 0.9918 - val_loss: 0.5224 - val_acc: 0.9972\n",
      "200000/200000 [==============================] - 5s 23us/step\n",
      "--------train---------\n",
      "================================\n",
      "Confusion Matrix:\n",
      "True Negative = 199437\n",
      "False Negative = 375\n",
      "True Positive = 2\n",
      "False Positive = 186\n",
      "================================\n",
      "f1 score = 0.007\n",
      "================================\n",
      "ROC AUC Score = 0.502\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(88, kernel_regularizer=l1(0.01), input_shape=(88,)))\n",
    "model.add(Dense(64, kernel_regularizer=l2(0.01)))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=SGD(lr=0.01),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(features, categorical_labels,\n",
    "                    batch_size=32,\n",
    "                    class_weight={0:1, 1:100},\n",
    "                    epochs=3,\n",
    "                    callbacks=[keras.callbacks.EarlyStopping()],\n",
    "                    validation_split=0.2,\n",
    "                    verbose=1)\n",
    "\n",
    "y_scores = model.predict(test_features, verbose=1)\n",
    "\n",
    "keras_print_metrics(test_labels, y_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = model.get_layer(name='dense_10').get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression():\n",
    "    lr = LogisticRegression(penalty='l2', random_state=KFOLD_SEED, verbose=2)\n",
    "    return lr\n",
    "\n",
    "\n",
    "def pipeline_test(pipeline, features, labels):\n",
    "    pipeline.fit(features, labels)\n",
    "    \n",
    "    predicted_scores = pipeline.predict_proba(test_features)\n",
    "    predicted_labels = pipeline.predict(test_features)\n",
    "        \n",
    "    print_metrics(test_labels, predicted_labels, predicted_scores, is_train=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Undersampling / Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]--------test---------\n",
      "================================\n",
      "Confusion Matrix:\n",
      "True Negative = 128714\n",
      "False Negative = 123\n",
      "True Positive = 254\n",
      "False Positive = 70909\n",
      "================================\n",
      "f1 score = 0.007\n",
      "================================\n",
      "ROC AUC Score = 0.659\n",
      "[LibLinear]--------test---------\n",
      "================================\n",
      "Confusion Matrix:\n",
      "True Negative = 129604\n",
      "False Negative = 124\n",
      "True Positive = 253\n",
      "False Positive = 70019\n",
      "================================\n",
      "f1 score = 0.007\n",
      "================================\n",
      "ROC AUC Score = 0.660\n",
      "[LibLinear]--------test---------\n",
      "================================\n",
      "Confusion Matrix:\n",
      "True Negative = 130225\n",
      "False Negative = 121\n",
      "True Positive = 256\n",
      "False Positive = 69398\n",
      "================================\n",
      "f1 score = 0.007\n",
      "================================\n",
      "ROC AUC Score = 0.666\n"
     ]
    }
   ],
   "source": [
    "def sample_pipelines_test(pipeline_test_fn=pipeline_test):\n",
    "    rus = RandomUnderSampler(ratio={0: 1531*10, 1: 1531}, random_state=KFOLD_SEED)\n",
    "    ros = RandomOverSampler(random_state=KFOLD_SEED)\n",
    "    smote = SMOTE(n_jobs=-1, k_neighbors=1, m_neighbors = 3, random_state=KFOLD_SEED)\n",
    "    \n",
    "    lr1 = LogisticRegression(penalty='l2', class_weight={0:1, 1:10}, random_state=KFOLD_SEED, verbose=2)\n",
    "    p1 = Pipeline([('rus', rus), ('lr', lr1)])\n",
    "    pipeline_test_fn(p1, features, labels)\n",
    "    \n",
    "    p2 = Pipeline([('rus', rus), ('ros', ros), ('lr', logistic_regression())])\n",
    "    pipeline_test_fn(p2, features, labels)\n",
    "    \n",
    "    p3 = Pipeline([('rus', rus), ('smote', smote), ('lr', logistic_regression())])\n",
    "    pipeline_test_fn(p3, features, labels)\n",
    "    \n",
    "    \n",
    "\n",
    "sample_pipelines_test(pipeline_test_fn=pipeline_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensembler_test(classifier_fn, ensemblers):\n",
    "    rus = RandomUnderSampler(ratio={0: 1531*10, 1: 1531}, random_state=KFOLD_SEED)\n",
    "    X_us, y_us = rus.fit_sample(features, labels)\n",
    "    \n",
    "    for i, e in enumerate(ensemblers):\n",
    "        print(\"fitting sample\")\n",
    "        X_res, y_res = e.fit_sample(X_us, y_us)\n",
    "        print(X_res.shape, y_res.shape)\n",
    "        clf = classifier_fn()\n",
    "        print(\"training\")\n",
    "        \n",
    "        for j, X_train in enumerate(X_res):\n",
    "            model = clf.fit(X_train, y_res[j])\n",
    "        \n",
    "        predicted_scores = model.predict_proba(test_features)\n",
    "        predicted_labels = model.predict(test_features)\n",
    "        \n",
    "        print(\"Ensembler %d\" % i)\n",
    "        print_metrics(test_labels, predicted_labels, predicted_scores, is_train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EasyEnsemble and decision tree are consistenly the best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting sample\n",
      "(10, 3062, 88) (10, 3062)\n",
      "training\n",
      "[LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear]Ensembler 0\n",
      "--------test---------\n",
      "================================\n",
      "Confusion Matrix:\n",
      "True Negative = 126771\n",
      "False Negative = 119\n",
      "True Positive = 258\n",
      "False Positive = 72852\n",
      "================================\n",
      "f1 score = 0.007\n",
      "================================\n",
      "ROC AUC Score = 0.660\n",
      "fitting sample\n",
      "(18, 3062, 88) (18, 3062)\n",
      "training\n",
      "[LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear]Ensembler 1\n",
      "--------test---------\n",
      "================================\n",
      "Confusion Matrix:\n",
      "True Negative = 109272\n",
      "False Negative = 146\n",
      "True Positive = 231\n",
      "False Positive = 90351\n",
      "================================\n",
      "f1 score = 0.005\n",
      "================================\n",
      "ROC AUC Score = 0.580\n",
      "fitting sample\n",
      "(17, 3062, 88) (17, 3062)\n",
      "training\n",
      "[LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear]Ensembler 2\n",
      "--------test---------\n",
      "================================\n",
      "Confusion Matrix:\n",
      "True Negative = 134970\n",
      "False Negative = 152\n",
      "True Positive = 225\n",
      "False Positive = 64653\n",
      "================================\n",
      "f1 score = 0.007\n",
      "================================\n",
      "ROC AUC Score = 0.636\n",
      "fitting sample\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15, 3062, 88) (15, 3062)\n",
      "training\n",
      "[LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear]Ensembler 3\n",
      "--------test---------\n",
      "================================\n",
      "Confusion Matrix:\n",
      "True Negative = 143210\n",
      "False Negative = 172\n",
      "True Positive = 205\n",
      "False Positive = 56413\n",
      "================================\n",
      "f1 score = 0.007\n",
      "================================\n",
      "ROC AUC Score = 0.631\n"
     ]
    }
   ],
   "source": [
    "ee = EasyEnsemble(random_state=KFOLD_SEED)\n",
    "bc = BalanceCascade(random_state=KFOLD_SEED)\n",
    "\n",
    "dt = DecisionTreeClassifier(class_weight='balanced', random_state=KFOLD_SEED)\n",
    "bc_dt = BalanceCascade(estimator=dt, random_state=KFOLD_SEED)\n",
    "\n",
    "rf = RandomForestClassifier(class_weight='balanced', n_jobs=-1, random_state=KFOLD_SEED, verbose=1)\n",
    "bc_rf = BalanceCascade(estimator=rf, random_state=KFOLD_SEED)\n",
    "\n",
    "# xgbc = XGBClassifier(n_jobs=-1, n_estimators=10, scale_pos_weight=10)\n",
    "# bc_xgbc = BalanceCascade(estimator=xgbc, random_state=KFOLD_SEED)\n",
    "\n",
    "\n",
    "ensemblers = [ee, bc, bc_dt, bc_rf]\n",
    "ensembler_test(logistic_regression, ensemblers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try to tune EasyEnsemble by adjusting subsets. It does not affect f1-score or ROC AUC socre\n",
    "```\n",
    "ee = EasyEnsemble(n_subsets = 100, random_state=KFOLD_SEED)\n",
    "ensembler_test(logistic_regression, [ee])\n",
    "\n",
    "ee = EasyEnsemble(n_subsets = 4, random_state=KFOLD_SEED)\n",
    "ensembler_test(logistic_regression, [ee])\n",
    "```\n",
    "Both result in:\n",
    "```\n",
    "================================\n",
    "Confusion Matrix:\n",
    "True Negative = 127470\n",
    "False Negative = 132\n",
    "True Positive = 245\n",
    "False Positive = 72153\n",
    "================================\n",
    "f1 score = 0.007\n",
    "================================\n",
    "ROC AUC Score = 0.644\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tune max subset for BalanceCascade with DecisionTreeClassifier\n",
    "\n",
    "5 is the best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting sample\n",
      "(17, 3062, 88) (17, 3062)\n",
      "training\n",
      "[LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear]Ensembler 0\n",
      "--------test---------\n",
      "================================\n",
      "Confusion Matrix:\n",
      "True Negative = 134970\n",
      "False Negative = 152\n",
      "True Positive = 225\n",
      "False Positive = 64653\n",
      "================================\n",
      "f1 score = 0.007\n",
      "================================\n",
      "ROC AUC Score = 0.636\n",
      "fitting sample\n",
      "(10, 3062, 88) (10, 3062)\n",
      "training\n",
      "[LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear]Ensembler 1\n",
      "--------test---------\n",
      "================================\n",
      "Confusion Matrix:\n",
      "True Negative = 130663\n",
      "False Negative = 138\n",
      "True Positive = 239\n",
      "False Positive = 68960\n",
      "================================\n",
      "f1 score = 0.007\n",
      "================================\n",
      "ROC AUC Score = 0.644\n",
      "fitting sample\n",
      "(5, 3062, 88) (5, 3062)\n",
      "training\n",
      "[LibLinear][LibLinear][LibLinear][LibLinear][LibLinear]Ensembler 2\n",
      "--------test---------\n",
      "================================\n",
      "Confusion Matrix:\n",
      "True Negative = 127183\n",
      "False Negative = 109\n",
      "True Positive = 268\n",
      "False Positive = 72440\n",
      "================================\n",
      "f1 score = 0.007\n",
      "================================\n",
      "ROC AUC Score = 0.674\n"
     ]
    }
   ],
   "source": [
    "dt_20 = DecisionTreeClassifier(random_state=KFOLD_SEED)\n",
    "bc_dt_20 = BalanceCascade(estimator=dt_20, n_max_subset=20, random_state=KFOLD_SEED)\n",
    "\n",
    "dt_10 = DecisionTreeClassifier(random_state=KFOLD_SEED)\n",
    "bc_dt_10 = BalanceCascade(estimator=dt_10, n_max_subset=10, random_state=KFOLD_SEED)\n",
    "\n",
    "dt_5 = DecisionTreeClassifier(random_state=KFOLD_SEED)\n",
    "bc_dt_5 = BalanceCascade(estimator=dt_5, n_max_subset=5, random_state=KFOLD_SEED)\n",
    "\n",
    "ensemblers = [bc_dt_20, bc_dt_10, bc_dt_5]\n",
    "ensembler_test(logistic_regression, ensemblers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tune max features, overall it doesn't affect ROC AUC much, but 17 features is slightly higher than others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting sample\n",
      "(5, 3062, 88) (5, 3062)\n",
      "training\n",
      "[LibLinear][LibLinear][LibLinear][LibLinear][LibLinear]Ensembler 0\n",
      "--------test---------\n",
      "================================\n",
      "Confusion Matrix:\n",
      "True Negative = 127258\n",
      "False Negative = 121\n",
      "True Positive = 256\n",
      "False Positive = 72365\n",
      "================================\n",
      "f1 score = 0.007\n",
      "================================\n",
      "ROC AUC Score = 0.658\n",
      "fitting sample\n",
      "(5, 3062, 88) (5, 3062)\n",
      "training\n",
      "[LibLinear][LibLinear][LibLinear][LibLinear][LibLinear]Ensembler 1\n",
      "--------test---------\n",
      "================================\n",
      "Confusion Matrix:\n",
      "True Negative = 128352\n",
      "False Negative = 125\n",
      "True Positive = 252\n",
      "False Positive = 71271\n",
      "================================\n",
      "f1 score = 0.007\n",
      "================================\n",
      "ROC AUC Score = 0.656\n",
      "fitting sample\n",
      "(5, 3062, 88) (5, 3062)\n",
      "training\n",
      "[LibLinear][LibLinear][LibLinear][LibLinear][LibLinear]Ensembler 2\n",
      "--------test---------\n",
      "================================\n",
      "Confusion Matrix:\n",
      "True Negative = 131504\n",
      "False Negative = 141\n",
      "True Positive = 236\n",
      "False Positive = 68119\n",
      "================================\n",
      "f1 score = 0.007\n",
      "================================\n",
      "ROC AUC Score = 0.642\n",
      "fitting sample\n",
      "(5, 3062, 88) (5, 3062)\n",
      "training\n",
      "[LibLinear][LibLinear][LibLinear][LibLinear][LibLinear]Ensembler 3\n",
      "--------test---------\n",
      "================================\n",
      "Confusion Matrix:\n",
      "True Negative = 128496\n",
      "False Negative = 132\n",
      "True Positive = 245\n",
      "False Positive = 71127\n",
      "================================\n",
      "f1 score = 0.007\n",
      "================================\n",
      "ROC AUC Score = 0.647\n"
     ]
    }
   ],
   "source": [
    "# 70 features\n",
    "dt_08 = DecisionTreeClassifier(max_features=0.8, random_state=KFOLD_SEED)\n",
    "bc_dt_08 = BalanceCascade(estimator=dt_08, n_max_subset=5, random_state=KFOLD_SEED)\n",
    "\n",
    "# 35 features\n",
    "dt_04 = DecisionTreeClassifier(max_features=0.4, random_state=KFOLD_SEED)\n",
    "bc_dt_04 = BalanceCascade(estimator=dt_04, n_max_subset=5, random_state=KFOLD_SEED)\n",
    "\n",
    "# 17 features\n",
    "dt_02 = DecisionTreeClassifier(max_features=0.2, random_state=KFOLD_SEED)\n",
    "bc_dt_02 = BalanceCascade(estimator=dt_02, n_max_subset=5, random_state=KFOLD_SEED)\n",
    "\n",
    "# Auto is sqrt(n_features) ~= 9\n",
    "dt_auto = DecisionTreeClassifier(max_features='auto', random_state=KFOLD_SEED)\n",
    "bc_dt_auto = BalanceCascade(estimator=dt_auto, n_max_subset=5, random_state=KFOLD_SEED)\n",
    "\n",
    "ensemblers = [bc_dt_08, bc_dt_04, bc_dt_02, bc_dt_auto]\n",
    "ensembler_test(logistic_regression, ensemblers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No need to tune decision tree's class weight, since ensembler already ensures both classes have equal samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Min samples at leaves do not seem to matter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting sample\n",
      "(5, 3062, 88) (5, 3062)\n",
      "training\n",
      "[LibLinear][LibLinear][LibLinear][LibLinear][LibLinear]Ensembler 0\n",
      "--------test---------\n",
      "================================\n",
      "Confusion Matrix:\n",
      "True Negative = 130197\n",
      "False Negative = 134\n",
      "True Positive = 243\n",
      "False Positive = 69426\n",
      "================================\n",
      "f1 score = 0.007\n",
      "================================\n",
      "ROC AUC Score = 0.648\n",
      "fitting sample\n",
      "(5, 3062, 88) (5, 3062)\n",
      "training\n",
      "[LibLinear][LibLinear][LibLinear][LibLinear][LibLinear]Ensembler 1\n",
      "--------test---------\n",
      "================================\n",
      "Confusion Matrix:\n",
      "True Negative = 129656\n",
      "False Negative = 138\n",
      "True Positive = 239\n",
      "False Positive = 69967\n",
      "================================\n",
      "f1 score = 0.007\n",
      "================================\n",
      "ROC AUC Score = 0.642\n",
      "fitting sample\n",
      "(5, 3062, 88) (5, 3062)\n",
      "training\n",
      "[LibLinear][LibLinear][LibLinear][LibLinear][LibLinear]Ensembler 2\n",
      "--------test---------\n",
      "================================\n",
      "Confusion Matrix:\n",
      "True Negative = 129531\n",
      "False Negative = 140\n",
      "True Positive = 237\n",
      "False Positive = 70092\n",
      "================================\n",
      "f1 score = 0.007\n",
      "================================\n",
      "ROC AUC Score = 0.639\n",
      "fitting sample\n",
      "(5, 3062, 88) (5, 3062)\n",
      "training\n",
      "[LibLinear][LibLinear][LibLinear][LibLinear][LibLinear]Ensembler 3\n",
      "--------test---------\n",
      "================================\n",
      "Confusion Matrix:\n",
      "True Negative = 130548\n",
      "False Negative = 141\n",
      "True Positive = 236\n",
      "False Positive = 69075\n",
      "================================\n",
      "f1 score = 0.007\n",
      "================================\n",
      "ROC AUC Score = 0.640\n"
     ]
    }
   ],
   "source": [
    "dt_min_samples_50 = DecisionTreeClassifier(min_samples_leaf=50, random_state=KFOLD_SEED)\n",
    "bc_dt_min_samples_50 = BalanceCascade(estimator=dt_min_samples_50, n_max_subset=5, random_state=KFOLD_SEED)\n",
    "\n",
    "dt_min_samples_20 = DecisionTreeClassifier(min_samples_leaf=20, random_state=KFOLD_SEED)\n",
    "bc_dt_min_samples_20 = BalanceCascade(estimator=dt_min_samples_20, n_max_subset=5, random_state=KFOLD_SEED)\n",
    "\n",
    "dt_min_samples_10 = DecisionTreeClassifier(min_samples_leaf=10, random_state=KFOLD_SEED)\n",
    "bc_dt_min_samples_10 = BalanceCascade(estimator=dt_min_samples_10, n_max_subset=5, random_state=KFOLD_SEED)\n",
    "\n",
    "dt_min_samples_5 = DecisionTreeClassifier(min_samples_leaf=5, random_state=KFOLD_SEED)\n",
    "bc_dt_min_samples_5 = BalanceCascade(estimator=dt_min_samples_5, n_max_subset=5, random_state=KFOLD_SEED)\n",
    "\n",
    "ensemblers = [bc_dt_min_samples_50, bc_dt_min_samples_20, bc_dt_min_samples_10, bc_dt_min_samples_5]\n",
    "ensembler_test(logistic_regression, ensemblers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Class weight has to be balanced!\n",
    "If negative class is heavier, both TPR and FNR decrease, but TPR decrease causes more harm to ROC AUC.\n",
    "If positive class is heavier, the observation is the opposite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting sample\n",
      "(5, 3062, 88) (5, 3062)\n",
      "training\n",
      "Ensembler 0\n",
      "--------test---------\n",
      "================================\n",
      "Confusion Matrix:\n",
      "True Negative = 181161\n",
      "False Negative = 271\n",
      "True Positive = 106\n",
      "False Positive = 18462\n",
      "================================\n",
      "f1 score = 0.011\n",
      "================================\n",
      "ROC AUC Score = 0.594\n",
      "fitting sample\n",
      "(5, 3062, 88) (5, 3062)\n",
      "training\n",
      "Ensembler 0\n",
      "--------test---------\n",
      "================================\n",
      "Confusion Matrix:\n",
      "True Negative = 127183\n",
      "False Negative = 109\n",
      "True Positive = 268\n",
      "False Positive = 72440\n",
      "================================\n",
      "f1 score = 0.007\n",
      "================================\n",
      "ROC AUC Score = 0.674\n",
      "fitting sample\n",
      "(5, 3062, 88) (5, 3062)\n",
      "training\n",
      "Ensembler 0\n",
      "--------test---------\n",
      "================================\n",
      "Confusion Matrix:\n",
      "True Negative = 50431\n",
      "False Negative = 30\n",
      "True Positive = 347\n",
      "False Positive = 149192\n",
      "================================\n",
      "f1 score = 0.005\n",
      "================================\n",
      "ROC AUC Score = 0.587\n",
      "fitting sample\n",
      "(5, 3062, 88) (5, 3062)\n",
      "training\n",
      "Ensembler 0\n",
      "--------test---------\n",
      "================================\n",
      "Confusion Matrix:\n",
      "True Negative = 14369\n",
      "False Negative = 11\n",
      "True Positive = 366\n",
      "False Positive = 185254\n",
      "================================\n",
      "f1 score = 0.004\n",
      "================================\n",
      "ROC AUC Score = 0.521\n"
     ]
    }
   ],
   "source": [
    "def create_lr_proxy(class_weight='balanced'):\n",
    "    def create_lr():\n",
    "        return LogisticRegression(penalty='l2', class_weight=class_weight)\n",
    "    return create_lr\n",
    "\n",
    "dt = DecisionTreeClassifier(random_state=KFOLD_SEED)\n",
    "bc = BalanceCascade(estimator=dt, n_max_subset=5, random_state=KFOLD_SEED)\n",
    "\n",
    "ensembler_test(create_lr_proxy({0: 2, 1: 1}), [bc])\n",
    "ensembler_test(create_lr_proxy(), [bc])\n",
    "ensembler_test(create_lr_proxy({0: 1, 1: 2}), [bc])\n",
    "ensembler_test(create_lr_proxy({0: 1, 1: 4}), [bc])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try L1 regularization, C=1.0 is just right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting sample\n",
      "(5, 3062, 88) (5, 3062)\n",
      "training\n",
      "Ensembler 0\n",
      "--------test---------\n",
      "================================\n",
      "Confusion Matrix:\n",
      "True Negative = 131468\n",
      "False Negative = 140\n",
      "True Positive = 237\n",
      "False Positive = 68155\n",
      "================================\n",
      "f1 score = 0.007\n",
      "================================\n",
      "ROC AUC Score = 0.644\n",
      "fitting sample\n",
      "(5, 3062, 88) (5, 3062)\n",
      "training\n",
      "Ensembler 0\n",
      "--------test---------\n",
      "================================\n",
      "Confusion Matrix:\n",
      "True Negative = 131521\n",
      "False Negative = 140\n",
      "True Positive = 237\n",
      "False Positive = 68102\n",
      "================================\n",
      "f1 score = 0.007\n",
      "================================\n",
      "ROC AUC Score = 0.644\n",
      "fitting sample\n",
      "(5, 3062, 88) (5, 3062)\n",
      "training\n",
      "Ensembler 0\n",
      "--------test---------\n",
      "================================\n",
      "Confusion Matrix:\n",
      "True Negative = 131493\n",
      "False Negative = 140\n",
      "True Positive = 237\n",
      "False Positive = 68130\n",
      "================================\n",
      "f1 score = 0.007\n",
      "================================\n",
      "ROC AUC Score = 0.644\n",
      "fitting sample\n",
      "(5, 3062, 88) (5, 3062)\n",
      "training\n",
      "Ensembler 0\n",
      "--------test---------\n",
      "================================\n",
      "Confusion Matrix:\n",
      "True Negative = 131491\n",
      "False Negative = 144\n",
      "True Positive = 233\n",
      "False Positive = 68132\n",
      "================================\n",
      "f1 score = 0.007\n",
      "================================\n",
      "ROC AUC Score = 0.638\n",
      "fitting sample\n",
      "(5, 3062, 88) (5, 3062)\n",
      "training\n",
      "Ensembler 0\n",
      "--------test---------\n",
      "================================\n",
      "Confusion Matrix:\n",
      "True Negative = 131554\n",
      "False Negative = 145\n",
      "True Positive = 232\n",
      "False Positive = 68069\n",
      "================================\n",
      "f1 score = 0.007\n",
      "================================\n",
      "ROC AUC Score = 0.637\n"
     ]
    }
   ],
   "source": [
    "def create_lr_proxy(C=1.0):\n",
    "    def create_lr():\n",
    "        return LogisticRegression(penalty='l1', C=C, random_state=KFOLD_SEED)\n",
    "    return create_lr\n",
    "\n",
    "dt = DecisionTreeClassifier(max_features=0.2, random_state=KFOLD_SEED)\n",
    "bc = BalanceCascade(estimator=dt, n_max_subset=5, random_state=KFOLD_SEED)\n",
    "\n",
    "ensembler_test(create_lr_proxy(2.0), [bc])\n",
    "ensembler_test(create_lr_proxy(1.0), [bc])\n",
    "ensembler_test(create_lr_proxy(0.8), [bc])\n",
    "ensembler_test(create_lr_proxy(0.5), [bc])\n",
    "ensembler_test(create_lr_proxy(0.2), [bc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
